# Design Specification: AIntern v0.7.1a "Embedding Service Interface"

## Overview

**Version**: v0.7.1a
**Parent**: v0.7.1 Embedding Foundation
**Focus**: Core interfaces and models for embedding generation with multiple backend support

### Purpose

This sub-version establishes the foundational contracts for the embedding system:
1. `IEmbeddingService` interface for text embedding generation with model lifecycle management
2. `EmbeddingModels` containing configuration options, enums, and progress reporting models
3. `EmbeddingModelInfo` class for model metadata and preset configurations
4. `IEmbeddingModelRegistry` interface for managing available embedding models

### Dependencies

**From v0.6.5 (Agent Loop & Polish)**:
- Stable application infrastructure
- Existing LLamaSharp integration patterns from v0.4.x

**External Dependencies**:
- System.Numerics (for SIMD-accelerated similarity calculations)
- Standard .NET interfaces (IAsyncDisposable, IProgress<T>)

---

## Architecture

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                   v0.7.1a Embedding Service Interface Architecture            │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                        Core Interface Layer                              │ │
│  │  src/AIntern.Core/Interfaces/                                           │ │
│  ├─────────────────────────────────────────────────────────────────────────┤ │
│  │                                                                          │ │
│  │  ┌────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                       IEmbeddingService                             │ │ │
│  │  │  Extends: IAsyncDisposable                                          │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Properties:                                                 │   │ │ │
│  │  │  │  ├── IsModelLoaded: bool                                    │   │ │ │
│  │  │  │  ├── EmbeddingDimension: int                                │   │ │ │
│  │  │  │  ├── MaxTokens: int                                         │   │ │ │
│  │  │  │  └── CurrentModelName: string?                              │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Model Lifecycle Methods:                                   │   │ │ │
│  │  │  │  ├── LoadModelAsync(options, progress?, ct)                 │   │ │ │
│  │  │  │  └── UnloadModelAsync()                                     │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Embedding Generation Methods:                              │   │ │ │
│  │  │  │  ├── EmbedAsync(text, ct) → float[]                        │   │ │ │
│  │  │  │  └── EmbedBatchAsync(texts, progress?, ct) → float[][]     │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Vector Operations:                                         │   │ │ │
│  │  │  │  ├── CosineSimilarity(e1, e2) → float                      │   │ │ │
│  │  │  │  └── NormalizeEmbedding(embedding)                          │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Events:                                                    │   │ │ │
│  │  │  │  └── ModelStateChanged                                      │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  └────────────────────────────────────────────────────────────────────┘ │ │
│  │                                                                          │ │
│  │  ┌────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                   IEmbeddingModelRegistry                          │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Query Methods:                                             │   │ │ │
│  │  │  │  ├── GetAvailableModelsAsync(ct) → EmbeddingModelInfo[]    │   │ │ │
│  │  │  │  ├── GetModelAsync(modelId, ct) → EmbeddingModelInfo?      │   │ │ │
│  │  │  │  ├── GetDefaultModelAsync(ct) → EmbeddingModelInfo?        │   │ │ │
│  │  │  │  └── IsModelDownloadedAsync(modelId, ct) → bool            │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Management Methods:                                        │   │ │ │
│  │  │  │  ├── RegisterModelAsync(model, ct)                         │   │ │ │
│  │  │  │  ├── UnregisterModelAsync(modelId, ct)                     │   │ │ │
│  │  │  │  └── ScanDirectoryAsync(directory, ct) → EmbeddingModelInfo[] │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  └────────────────────────────────────────────────────────────────────┘ │ │
│  │                                                                          │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                          Model Layer                                     │ │
│  │  src/AIntern.Core/Models/                                               │ │
│  ├─────────────────────────────────────────────────────────────────────────┤ │
│  │                                                                          │ │
│  │  ┌────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                    EmbeddingModelOptions                            │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Model Configuration:                                       │   │ │ │
│  │  │  │  ├── ModelPath: string                                     │   │ │ │
│  │  │  │  ├── ModelName: string                                     │   │ │ │
│  │  │  │  └── ModelType: EmbeddingModelType                         │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Hardware Configuration:                                    │   │ │ │
│  │  │  │  ├── GpuLayers: int (-1 auto, 0 CPU only)                  │   │ │ │
│  │  │  │  ├── Threads: int (0 = auto)                               │   │ │ │
│  │  │  │  └── UseMemoryMapping: bool                                │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Inference Configuration:                                   │   │ │ │
│  │  │  │  ├── ContextSize: int (max tokens)                         │   │ │ │
│  │  │  │  ├── BatchSize: int                                        │   │ │ │
│  │  │  │  ├── NormalizeEmbeddings: bool                             │   │ │ │
│  │  │  │  ├── PoolingType: EmbeddingPoolingType                     │   │ │ │
│  │  │  │  └── TextPrefix: string?                                   │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  └────────────────────────────────────────────────────────────────────┘ │ │
│  │                                                                          │ │
│  │  ┌────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                      Enumerations                                   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  EmbeddingModelType:                                        │   │ │ │
│  │  │  │  ├── Auto (detect from file extension)                     │   │ │ │
│  │  │  │  ├── Gguf (LLamaSharp loader)                              │   │ │ │
│  │  │  │  ├── Onnx (ONNX Runtime loader)                            │   │ │ │
│  │  │  │  └── SentenceTransformers (ML.NET/custom)                  │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  EmbeddingPoolingType:                                      │   │ │ │
│  │  │  │  ├── Mean (average of all tokens)                          │   │ │ │
│  │  │  │  ├── Cls (use [CLS] token)                                 │   │ │ │
│  │  │  │  ├── Last (use last token)                                 │   │ │ │
│  │  │  │  └── Max (max across token dimension)                      │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  └────────────────────────────────────────────────────────────────────┘ │ │
│  │                                                                          │ │
│  │  ┌────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                    Progress Reporting Models                        │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  ModelLoadProgress:                                         │   │ │ │
│  │  │  │  ├── Stage: string                                         │   │ │ │
│  │  │  │  ├── PercentComplete: double                               │   │ │ │
│  │  │  │  ├── BytesLoaded: long?                                    │   │ │ │
│  │  │  │  └── TotalBytes: long?                                     │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  EmbeddingProgress:                                         │   │ │ │
│  │  │  │  ├── ProcessedCount: int                                   │   │ │ │
│  │  │  │  ├── TotalCount: int                                       │   │ │ │
│  │  │  │  ├── PercentComplete: double (computed)                    │   │ │ │
│  │  │  │  ├── TextsPerSecond: double?                               │   │ │ │
│  │  │  │  └── EstimatedRemaining: TimeSpan?                         │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  └────────────────────────────────────────────────────────────────────┘ │ │
│  │                                                                          │ │
│  │  ┌────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                    EmbeddingModelInfo                               │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Identity:                                                  │   │ │ │
│  │  │  │  ├── Id: string                                            │   │ │ │
│  │  │  │  ├── Name: string                                          │   │ │ │
│  │  │  │  └── Description: string                                   │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Technical Specs:                                           │   │ │ │
│  │  │  │  ├── Path: string                                          │   │ │ │
│  │  │  │  ├── Type: EmbeddingModelType                              │   │ │ │
│  │  │  │  ├── Dimension: int                                        │   │ │ │
│  │  │  │  ├── MaxTokens: int                                        │   │ │ │
│  │  │  │  └── SizeBytes: long                                       │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Capabilities:                                              │   │ │ │
│  │  │  │  ├── IsDefault: bool                                       │   │ │ │
│  │  │  │  ├── SupportsGpu: bool                                     │   │ │ │
│  │  │  │  ├── UseCases: string[]                                    │   │ │ │
│  │  │  │  └── TextPrefix: string?                                   │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Computed:                                                  │   │ │ │
│  │  │  │  └── SizeDisplay: string (human-readable)                  │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  └────────────────────────────────────────────────────────────────────┘ │ │
│  │                                                                          │ │
│  │  ┌────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                  EmbeddingModelPresets (static)                     │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Available Presets:                                         │   │ │ │
│  │  │  │  ├── NomicEmbedText (768 dim, 8192 ctx, GGUF, default)    │   │ │ │
│  │  │  │  ├── AllMiniLmL6V2 (384 dim, 512 ctx, ONNX)               │   │ │ │
│  │  │  │  ├── BgeSmallEn (384 dim, 512 ctx, ONNX)                  │   │ │ │
│  │  │  │  └── CodeBert (768 dim, 512 ctx, ONNX)                    │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  └────────────────────────────────────────────────────────────────────┘ │ │
│  │                                                                          │ │
│  │  ┌────────────────────────────────────────────────────────────────────┐ │ │
│  │  │              EmbeddingModelStateChangedEventArgs                    │ │ │
│  │  │  ┌─────────────────────────────────────────────────────────────┐   │ │ │
│  │  │  │  Properties:                                                │   │ │ │
│  │  │  │  ├── IsLoaded: bool                                        │   │ │ │
│  │  │  │  ├── ModelPath: string?                                    │   │ │ │
│  │  │  │  ├── ModelName: string?                                    │   │ │ │
│  │  │  │  ├── EmbeddingDimension: int                               │   │ │ │
│  │  │  │  └── Error: string?                                        │   │ │ │
│  │  │  └─────────────────────────────────────────────────────────────┘   │ │ │
│  │  └────────────────────────────────────────────────────────────────────┘ │ │
│  │                                                                          │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Interface Details

### IEmbeddingService Interface

The core service interface defines the contract for all embedding generation implementations:

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                        IEmbeddingService Lifecycle                            │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  State Machine                                                           │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │     ┌─────────────┐        LoadModelAsync()        ┌───────────┐  │  │ │
│  │  │     │  Unloaded   │ ─────────────────────────────► │  Loading  │  │  │ │
│  │  │     │             │                                │           │  │  │ │
│  │  │     │ IsModelLoaded│ ◄───────────────────────────── │           │  │  │ │
│  │  │     │   = false   │       UnloadModelAsync()       │           │  │  │ │
│  │  │     └─────────────┘              or                └─────┬─────┘  │  │ │
│  │  │           ▲                   Exception                  │        │  │ │
│  │  │           │                                              │        │  │ │
│  │  │           │                                    Success   │        │  │ │
│  │  │           │         UnloadModelAsync()                   ▼        │  │ │
│  │  │           └─────────────────────────────────────┌───────────┐     │  │ │
│  │  │                                                 │   Ready   │     │  │ │
│  │  │                                                 │           │     │  │ │
│  │  │                                                 │ IsModelLoaded│  │  │ │
│  │  │                                                 │   = true  │     │  │ │
│  │  │                                                 └───────────┘     │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Embedding Generation Flow                                               │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │  EmbedAsync(text)                                                 │  │ │
│  │  │  ┌──────────────────────────────────────────────────────────────┐ │  │ │
│  │  │  │  1. Check IsModelLoaded → throw if false                     │ │  │ │
│  │  │  │  2. Apply TextPrefix if configured                           │ │  │ │
│  │  │  │  3. Tokenize text (truncate if > MaxTokens)                  │ │  │ │
│  │  │  │  4. Generate embedding via backend                            │ │  │ │
│  │  │  │  5. Apply pooling strategy (PoolingType)                     │ │  │ │
│  │  │  │  6. Normalize if NormalizeEmbeddings = true                  │ │  │ │
│  │  │  │  7. Return float[EmbeddingDimension]                         │ │  │ │
│  │  │  └──────────────────────────────────────────────────────────────┘ │  │ │
│  │  │                                                                    │  │ │
│  │  │  EmbedBatchAsync(texts)                                           │  │ │
│  │  │  ┌──────────────────────────────────────────────────────────────┐ │  │ │
│  │  │  │  1. Check IsModelLoaded → throw if false                     │ │  │ │
│  │  │  │  2. Partition texts into BatchSize chunks                    │ │  │ │
│  │  │  │  3. For each batch:                                          │ │  │ │
│  │  │  │     ├── Apply TextPrefix to each text                        │ │  │ │
│  │  │  │     ├── Generate embeddings via backend                      │ │  │ │
│  │  │  │     ├── Normalize each if configured                         │ │  │ │
│  │  │  │     └── Report progress (processed/total, rate, ETA)         │ │  │ │
│  │  │  │  4. Return IReadOnlyList<float[]>                            │ │  │ │
│  │  │  └──────────────────────────────────────────────────────────────┘ │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Vector Operations

### Cosine Similarity Calculation

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                          Cosine Similarity Algorithm                          │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Mathematical Definition                                                 │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │  CosineSimilarity(A, B) =           A · B                         │  │ │
│  │  │                            ───────────────────────                 │  │ │
│  │  │                            ‖A‖ × ‖B‖                               │  │ │
│  │  │                                                                    │  │ │
│  │  │  Where:                                                            │  │ │
│  │  │    A · B = Σ(aᵢ × bᵢ)           (dot product)                     │  │ │
│  │  │    ‖A‖ = √(Σ(aᵢ²))              (Euclidean norm)                  │  │ │
│  │  │    ‖B‖ = √(Σ(bᵢ²))                                                │  │ │
│  │  │                                                                    │  │ │
│  │  │  Result range: [-1, 1]                                            │  │ │
│  │  │    1  = identical direction                                       │  │ │
│  │  │    0  = orthogonal (unrelated)                                    │  │ │
│  │  │   -1  = opposite direction                                        │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  SIMD Optimization Strategy                                              │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │  if (Vector.IsHardwareAccelerated && length >= Vector<float>.Count)│  │ │
│  │  │  {                                                                 │  │ │
│  │  │      // Process Vector<float>.Count floats at once                │  │ │
│  │  │      // (8 floats on AVX2, 4 on SSE, 4 on NEON ARM)               │  │ │
│  │  │                                                                    │  │ │
│  │  │      ┌───────────────────────────────────────────────────────┐   │  │ │
│  │  │      │ Vector<float> v1, v2                                  │   │  │ │
│  │  │      │                                                        │   │  │ │
│  │  │      │ dotVec   += v1 * v2      // parallel multiply-add     │   │  │ │
│  │  │      │ norm1Vec += v1 * v1                                    │   │  │ │
│  │  │      │ norm2Vec += v2 * v2                                    │   │  │ │
│  │  │      └───────────────────────────────────────────────────────┘   │  │ │
│  │  │                                                                    │  │ │
│  │  │      // Horizontal sum of vector elements                         │  │ │
│  │  │      // Process remaining elements with scalar loop               │  │ │
│  │  │  }                                                                 │  │ │
│  │  │  else                                                              │  │ │
│  │  │  {                                                                 │  │ │
│  │  │      // Scalar fallback for unsupported hardware                  │  │ │
│  │  │  }                                                                 │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Performance Characteristics                                             │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │  Embedding Size   │  Scalar Time  │  SIMD Time   │  Speedup       │  │ │
│  │  │  ─────────────────┼───────────────┼──────────────┼────────────────│  │ │
│  │  │  384 (MiniLM)     │    ~1.5 μs    │   ~0.3 μs    │     ~5x        │  │ │
│  │  │  768 (BERT/Nomic) │    ~3.0 μs    │   ~0.5 μs    │     ~6x        │  │ │
│  │  │  1024             │    ~4.0 μs    │   ~0.6 μs    │     ~7x        │  │ │
│  │  │                                                                    │  │ │
│  │  │  Note: Measurements depend on CPU architecture                    │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

### Embedding Normalization

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                         Embedding Normalization                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Purpose                                                                 │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │  Normalization converts an embedding to unit length (‖e‖ = 1)     │  │ │
│  │  │                                                                    │  │ │
│  │  │  Benefits:                                                         │  │ │
│  │  │  ├── Cosine similarity becomes dot product (faster)               │  │ │
│  │  │  │   cos(A, B) = A · B when ‖A‖ = ‖B‖ = 1                        │  │ │
│  │  │  ├── Enables approximate nearest neighbor algorithms              │  │ │
│  │  │  ├── Ensures consistent magnitude across embeddings               │  │ │
│  │  │  └── Required by many vector databases                            │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Algorithm                                                               │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │  Input:  e = [e₁, e₂, ..., eₙ]                                    │  │ │
│  │  │                                                                    │  │ │
│  │  │  Step 1: magnitude = √(Σ(eᵢ²))                                    │  │ │
│  │  │                                                                    │  │ │
│  │  │  Step 2: if magnitude > 0:                                        │  │ │
│  │  │            eᵢ = eᵢ / magnitude  (for all i)                       │  │ │
│  │  │                                                                    │  │ │
│  │  │  Output: e' where ‖e'‖ = 1                                        │  │ │
│  │  │                                                                    │  │ │
│  │  │  Note: In-place modification (Span<float>) for efficiency        │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Model Type Details

### EmbeddingModelType Enumeration

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                          Embedding Model Types                                │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Auto (Default)                                                          │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Detection Logic:                                                  │  │ │
│  │  │  ├── Extension ".gguf" → Gguf                                     │  │ │
│  │  │  ├── Extension ".onnx" → Onnx                                     │  │ │
│  │  │  ├── Directory with "config.json" → SentenceTransformers          │  │ │
│  │  │  └── Otherwise → throw NotSupportedException                      │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Gguf (LLamaSharp)                                                       │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Characteristics:                                                  │  │ │
│  │  │  ├── Quantized format (Q4_K_M, Q5_K_M, Q8_0, F16)                 │  │ │
│  │  │  ├── Native GPU support via Metal (macOS) or CUDA (Win/Linux)    │  │ │
│  │  │  ├── Larger context windows possible (8K+ tokens)                 │  │ │
│  │  │  ├── Memory-mapped loading supported                              │  │ │
│  │  │  └── Best for: Code search, technical documentation               │  │ │
│  │  │                                                                    │  │ │
│  │  │  Example Models:                                                   │  │ │
│  │  │  ├── nomic-embed-text-v1.5.Q8_0.gguf                              │  │ │
│  │  │  ├── e5-large-v2.Q4_K_M.gguf                                      │  │ │
│  │  │  └── mxbai-embed-large-v1.Q5_K_M.gguf                             │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Onnx (ONNX Runtime)                                                     │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Characteristics:                                                  │  │ │
│  │  │  ├── Cross-platform optimized inference                           │  │ │
│  │  │  ├── DirectML (Windows), CoreML (macOS), CUDA execution providers│  │ │
│  │  │  ├── FP32 or FP16 precision                                       │  │ │
│  │  │  ├── Requires tokenizer files alongside model                     │  │ │
│  │  │  └── Best for: Fast inference, sentence transformers              │  │ │
│  │  │                                                                    │  │ │
│  │  │  Example Models:                                                   │  │ │
│  │  │  ├── all-MiniLM-L6-v2.onnx                                        │  │ │
│  │  │  ├── bge-small-en-v1.5.onnx                                       │  │ │
│  │  │  └── codebert-base.onnx                                           │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  SentenceTransformers                                                    │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Characteristics:                                                  │  │ │
│  │  │  ├── HuggingFace model format (config.json + pytorch_model.bin)  │  │ │
│  │  │  ├── Loaded via ML.NET or custom Python interop                   │  │ │
│  │  │  ├── Full precision (FP32)                                        │  │ │
│  │  │  ├── Rich ecosystem of pre-trained models                         │  │ │
│  │  │  └── Best for: Research, specialized domain models                │  │ │
│  │  │                                                                    │  │ │
│  │  │  Note: Future implementation in v0.7.1c                           │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

### EmbeddingPoolingType Enumeration

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                          Pooling Strategies                                   │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Token Embeddings → Single Vector                                        │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │  Input: "Hello world"                                              │  │ │
│  │  │                                                                    │  │ │
│  │  │  Token Embeddings (n tokens × d dimensions):                       │  │ │
│  │  │  ┌─────────────────────────────────────────────────────────┐      │  │ │
│  │  │  │  [CLS] │ Hello │ world │ [SEP] │                        │      │  │ │
│  │  │  │  ──────┼───────┼───────┼───────┤                        │      │  │ │
│  │  │  │  0.1   │ 0.3   │ 0.2   │ 0.1   │  dim 0                 │      │  │ │
│  │  │  │  0.4   │ 0.1   │ 0.5   │ 0.2   │  dim 1                 │      │  │ │
│  │  │  │  0.2   │ 0.6   │ 0.3   │ 0.4   │  dim 2                 │      │  │ │
│  │  │  │  ...   │ ...   │ ...   │ ...   │  ...                   │      │  │ │
│  │  │  └─────────────────────────────────────────────────────────┘      │  │ │
│  │  │                                                                    │  │ │
│  │  │  Output: Single vector of d dimensions                             │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Mean Pooling (Default)                                                  │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Formula: output[d] = mean(token_embeddings[:, d])                │  │ │
│  │  │                                                                    │  │ │
│  │  │  Example (dim 0): (0.1 + 0.3 + 0.2 + 0.1) / 4 = 0.175             │  │ │
│  │  │                                                                    │  │ │
│  │  │  Best for: General-purpose, sentence similarity                   │  │ │
│  │  │  Used by: Most sentence transformer models                        │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  CLS Pooling                                                             │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Formula: output = token_embeddings[0]  (the [CLS] token)         │  │ │
│  │  │                                                                    │  │ │
│  │  │  Example: output = [0.1, 0.4, 0.2, ...]                           │  │ │
│  │  │                                                                    │  │ │
│  │  │  Best for: BERT-style models trained with [CLS] supervision       │  │ │
│  │  │  Used by: CodeBERT, original BERT                                 │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Last Pooling                                                            │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Formula: output = token_embeddings[-1]  (last token)             │  │ │
│  │  │                                                                    │  │ │
│  │  │  Example: output = [0.1, 0.2, 0.4, ...]  (from [SEP])             │  │ │
│  │  │                                                                    │  │ │
│  │  │  Best for: Decoder-only models (GPT-style)                        │  │ │
│  │  │  Used by: LLaMA-based embedding models                            │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Max Pooling                                                             │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Formula: output[d] = max(token_embeddings[:, d])                 │  │ │
│  │  │                                                                    │  │ │
│  │  │  Example (dim 0): max(0.1, 0.3, 0.2, 0.1) = 0.3                   │  │ │
│  │  │                                                                    │  │ │
│  │  │  Best for: Capturing presence of features regardless of position  │  │ │
│  │  │  Used by: Some specialized retrieval models                       │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Model Presets

### Predefined Embedding Models

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                      EmbeddingModelPresets Configuration                      │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Nomic Embed Text v1.5 (DEFAULT)                                         │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Id:          nomic-embed-text-v1.5                                │  │ │
│  │  │  Type:        GGUF (LLamaSharp)                                    │  │ │
│  │  │  Dimension:   768                                                   │  │ │
│  │  │  Max Tokens:  8192                                                  │  │ │
│  │  │  GPU:         Supported (Metal/CUDA)                                │  │ │
│  │  │  TextPrefix:  "search_document: "                                   │  │ │
│  │  │  Use Cases:   Code Search, Documentation, General Text             │  │ │
│  │  │                                                                    │  │ │
│  │  │  Strengths:                                                        │  │ │
│  │  │  ├── Excellent code understanding                                 │  │ │
│  │  │  ├── Long context support (8K tokens)                             │  │ │
│  │  │  ├── Trained on programming documentation                         │  │ │
│  │  │  └── Quantized versions available (Q4, Q5, Q8)                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  All-MiniLM-L6-v2                                                        │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Id:          all-minilm-l6-v2                                     │  │ │
│  │  │  Type:        ONNX                                                  │  │ │
│  │  │  Dimension:   384                                                   │  │ │
│  │  │  Max Tokens:  512                                                   │  │ │
│  │  │  GPU:         Supported (DirectML/CoreML/CUDA)                      │  │ │
│  │  │  TextPrefix:  None                                                  │  │ │
│  │  │  Use Cases:   Fast Search, Low Memory                              │  │ │
│  │  │                                                                    │  │ │
│  │  │  Strengths:                                                        │  │ │
│  │  │  ├── Very fast inference (~5ms/embedding)                         │  │ │
│  │  │  ├── Small model size (~80MB)                                     │  │ │
│  │  │  ├── Good general-purpose performance                              │  │ │
│  │  │  └── Low memory footprint                                          │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  BGE Small EN v1.5                                                       │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Id:          bge-small-en-v1.5                                    │  │ │
│  │  │  Type:        ONNX                                                  │  │ │
│  │  │  Dimension:   384                                                   │  │ │
│  │  │  Max Tokens:  512                                                   │  │ │
│  │  │  GPU:         Supported                                             │  │ │
│  │  │  TextPrefix:  None                                                  │  │ │
│  │  │  Use Cases:   Code Search, Semantic Search                         │  │ │
│  │  │                                                                    │  │ │
│  │  │  Strengths:                                                        │  │ │
│  │  │  ├── Strong performance on MTEB benchmark                          │  │ │
│  │  │  ├── Good balance of speed and quality                            │  │ │
│  │  │  ├── Better code understanding than MiniLM                        │  │ │
│  │  │  └── From BAAI (Beijing Academy of AI)                             │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  CodeBERT Base                                                           │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Id:          codebert-base                                        │  │ │
│  │  │  Type:        ONNX                                                  │  │ │
│  │  │  Dimension:   768                                                   │  │ │
│  │  │  Max Tokens:  512                                                   │  │ │
│  │  │  GPU:         Supported                                             │  │ │
│  │  │  TextPrefix:  None                                                  │  │ │
│  │  │  Use Cases:   Code Search, Code Understanding                      │  │ │
│  │  │                                                                    │  │ │
│  │  │  Strengths:                                                        │  │ │
│  │  │  ├── Trained specifically on code (6 languages)                   │  │ │
│  │  │  ├── Microsoft Research model                                     │  │ │
│  │  │  ├── Understands code structure and semantics                     │  │ │
│  │  │  └── Good for code-to-code similarity                              │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Model Comparison Matrix                                                 │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │                                                                    │  │ │
│  │  │  Model          │ Dim │ Tokens│ Speed │ Quality │ Code  │ Memory │  │ │
│  │  │  ────────────────┼─────┼───────┼───────┼─────────┼───────┼────────│  │ │
│  │  │  Nomic v1.5     │ 768 │ 8192  │ Med   │ High    │ High  │ Med    │  │ │
│  │  │  MiniLM-L6      │ 384 │ 512   │ Fast  │ Med     │ Low   │ Low    │  │ │
│  │  │  BGE-Small      │ 384 │ 512   │ Fast  │ Med-Hi  │ Med   │ Low    │  │ │
│  │  │  CodeBERT       │ 768 │ 512   │ Med   │ Med     │ High  │ Med    │  │ │
│  │  │                                                                    │  │ │
│  │  │  Recommendation:                                                   │  │ │
│  │  │  ├── General use → Nomic Embed Text (default)                     │  │ │
│  │  │  ├── Speed priority → MiniLM-L6                                   │  │ │
│  │  │  └── Code-only → CodeBERT                                         │  │ │
│  │  │                                                                    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## File Specifications

### 1. IEmbeddingService.cs

**Location**: `src/AIntern.Core/Interfaces/IEmbeddingService.cs`
**Type**: `interface`
**Implements**: `IAsyncDisposable`
**Purpose**: Core contract for embedding generation with model lifecycle management

```csharp
namespace AIntern.Core.Interfaces;

using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using AIntern.Core.Models;

/// <summary>
/// Service for generating text embeddings using local models.
/// Supports both GGUF models via LLamaSharp and ONNX models.
/// </summary>
public interface IEmbeddingService : IAsyncDisposable
{
    /// <summary>
    /// Whether an embedding model is currently loaded and ready.
    /// </summary>
    bool IsModelLoaded { get; }

    /// <summary>
    /// Dimension of the embedding vectors produced by the current model.
    /// Returns 0 if no model is loaded.
    /// </summary>
    int EmbeddingDimension { get; }

    /// <summary>
    /// Maximum number of tokens the model can process per embedding request.
    /// Text exceeding this limit will be truncated.
    /// </summary>
    int MaxTokens { get; }

    /// <summary>
    /// Name/identifier of the currently loaded model.
    /// </summary>
    string? CurrentModelName { get; }

    /// <summary>
    /// Load an embedding model from disk.
    /// </summary>
    /// <param name="options">Model loading configuration.</param>
    /// <param name="progress">Optional progress reporter.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <exception cref="ArgumentException">
    /// Thrown when model type is incompatible with this service implementation.
    /// </exception>
    /// <exception cref="FileNotFoundException">
    /// Thrown when model file does not exist.
    /// </exception>
    /// <exception cref="InvalidOperationException">
    /// Thrown when model loading fails due to format or memory issues.
    /// </exception>
    Task LoadModelAsync(
        EmbeddingModelOptions options,
        IProgress<ModelLoadProgress>? progress = null,
        CancellationToken ct = default);

    /// <summary>
    /// Unload the currently loaded model and free resources.
    /// Safe to call even if no model is loaded.
    /// </summary>
    Task UnloadModelAsync();

    /// <summary>
    /// Generate an embedding vector for a single text input.
    /// </summary>
    /// <param name="text">The text to embed.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>
    /// The embedding vector as a float array with length EmbeddingDimension.
    /// Returns zero vector if text is null or empty.
    /// </returns>
    /// <exception cref="InvalidOperationException">
    /// Thrown when no model is loaded.
    /// </exception>
    Task<float[]> EmbedAsync(string text, CancellationToken ct = default);

    /// <summary>
    /// Generate embedding vectors for multiple text inputs efficiently.
    /// Uses batching for improved throughput.
    /// </summary>
    /// <param name="texts">Collection of texts to embed.</param>
    /// <param name="progress">Optional progress reporter.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>
    /// List of embedding vectors in the same order as input.
    /// Empty texts produce zero vectors.
    /// </returns>
    /// <exception cref="InvalidOperationException">
    /// Thrown when no model is loaded.
    /// </exception>
    Task<IReadOnlyList<float[]>> EmbedBatchAsync(
        IEnumerable<string> texts,
        IProgress<EmbeddingProgress>? progress = null,
        CancellationToken ct = default);

    /// <summary>
    /// Calculate cosine similarity between two embedding vectors.
    /// Uses SIMD acceleration when available.
    /// </summary>
    /// <param name="embedding1">First embedding vector.</param>
    /// <param name="embedding2">Second embedding vector.</param>
    /// <returns>
    /// Similarity score between -1 and 1.
    /// Returns 0 for empty embeddings.
    /// </returns>
    /// <exception cref="ArgumentException">
    /// Thrown when embeddings have different dimensions.
    /// </exception>
    float CosineSimilarity(ReadOnlySpan<float> embedding1, ReadOnlySpan<float> embedding2);

    /// <summary>
    /// Normalize an embedding vector to unit length.
    /// Modifies the embedding in place.
    /// </summary>
    /// <param name="embedding">The embedding to normalize.</param>
    /// <remarks>
    /// After normalization, ||embedding|| = 1.
    /// Normalized embeddings allow cosine similarity to be computed via dot product.
    /// No-op for empty embeddings.
    /// </remarks>
    void NormalizeEmbedding(Span<float> embedding);

    /// <summary>
    /// Event raised when model loading state changes.
    /// Fired on successful load, unload, or load failure.
    /// </summary>
    event EventHandler<EmbeddingModelStateChangedEventArgs>? ModelStateChanged;
}
```

---

### 2. EmbeddingModels.cs

**Location**: `src/AIntern.Core/Models/EmbeddingModels.cs`
**Purpose**: Configuration options, enumerations, and progress reporting models

```csharp
namespace AIntern.Core.Models;

using System;

/// <summary>
/// Configuration options for loading an embedding model.
/// </summary>
public sealed class EmbeddingModelOptions
{
    /// <summary>
    /// Path to the embedding model file (GGUF or ONNX).
    /// </summary>
    public string ModelPath { get; init; } = string.Empty;

    /// <summary>
    /// Display name for the model.
    /// </summary>
    public string ModelName { get; init; } = string.Empty;

    /// <summary>
    /// Type of model for selecting the appropriate loader.
    /// Default: Auto (detect from file extension).
    /// </summary>
    public EmbeddingModelType ModelType { get; init; } = EmbeddingModelType.Auto;

    /// <summary>
    /// Number of GPU layers to offload.
    /// -1: Auto-detect optimal GPU layers.
    /// 0: CPU only (no GPU acceleration).
    /// >0: Specific number of layers on GPU.
    /// </summary>
    public int GpuLayers { get; init; } = -1;

    /// <summary>
    /// Context size (maximum tokens) for the model.
    /// Text exceeding this will be truncated.
    /// Default: 512.
    /// </summary>
    public int ContextSize { get; init; } = 512;

    /// <summary>
    /// Batch size for embedding generation.
    /// Larger batches are faster but use more memory.
    /// Default: 32.
    /// </summary>
    public int BatchSize { get; init; } = 32;

    /// <summary>
    /// Number of threads for CPU inference.
    /// 0: Auto (use all available cores).
    /// </summary>
    public int Threads { get; init; } = 0;

    /// <summary>
    /// Whether to normalize embeddings to unit length after generation.
    /// Recommended for cosine similarity comparisons.
    /// Default: true.
    /// </summary>
    public bool NormalizeEmbeddings { get; init; } = true;

    /// <summary>
    /// Pooling strategy for combining token embeddings.
    /// Default: Mean.
    /// </summary>
    public EmbeddingPoolingType PoolingType { get; init; } = EmbeddingPoolingType.Mean;

    /// <summary>
    /// Optional prefix to prepend to all texts before embedding.
    /// Some models require specific prefixes (e.g., "query: " or "passage: ").
    /// </summary>
    public string? TextPrefix { get; init; }

    /// <summary>
    /// Whether to use memory mapping for model loading.
    /// Faster startup but may affect inference speed.
    /// Default: true.
    /// </summary>
    public bool UseMemoryMapping { get; init; } = true;
}

/// <summary>
/// Types of embedding models supported.
/// </summary>
public enum EmbeddingModelType
{
    /// <summary>
    /// Auto-detect based on file extension.
    /// .gguf → Gguf, .onnx → Onnx, directory → SentenceTransformers.
    /// </summary>
    Auto = 0,

    /// <summary>
    /// GGUF format models loaded via LLamaSharp.
    /// Supports quantization (Q4_K_M, Q5_K_M, Q8_0, F16).
    /// </summary>
    Gguf = 1,

    /// <summary>
    /// ONNX format models loaded via ONNX Runtime.
    /// Cross-platform optimized inference.
    /// </summary>
    Onnx = 2,

    /// <summary>
    /// Sentence Transformers models via ML.NET or custom loader.
    /// HuggingFace format (config.json + pytorch_model.bin).
    /// </summary>
    SentenceTransformers = 3
}

/// <summary>
/// Pooling strategies for combining token embeddings into a single vector.
/// </summary>
public enum EmbeddingPoolingType
{
    /// <summary>
    /// Mean of all token embeddings (most common).
    /// Best for general-purpose sentence similarity.
    /// </summary>
    Mean = 0,

    /// <summary>
    /// Use the [CLS] token embedding.
    /// Best for BERT-style models trained with [CLS] supervision.
    /// </summary>
    Cls = 1,

    /// <summary>
    /// Use the last token embedding.
    /// Best for decoder-only models (GPT-style, LLaMA).
    /// </summary>
    Last = 2,

    /// <summary>
    /// Max pooling across token dimension.
    /// Captures presence of features regardless of position.
    /// </summary>
    Max = 3
}

/// <summary>
/// Progress information during model loading.
/// </summary>
public sealed class ModelLoadProgress
{
    /// <summary>
    /// Current loading stage description.
    /// Examples: "Initializing", "Loading weights", "Creating embedder".
    /// </summary>
    public string Stage { get; init; } = string.Empty;

    /// <summary>
    /// Percentage complete (0-100).
    /// </summary>
    public double PercentComplete { get; init; }

    /// <summary>
    /// Bytes loaded so far (for large models).
    /// </summary>
    public long? BytesLoaded { get; init; }

    /// <summary>
    /// Total bytes to load.
    /// </summary>
    public long? TotalBytes { get; init; }
}

/// <summary>
/// Progress information during batch embedding generation.
/// </summary>
public sealed class EmbeddingProgress
{
    /// <summary>
    /// Number of texts processed so far.
    /// </summary>
    public int ProcessedCount { get; init; }

    /// <summary>
    /// Total number of texts to process.
    /// </summary>
    public int TotalCount { get; init; }

    /// <summary>
    /// Percentage complete (0-100).
    /// </summary>
    public double PercentComplete => TotalCount > 0
        ? (double)ProcessedCount / TotalCount * 100
        : 0;

    /// <summary>
    /// Current processing rate (texts per second).
    /// </summary>
    public double? TextsPerSecond { get; init; }

    /// <summary>
    /// Estimated time remaining based on current rate.
    /// </summary>
    public TimeSpan? EstimatedRemaining { get; init; }
}

/// <summary>
/// Event args for model state changes.
/// </summary>
public sealed class EmbeddingModelStateChangedEventArgs : EventArgs
{
    /// <summary>
    /// Whether a model is currently loaded.
    /// </summary>
    public bool IsLoaded { get; init; }

    /// <summary>
    /// Path to the loaded model (null if unloaded).
    /// </summary>
    public string? ModelPath { get; init; }

    /// <summary>
    /// Name of the loaded model.
    /// </summary>
    public string? ModelName { get; init; }

    /// <summary>
    /// Embedding dimension of the loaded model.
    /// </summary>
    public int EmbeddingDimension { get; init; }

    /// <summary>
    /// Error message if loading failed.
    /// </summary>
    public string? Error { get; init; }
}
```

---

### 3. EmbeddingModelInfo.cs

**Location**: `src/AIntern.Core/Models/EmbeddingModelInfo.cs`
**Purpose**: Model metadata and preset configurations

```csharp
namespace AIntern.Core.Models;

using System;

/// <summary>
/// Information about an available embedding model.
/// </summary>
public sealed class EmbeddingModelInfo
{
    /// <summary>
    /// Unique identifier for the model.
    /// </summary>
    public string Id { get; init; } = string.Empty;

    /// <summary>
    /// Display name.
    /// </summary>
    public string Name { get; init; } = string.Empty;

    /// <summary>
    /// Model description.
    /// </summary>
    public string Description { get; init; } = string.Empty;

    /// <summary>
    /// Path to the model file.
    /// </summary>
    public string Path { get; init; } = string.Empty;

    /// <summary>
    /// Model type (GGUF, ONNX, etc.).
    /// </summary>
    public EmbeddingModelType Type { get; init; }

    /// <summary>
    /// Embedding dimension.
    /// </summary>
    public int Dimension { get; init; }

    /// <summary>
    /// Maximum context length in tokens.
    /// </summary>
    public int MaxTokens { get; init; }

    /// <summary>
    /// File size in bytes.
    /// </summary>
    public long SizeBytes { get; init; }

    /// <summary>
    /// Whether this is the default/recommended model.
    /// </summary>
    public bool IsDefault { get; init; }

    /// <summary>
    /// Whether the model supports GPU acceleration.
    /// </summary>
    public bool SupportsGpu { get; init; }

    /// <summary>
    /// Recommended use cases.
    /// </summary>
    public string[] UseCases { get; init; } = Array.Empty<string>();

    /// <summary>
    /// Optional text prefix required by the model.
    /// </summary>
    public string? TextPrefix { get; init; }

    /// <summary>
    /// Human-readable size string.
    /// </summary>
    public string SizeDisplay => SizeBytes switch
    {
        < 1024 => $"{SizeBytes} B",
        < 1024 * 1024 => $"{SizeBytes / 1024.0:F1} KB",
        < 1024 * 1024 * 1024 => $"{SizeBytes / (1024.0 * 1024):F1} MB",
        _ => $"{SizeBytes / (1024.0 * 1024 * 1024):F2} GB"
    };
}

/// <summary>
/// Predefined embedding model configurations.
/// </summary>
public static class EmbeddingModelPresets
{
    /// <summary>
    /// Nomic Embed Text v1.5 - Excellent for code and general text.
    /// Default recommendation for AIntern RAG system.
    /// </summary>
    public static EmbeddingModelInfo NomicEmbedText => new()
    {
        Id = "nomic-embed-text-v1.5",
        Name = "Nomic Embed Text v1.5",
        Description = "High-quality embedding model optimized for code and technical content",
        Type = EmbeddingModelType.Gguf,
        Dimension = 768,
        MaxTokens = 8192,
        IsDefault = true,
        SupportsGpu = true,
        UseCases = new[] { "Code Search", "Documentation", "General Text" },
        TextPrefix = "search_document: "
    };

    /// <summary>
    /// All-MiniLM-L6-v2 - Fast and lightweight.
    /// Best for: Speed-critical applications with limited memory.
    /// </summary>
    public static EmbeddingModelInfo AllMiniLmL6V2 => new()
    {
        Id = "all-minilm-l6-v2",
        Name = "All-MiniLM-L6-v2",
        Description = "Lightweight model for fast embedding generation",
        Type = EmbeddingModelType.Onnx,
        Dimension = 384,
        MaxTokens = 512,
        IsDefault = false,
        SupportsGpu = true,
        UseCases = new[] { "Fast Search", "Low Memory" }
    };

    /// <summary>
    /// BGE-Small-EN - Good balance of quality and speed.
    /// Best for: Code search with moderate resource usage.
    /// </summary>
    public static EmbeddingModelInfo BgeSmallEn => new()
    {
        Id = "bge-small-en-v1.5",
        Name = "BGE Small EN v1.5",
        Description = "Balanced model from BAAI with good code understanding",
        Type = EmbeddingModelType.Onnx,
        Dimension = 384,
        MaxTokens = 512,
        IsDefault = false,
        SupportsGpu = true,
        UseCases = new[] { "Code Search", "Semantic Search" }
    };

    /// <summary>
    /// CodeBERT - Specialized for code.
    /// Best for: Pure code search and code-to-code similarity.
    /// </summary>
    public static EmbeddingModelInfo CodeBert => new()
    {
        Id = "codebert-base",
        Name = "CodeBERT Base",
        Description = "Microsoft's model trained specifically on code",
        Type = EmbeddingModelType.Onnx,
        Dimension = 768,
        MaxTokens = 512,
        IsDefault = false,
        SupportsGpu = true,
        UseCases = new[] { "Code Search", "Code Understanding" }
    };
}
```

---

### 4. IEmbeddingModelRegistry.cs

**Location**: `src/AIntern.Core/Interfaces/IEmbeddingModelRegistry.cs`
**Type**: `interface`
**Purpose**: Registry for managing available embedding models

```csharp
namespace AIntern.Core.Interfaces;

using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using AIntern.Core.Models;

/// <summary>
/// Registry for managing available embedding models.
/// Provides discovery, registration, and querying of embedding model configurations.
/// </summary>
public interface IEmbeddingModelRegistry
{
    /// <summary>
    /// Get all available embedding models.
    /// Includes both preset models and user-registered models.
    /// </summary>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of available model configurations.</returns>
    Task<IReadOnlyList<EmbeddingModelInfo>> GetAvailableModelsAsync(
        CancellationToken ct = default);

    /// <summary>
    /// Get a specific model by ID.
    /// </summary>
    /// <param name="modelId">The model identifier.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Model info if found, null otherwise.</returns>
    Task<EmbeddingModelInfo?> GetModelAsync(
        string modelId,
        CancellationToken ct = default);

    /// <summary>
    /// Get the default/recommended embedding model.
    /// </summary>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Default model info, or null if no default is configured.</returns>
    Task<EmbeddingModelInfo?> GetDefaultModelAsync(
        CancellationToken ct = default);

    /// <summary>
    /// Check if a model file exists at the expected path.
    /// </summary>
    /// <param name="modelId">The model identifier.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>True if the model file exists and is accessible.</returns>
    Task<bool> IsModelDownloadedAsync(
        string modelId,
        CancellationToken ct = default);

    /// <summary>
    /// Register a custom embedding model.
    /// </summary>
    /// <param name="model">Model configuration to register.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <exception cref="ArgumentException">
    /// Thrown when a model with the same ID already exists.
    /// </exception>
    Task RegisterModelAsync(
        EmbeddingModelInfo model,
        CancellationToken ct = default);

    /// <summary>
    /// Unregister a custom model.
    /// Cannot unregister preset models.
    /// </summary>
    /// <param name="modelId">The model identifier to remove.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>True if the model was unregistered, false if not found.</returns>
    Task<bool> UnregisterModelAsync(
        string modelId,
        CancellationToken ct = default);

    /// <summary>
    /// Scan a directory for embedding model files.
    /// Detects GGUF and ONNX models based on file extension.
    /// </summary>
    /// <param name="directory">Directory path to scan.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of discovered model configurations.</returns>
    /// <exception cref="DirectoryNotFoundException">
    /// Thrown when the directory does not exist.
    /// </exception>
    Task<IReadOnlyList<EmbeddingModelInfo>> ScanDirectoryAsync(
        string directory,
        CancellationToken ct = default);
}
```

---

## File Summary

### Files to Create

| File | Location | Purpose |
|------|----------|---------|
| `IEmbeddingService.cs` | `src/AIntern.Core/Interfaces/` | Core embedding service contract |
| `EmbeddingModels.cs` | `src/AIntern.Core/Models/` | Options, enums, and progress models |
| `EmbeddingModelInfo.cs` | `src/AIntern.Core/Models/` | Model metadata and presets |
| `IEmbeddingModelRegistry.cs` | `src/AIntern.Core/Interfaces/` | Model registry interface |

### Directory Structure

```
src/AIntern.Core/
├── Interfaces/
│   ├── IEmbeddingService.cs         (NEW - v0.7.1a)
│   └── IEmbeddingModelRegistry.cs   (NEW - v0.7.1a)
└── Models/
    ├── EmbeddingModels.cs           (NEW - v0.7.1a)
    └── EmbeddingModelInfo.cs        (NEW - v0.7.1a)
```

---

## Usage Examples

### Basic Embedding Generation

```csharp
// Inject IEmbeddingService via DI
public class CodeSearchService
{
    private readonly IEmbeddingService _embedding;

    public CodeSearchService(IEmbeddingService embedding)
    {
        _embedding = embedding;
    }

    public async Task InitializeAsync(CancellationToken ct)
    {
        // Load the default embedding model
        var options = new EmbeddingModelOptions
        {
            ModelPath = "/models/nomic-embed-text-v1.5.Q8_0.gguf",
            ModelName = "Nomic Embed Text",
            ModelType = EmbeddingModelType.Gguf,
            GpuLayers = -1,  // Auto-detect
            ContextSize = 8192,
            NormalizeEmbeddings = true,
            TextPrefix = "search_document: "
        };

        await _embedding.LoadModelAsync(options, progress: null, ct);
    }

    public async Task<float[]> EmbedQueryAsync(string query, CancellationToken ct)
    {
        // Single embedding for search query
        return await _embedding.EmbedAsync(query, ct);
    }
}
```

### Batch Embedding with Progress

```csharp
public async Task IndexDocumentsAsync(
    IEnumerable<string> documents,
    IProgress<EmbeddingProgress> progress,
    CancellationToken ct)
{
    // Generate embeddings for all documents
    var embeddings = await _embedding.EmbedBatchAsync(
        documents,
        progress,
        ct);

    // Store in vector database
    for (int i = 0; i < embeddings.Count; i++)
    {
        await _vectorDb.StoreAsync(documents.ElementAt(i), embeddings[i], ct);
    }
}
```

### Similarity Search

```csharp
public async Task<IEnumerable<SearchResult>> SearchAsync(
    string query,
    float[] queryEmbedding,
    IEnumerable<(string Text, float[] Embedding)> candidates,
    int topK = 10)
{
    var results = candidates
        .Select(c => new SearchResult
        {
            Text = c.Text,
            Score = _embedding.CosineSimilarity(queryEmbedding, c.Embedding)
        })
        .OrderByDescending(r => r.Score)
        .Take(topK);

    return results;
}
```

### Model Registry Usage

```csharp
public async Task<EmbeddingModelInfo> SelectModelAsync(
    IEmbeddingModelRegistry registry,
    CancellationToken ct)
{
    // List all available models
    var models = await registry.GetAvailableModelsAsync(ct);

    foreach (var model in models)
    {
        Console.WriteLine($"{model.Name} ({model.SizeDisplay})");
        Console.WriteLine($"  Type: {model.Type}, Dimension: {model.Dimension}");
        Console.WriteLine($"  Downloaded: {await registry.IsModelDownloadedAsync(model.Id, ct)}");
    }

    // Get the default model
    return await registry.GetDefaultModelAsync(ct)
        ?? throw new InvalidOperationException("No default model configured");
}
```

---

## Verification Steps

### 1. Build Verification

```bash
# Verify Core project builds with new interfaces
dotnet build src/AIntern.Core
```

### 2. Unit Test Suggestions

```csharp
// EmbeddingModelOptions tests
[Fact]
public void EmbeddingModelOptions_DefaultValues_AreCorrect()
{
    var options = new EmbeddingModelOptions();

    Assert.Equal(EmbeddingModelType.Auto, options.ModelType);
    Assert.Equal(-1, options.GpuLayers);
    Assert.Equal(512, options.ContextSize);
    Assert.Equal(32, options.BatchSize);
    Assert.True(options.NormalizeEmbeddings);
    Assert.Equal(EmbeddingPoolingType.Mean, options.PoolingType);
}

// EmbeddingModelInfo tests
[Fact]
public void EmbeddingModelInfo_SizeDisplay_FormatsCorrectly()
{
    var smallModel = new EmbeddingModelInfo { SizeBytes = 500 };
    Assert.Equal("500 B", smallModel.SizeDisplay);

    var mediumModel = new EmbeddingModelInfo { SizeBytes = 80 * 1024 * 1024 };
    Assert.Equal("80.0 MB", mediumModel.SizeDisplay);

    var largeModel = new EmbeddingModelInfo { SizeBytes = 2L * 1024 * 1024 * 1024 };
    Assert.Equal("2.00 GB", largeModel.SizeDisplay);
}

// EmbeddingProgress tests
[Fact]
public void EmbeddingProgress_PercentComplete_CalculatesCorrectly()
{
    var progress = new EmbeddingProgress
    {
        ProcessedCount = 50,
        TotalCount = 200
    };

    Assert.Equal(25.0, progress.PercentComplete);
}

[Fact]
public void EmbeddingProgress_PercentComplete_HandlesZeroTotal()
{
    var progress = new EmbeddingProgress
    {
        ProcessedCount = 0,
        TotalCount = 0
    };

    Assert.Equal(0, progress.PercentComplete);
}

// EmbeddingModelPresets tests
[Fact]
public void EmbeddingModelPresets_NomicEmbedText_IsDefault()
{
    var preset = EmbeddingModelPresets.NomicEmbedText;

    Assert.True(preset.IsDefault);
    Assert.Equal(768, preset.Dimension);
    Assert.Equal(8192, preset.MaxTokens);
    Assert.Equal(EmbeddingModelType.Gguf, preset.Type);
}

[Fact]
public void EmbeddingModelPresets_AllModels_HaveValidConfiguration()
{
    var presets = new[]
    {
        EmbeddingModelPresets.NomicEmbedText,
        EmbeddingModelPresets.AllMiniLmL6V2,
        EmbeddingModelPresets.BgeSmallEn,
        EmbeddingModelPresets.CodeBert
    };

    foreach (var preset in presets)
    {
        Assert.NotEmpty(preset.Id);
        Assert.NotEmpty(preset.Name);
        Assert.True(preset.Dimension > 0);
        Assert.True(preset.MaxTokens > 0);
        Assert.NotEmpty(preset.UseCases);
    }
}
```

---

## Integration Notes

### Usage in v0.7.1b (LLamaSharp Implementation)

The `IEmbeddingService` interface will be implemented by `LlamaEmbeddingService` which:
- Loads GGUF models via `LLamaWeights.LoadFromFile`
- Creates `LLamaEmbedder` for embedding generation
- Implements SIMD-accelerated `CosineSimilarity` and `NormalizeEmbedding`
- Uses semaphores for thread-safe model access

### Usage in v0.7.1c (ONNX Implementation)

A separate `OnnxEmbeddingService` will implement `IEmbeddingService` for ONNX models:
- Uses ONNX Runtime's `InferenceSession`
- Supports DirectML (Windows), CoreML (macOS), CUDA execution providers
- Includes built-in tokenizer support

### Dependency Injection Registration

```csharp
// In DI container setup
services.AddSingleton<IEmbeddingModelRegistry, EmbeddingModelRegistry>();
services.AddSingleton<IEmbeddingService, LlamaEmbeddingService>();
// Or for ONNX:
// services.AddSingleton<IEmbeddingService, OnnxEmbeddingService>();
```

---

## Acceptance Criteria

- [ ] `IEmbeddingService` interface defined with all properties and methods
- [ ] `EmbeddingModelOptions` supports all configuration options
- [ ] `EmbeddingModelType` enum covers Auto, Gguf, Onnx, and SentenceTransformers
- [ ] `EmbeddingPoolingType` includes Mean, Cls, Last, Max
- [ ] `ModelLoadProgress` and `EmbeddingProgress` classes defined
- [ ] `EmbeddingModelStateChangedEventArgs` for event notifications
- [ ] `EmbeddingModelInfo` with all metadata properties
- [ ] `EmbeddingModelPresets` with four preset configurations
- [ ] `IEmbeddingModelRegistry` interface for model management
- [ ] All classes have comprehensive XML documentation comments
- [ ] Build succeeds with no warnings

---

## Changelog Entry

```markdown
## v0.7.1a - Embedding Service Interface

### Added
- `IEmbeddingService` interface for text embedding generation
  - Model lifecycle management (LoadModelAsync, UnloadModelAsync)
  - Single and batch embedding generation (EmbedAsync, EmbedBatchAsync)
  - SIMD-accelerated vector operations (CosineSimilarity, NormalizeEmbedding)
  - Model state change notifications (ModelStateChanged event)
- `EmbeddingModelOptions` configuration class
  - Model path and type selection
  - Hardware configuration (GPU layers, threads, memory mapping)
  - Inference configuration (context size, batch size, pooling, normalization)
  - Text prefix support for asymmetric models
- `EmbeddingModelType` enumeration (Auto, Gguf, Onnx, SentenceTransformers)
- `EmbeddingPoolingType` enumeration (Mean, Cls, Last, Max)
- Progress reporting models (ModelLoadProgress, EmbeddingProgress)
- `EmbeddingModelStateChangedEventArgs` for event notifications
- `EmbeddingModelInfo` model metadata class
  - Identity, technical specs, and capability properties
  - Human-readable size display
- `EmbeddingModelPresets` static class with preset configurations
  - NomicEmbedText (768d, 8K ctx, GGUF, default)
  - AllMiniLmL6V2 (384d, 512 ctx, ONNX)
  - BgeSmallEn (384d, 512 ctx, ONNX)
  - CodeBert (768d, 512 ctx, ONNX)
- `IEmbeddingModelRegistry` interface for model management
  - Query methods (GetAvailableModelsAsync, GetModelAsync, GetDefaultModelAsync)
  - Model existence check (IsModelDownloadedAsync)
  - Registration methods (RegisterModelAsync, UnregisterModelAsync)
  - Directory scanning (ScanDirectoryAsync)

### Files Created
- `src/AIntern.Core/Interfaces/IEmbeddingService.cs`
- `src/AIntern.Core/Interfaces/IEmbeddingModelRegistry.cs`
- `src/AIntern.Core/Models/EmbeddingModels.cs`
- `src/AIntern.Core/Models/EmbeddingModelInfo.cs`
```
