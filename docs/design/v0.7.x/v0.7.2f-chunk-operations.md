# Design Specification: AIntern v0.7.2f "Chunk Operations"

## Overview

**Version**: v0.7.2f
**Parent**: v0.7.2 Vector Storage
**Focus**: Implement chunk CRUD operations including adding, retrieving, and removing chunks

### Purpose

Implement the core chunk storage and retrieval operations:
1. Implement `AddChunksAsync` and `AddChunksBatchAsync` with progress reporting
2. Implement `GetChunkAsync` with optional embedding retrieval
3. Implement `RemoveChunksForFileAsync` and `RemoveChunksForFilesAsync`
4. Implement `ClearIndexAsync` for full index reset
5. Provide embedding serialization utilities

### Dependencies

**From v0.7.2a (Vector Store Interface)**:
- `ChunkWithEmbedding` model for storage input
- `StoredChunk` model for retrieval
- `ChunkStorageProgress` for progress reporting
- `ChunkStoragePhase` enum for phases

**From v0.7.2b (Vector Index Models)**:
- `IndexedFile` for file tracking
- `FileIndexStatus` for status tracking

**From v0.7.2e (Store Implementation)**:
- `SqliteVectorStore` partial class to extend
- `SanitizeTableName()` utility
- `_writeLock` for thread safety

**From v0.7.1d (Text Chunk Models)**:
- `TextChunk` model (embedded in ChunkWithEmbedding)
- `ChunkType` enum
- `SymbolType` enum

---

## Architecture

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                         v0.7.2f Chunk Operations                              │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  SqliteVectorStore.ChunkOperations.cs (partial class extension)              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                                                                          │ │
│  │  Add Operations:                                                          │ │
│  │  ├── AddChunksAsync()               ← Simple add, no progress            │ │
│  │  ├── AddChunksBatchAsync()          ← Batch add with progress            │ │
│  │  ├── InsertVectorAsync()            ← Private: insert into vectors_*    │ │
│  │  └── InsertChunkMetadataAsync()     ← Private: insert into chunk_metadata│ │
│  │                                                                          │ │
│  │  Get Operations:                                                          │ │
│  │  ├── GetChunkAsync()                ← Get chunk by ID                    │ │
│  │  ├── GetEmbeddingAsync()            ← Private: get embedding from vectors│ │
│  │  └── GetChunksForFileAsync()        ← Get all chunks for a file         │ │
│  │                                                                          │ │
│  │  Remove Operations:                                                       │ │
│  │  ├── RemoveChunksForFileAsync()     ← Remove chunks for single file     │ │
│  │  ├── RemoveChunksForFilesAsync()    ← Remove chunks for multiple files  │ │
│  │  └── ClearIndexAsync()              ← Remove all chunks from index      │ │
│  │                                                                          │ │
│  │  Utilities:                                                               │ │
│  │  ├── ReadStoredChunkFromReader()    ← SqliteDataReader → StoredChunk    │ │
│  │  ├── EmbeddingToBlob()              ← float[] → byte[]                  │ │
│  │  └── BlobToEmbedding()              ← byte[] → float[]                  │ │
│  │                                                                          │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Batch Insert Flow

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                        AddChunksBatchAsync Flow                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  Input: IEnumerable<ChunkWithEmbedding> chunks                               │
│       │                                                                      │
│       ▼                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase: Preparing                                                        │ │
│  │  • Materialize to List                                                   │ │
│  │  • Calculate batch count                                                 │ │
│  │  • Report initial progress                                               │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│       │                                                                      │
│       ▼                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Acquire _writeLock                                                      │ │
│  │  Begin Transaction                                                       │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│       │                                                                      │
│       ▼                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  For each batch (BulkInsertBatchSize chunks):                            │ │
│  │                                                                          │ │
│  │    Phase: InsertingVectors                                               │ │
│  │    ├── ct.ThrowIfCancellationRequested()                                │ │
│  │    ├── Report progress                                                   │ │
│  │    └── For each chunk in batch:                                          │ │
│  │        └── InsertVectorAsync(sanitizedId, chunkId, embedding, tx)       │ │
│  │                                                                          │ │
│  │    Phase: InsertingMetadata                                              │ │
│  │    ├── Report progress                                                   │ │
│  │    └── For each chunk in batch:                                          │ │
│  │        └── InsertChunkMetadataAsync(indexId, chunk, tx)                 │ │
│  │                                                                          │ │
│  │    processedCount += batch.Length                                        │ │
│  │                                                                          │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│       │                                                                      │
│       ▼                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase: Committing                                                       │ │
│  │  • Update vector_indexes.chunk_count += totalChunks                      │ │
│  │  • Update vector_indexes.updated_at                                      │ │
│  │  • Commit transaction                                                    │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│       │                                                                      │
│       ▼                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase: Complete                                                         │ │
│  │  • Report final progress (StoredCount = TotalCount)                      │ │
│  │  • Release _writeLock                                                    │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  Error Handling:                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  On any exception:                                                        │ │
│  │  • Rollback transaction                                                  │ │
│  │  • Release _writeLock (in finally)                                       │ │
│  │  • Re-throw                                                              │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Embedding Serialization

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                       Embedding Serialization                                 │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  EmbeddingToBlob() - float[] → byte[]                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                                                                          │ │
│  │  float[] embedding = [0.123f, 0.456f, 0.789f, ...]                       │ │
│  │                                                                          │ │
│  │  // Calculate byte array size                                            │ │
│  │  int byteLength = embedding.Length * sizeof(float); // 4 bytes per float │ │
│  │                                                                          │ │
│  │  // Direct memory copy                                                   │ │
│  │  byte[] bytes = new byte[byteLength];                                    │ │
│  │  Buffer.BlockCopy(embedding, 0, bytes, 0, byteLength);                   │ │
│  │                                                                          │ │
│  │  // Example: 384-dim embedding → 1536 bytes                              │ │
│  │  //          768-dim embedding → 3072 bytes                              │ │
│  │                                                                          │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  BlobToEmbedding() - byte[] → float[]                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                                                                          │ │
│  │  byte[] blob = [0x3E, 0x00, 0x00, 0x00, ...]                             │ │
│  │                                                                          │ │
│  │  // Calculate float array size                                           │ │
│  │  int floatCount = blob.Length / sizeof(float);                           │ │
│  │                                                                          │ │
│  │  // Direct memory copy                                                   │ │
│  │  float[] embedding = new float[floatCount];                              │ │
│  │  Buffer.BlockCopy(blob, 0, embedding, 0, blob.Length);                   │ │
│  │                                                                          │ │
│  │  return embedding;                                                        │ │
│  │                                                                          │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  Notes:                                                                       │
│  • Buffer.BlockCopy is the fastest method for array-to-array copy           │
│  • No endianness conversion needed (stored and retrieved on same platform)  │
│  • sqlite-vec expects raw binary data for FLOAT[n] columns                  │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## File Specification

### SqliteVectorStore.ChunkOperations.cs

**Location**: `src/SeniorIntern.Services/VectorStore/SqliteVectorStore.ChunkOperations.cs`

```csharp
namespace SeniorIntern.Services.VectorStore;

using System;
using System.Buffers;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Data.Sqlite;
using SeniorIntern.Core.Models;

/// <summary>
/// Partial class containing chunk CRUD operations.
/// </summary>
public sealed partial class SqliteVectorStore
{
    #region Add Operations

    /// <inheritdoc />
    public async Task AddChunksAsync(
        string indexId,
        IEnumerable<ChunkWithEmbedding> chunks,
        CancellationToken ct = default)
    {
        await AddChunksBatchAsync(indexId, chunks, null, ct);
    }

    /// <inheritdoc />
    public async Task AddChunksBatchAsync(
        string indexId,
        IEnumerable<ChunkWithEmbedding> chunks,
        IProgress<ChunkStorageProgress>? progress = null,
        CancellationToken ct = default)
    {
        EnsureInitialized();

        if (string.IsNullOrWhiteSpace(indexId))
            throw new ArgumentException("Index ID is required", nameof(indexId));

        var chunkList = chunks?.ToList() ?? throw new ArgumentNullException(nameof(chunks));
        if (chunkList.Count == 0)
        {
            _logger.LogDebug("No chunks to add to index {IndexId}", indexId);
            return;
        }

        var sanitizedId = SanitizeTableName(indexId);
        var batchSize = _options.BulkInsertBatchSize;
        var totalChunks = chunkList.Count;
        var processedCount = 0;

        _logger.LogDebug(
            "Adding {Count} chunks to index {IndexId} in batches of {BatchSize}",
            totalChunks, indexId, batchSize);

        // Report initial progress
        progress?.Report(new ChunkStorageProgress
        {
            Phase = ChunkStoragePhase.Preparing,
            StoredCount = 0,
            TotalCount = totalChunks,
            Message = $"Preparing to store {totalChunks} chunks"
        });

        await _writeLock.WaitAsync(ct);
        try
        {
            await using var transaction = await _connection!.BeginTransactionAsync(ct);
            try
            {
                // Process in batches
                var batchNumber = 0;
                foreach (var batch in chunkList.Chunk(batchSize))
                {
                    ct.ThrowIfCancellationRequested();
                    batchNumber++;

                    // Insert vectors phase
                    progress?.Report(new ChunkStorageProgress
                    {
                        Phase = ChunkStoragePhase.InsertingVectors,
                        StoredCount = processedCount,
                        TotalCount = totalChunks,
                        Message = $"Inserting vectors (batch {batchNumber})"
                    });

                    foreach (var chunk in batch)
                    {
                        await InsertVectorAsync(
                            sanitizedId,
                            chunk.Chunk.Id.ToString(),
                            chunk.Embedding,
                            (SqliteTransaction)transaction,
                            ct);
                    }

                    // Insert metadata phase
                    progress?.Report(new ChunkStorageProgress
                    {
                        Phase = ChunkStoragePhase.InsertingMetadata,
                        StoredCount = processedCount,
                        TotalCount = totalChunks,
                        Message = $"Inserting metadata (batch {batchNumber})"
                    });

                    foreach (var chunk in batch)
                    {
                        await InsertChunkMetadataAsync(
                            indexId,
                            chunk,
                            (SqliteTransaction)transaction,
                            ct);
                    }

                    processedCount += batch.Length;
                }

                // Committing phase
                progress?.Report(new ChunkStorageProgress
                {
                    Phase = ChunkStoragePhase.Committing,
                    StoredCount = processedCount,
                    TotalCount = totalChunks,
                    Message = "Committing transaction"
                });

                // Update index chunk count
                await UpdateIndexChunkCountAsync(
                    indexId,
                    totalChunks,
                    (SqliteTransaction)transaction,
                    ct);

                await transaction.CommitAsync(ct);

                // Complete phase
                progress?.Report(new ChunkStorageProgress
                {
                    Phase = ChunkStoragePhase.Complete,
                    StoredCount = totalChunks,
                    TotalCount = totalChunks,
                    Message = $"Successfully stored {totalChunks} chunks"
                });

                _logger.LogInformation(
                    "Added {Count} chunks to index {IndexId}",
                    totalChunks, indexId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to add chunks to index {IndexId}", indexId);
                await transaction.RollbackAsync(ct);
                throw;
            }
        }
        finally
        {
            _writeLock.Release();
        }
    }

    /// <summary>
    /// Inserts a single vector into the vector table.
    /// </summary>
    private async Task InsertVectorAsync(
        string sanitizedIndexId,
        string chunkId,
        float[] embedding,
        SqliteTransaction transaction,
        CancellationToken ct)
    {
        await using var cmd = _connection!.CreateCommand();
        cmd.Transaction = transaction;
        cmd.CommandText = $"INSERT INTO vectors_{sanitizedIndexId} (id, embedding) VALUES (@id, @embedding)";
        cmd.Parameters.AddWithValue("@id", chunkId);
        cmd.Parameters.AddWithValue("@embedding", EmbeddingToBlob(embedding));
        await cmd.ExecuteNonQueryAsync(ct);
    }

    /// <summary>
    /// Inserts chunk metadata into the metadata table.
    /// </summary>
    private async Task InsertChunkMetadataAsync(
        string indexId,
        ChunkWithEmbedding chunk,
        SqliteTransaction transaction,
        CancellationToken ct)
    {
        await using var cmd = _connection!.CreateCommand();
        cmd.Transaction = transaction;
        cmd.CommandText = """
            INSERT INTO chunk_metadata (
                id, index_id, file_id, content, start_line, end_line,
                start_offset, end_offset, chunk_type, language,
                symbol_name, symbol_type, parent_symbol, token_count
            ) VALUES (
                @id, @indexId, @fileId, @content, @startLine, @endLine,
                @startOffset, @endOffset, @chunkType, @language,
                @symbolName, @symbolType, @parentSymbol, @tokenCount
            )
            """;

        cmd.Parameters.AddWithValue("@id", chunk.Chunk.Id.ToString());
        cmd.Parameters.AddWithValue("@indexId", indexId);
        cmd.Parameters.AddWithValue("@fileId", chunk.FileId);
        cmd.Parameters.AddWithValue("@content", chunk.Chunk.Content);
        cmd.Parameters.AddWithValue("@startLine", chunk.Chunk.StartLine);
        cmd.Parameters.AddWithValue("@endLine", chunk.Chunk.EndLine);
        cmd.Parameters.AddWithValue("@startOffset", chunk.Chunk.StartOffset);
        cmd.Parameters.AddWithValue("@endOffset", chunk.Chunk.EndOffset);
        cmd.Parameters.AddWithValue("@chunkType", chunk.Chunk.Type.ToString());
        cmd.Parameters.AddWithValue("@language", (object?)chunk.Chunk.Language ?? DBNull.Value);
        cmd.Parameters.AddWithValue("@symbolName", (object?)chunk.Chunk.SymbolName ?? DBNull.Value);
        cmd.Parameters.AddWithValue("@symbolType",
            chunk.Chunk.SymbolType?.ToString() ?? (object)DBNull.Value);
        cmd.Parameters.AddWithValue("@parentSymbol", (object?)chunk.Chunk.ParentSymbol ?? DBNull.Value);
        cmd.Parameters.AddWithValue("@tokenCount", chunk.Chunk.TokenCount);

        await cmd.ExecuteNonQueryAsync(ct);
    }

    /// <summary>
    /// Updates the chunk count for an index.
    /// </summary>
    private async Task UpdateIndexChunkCountAsync(
        string indexId,
        int delta,
        SqliteTransaction transaction,
        CancellationToken ct)
    {
        await using var cmd = _connection!.CreateCommand();
        cmd.Transaction = transaction;
        cmd.CommandText = """
            UPDATE vector_indexes SET
                chunk_count = chunk_count + @count,
                updated_at = datetime('now')
            WHERE id = @id
            """;
        cmd.Parameters.AddWithValue("@count", delta);
        cmd.Parameters.AddWithValue("@id", indexId);
        await cmd.ExecuteNonQueryAsync(ct);
    }

    #endregion

    #region Get Operations

    /// <inheritdoc />
    public async Task<StoredChunk?> GetChunkAsync(
        string chunkId,
        bool includeEmbedding = false,
        CancellationToken ct = default)
    {
        EnsureInitialized();

        if (string.IsNullOrWhiteSpace(chunkId))
            throw new ArgumentException("Chunk ID is required", nameof(chunkId));

        await using var cmd = _connection!.CreateCommand();
        cmd.CommandText = """
            SELECT cm.id, cm.index_id, cm.file_id, cm.content, cm.start_line, cm.end_line,
                   cm.start_offset, cm.end_offset, cm.chunk_type, cm.language,
                   cm.symbol_name, cm.symbol_type, cm.parent_symbol, cm.token_count,
                   cm.indexed_at, if.file_path
            FROM chunk_metadata cm
            JOIN indexed_files if ON cm.file_id = if.id
            WHERE cm.id = @id
            """;
        cmd.Parameters.AddWithValue("@id", chunkId);

        await using var reader = await cmd.ExecuteReaderAsync(ct);
        if (!await reader.ReadAsync(ct))
        {
            _logger.LogDebug("Chunk not found: {ChunkId}", chunkId);
            return null;
        }

        var chunk = ReadStoredChunkFromReader(reader);

        // Optionally fetch embedding
        if (includeEmbedding)
        {
            var embedding = await GetEmbeddingAsync(chunk.IndexId, chunkId, ct);
            chunk = chunk with { Embedding = embedding };
        }

        return chunk;
    }

    /// <summary>
    /// Gets all chunks for a specific file.
    /// </summary>
    /// <param name="indexId">Index ID.</param>
    /// <param name="filePath">Relative file path.</param>
    /// <param name="includeEmbeddings">Whether to include embeddings.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of stored chunks.</returns>
    public async Task<IReadOnlyList<StoredChunk>> GetChunksForFileAsync(
        string indexId,
        string filePath,
        bool includeEmbeddings = false,
        CancellationToken ct = default)
    {
        EnsureInitialized();

        var chunks = new List<StoredChunk>();

        await using var cmd = _connection!.CreateCommand();
        cmd.CommandText = """
            SELECT cm.id, cm.index_id, cm.file_id, cm.content, cm.start_line, cm.end_line,
                   cm.start_offset, cm.end_offset, cm.chunk_type, cm.language,
                   cm.symbol_name, cm.symbol_type, cm.parent_symbol, cm.token_count,
                   cm.indexed_at, if.file_path
            FROM chunk_metadata cm
            JOIN indexed_files if ON cm.file_id = if.id
            WHERE cm.index_id = @indexId AND if.file_path = @filePath
            ORDER BY cm.start_line
            """;
        cmd.Parameters.AddWithValue("@indexId", indexId);
        cmd.Parameters.AddWithValue("@filePath", filePath);

        await using var reader = await cmd.ExecuteReaderAsync(ct);
        while (await reader.ReadAsync(ct))
        {
            var chunk = ReadStoredChunkFromReader(reader);
            
            if (includeEmbeddings)
            {
                var embedding = await GetEmbeddingAsync(indexId, chunk.Id, ct);
                chunk = chunk with { Embedding = embedding };
            }
            
            chunks.Add(chunk);
        }

        return chunks;
    }

    /// <summary>
    /// Gets the embedding for a specific chunk.
    /// </summary>
    private async Task<float[]?> GetEmbeddingAsync(
        string indexId,
        string chunkId,
        CancellationToken ct)
    {
        var sanitizedId = SanitizeTableName(indexId);

        await using var cmd = _connection!.CreateCommand();
        cmd.CommandText = $"SELECT embedding FROM vectors_{sanitizedId} WHERE id = @id";
        cmd.Parameters.AddWithValue("@id", chunkId);

        var result = await cmd.ExecuteScalarAsync(ct);
        if (result is byte[] blob)
            return BlobToEmbedding(blob);

        return null;
    }

    #endregion

    #region Remove Operations

    /// <inheritdoc />
    public async Task<int> RemoveChunksForFileAsync(
        string indexId,
        string filePath,
        CancellationToken ct = default)
    {
        return await RemoveChunksForFilesAsync(indexId, [filePath], ct);
    }

    /// <inheritdoc />
    public async Task<int> RemoveChunksForFilesAsync(
        string indexId,
        IEnumerable<string> filePaths,
        CancellationToken ct = default)
    {
        EnsureInitialized();

        if (string.IsNullOrWhiteSpace(indexId))
            throw new ArgumentException("Index ID is required", nameof(indexId));

        var filePathList = filePaths?.ToList() ?? throw new ArgumentNullException(nameof(filePaths));
        if (filePathList.Count == 0) return 0;

        var sanitizedId = SanitizeTableName(indexId);
        var totalRemoved = 0;

        _logger.LogDebug(
            "Removing chunks for {FileCount} files from index {IndexId}",
            filePathList.Count, indexId);

        await _writeLock.WaitAsync(ct);
        try
        {
            await using var transaction = await _connection!.BeginTransactionAsync(ct);
            try
            {
                foreach (var filePath in filePathList)
                {
                    // Get chunk IDs for this file
                    var chunkIds = new List<string>();

                    await using (var cmd = _connection.CreateCommand())
                    {
                        cmd.Transaction = (SqliteTransaction)transaction;
                        cmd.CommandText = """
                            SELECT cm.id FROM chunk_metadata cm
                            JOIN indexed_files if ON cm.file_id = if.id
                            WHERE if.index_id = @indexId AND if.file_path = @filePath
                            """;
                        cmd.Parameters.AddWithValue("@indexId", indexId);
                        cmd.Parameters.AddWithValue("@filePath", filePath);

                        await using var reader = await cmd.ExecuteReaderAsync(ct);
                        while (await reader.ReadAsync(ct))
                        {
                            chunkIds.Add(reader.GetString(0));
                        }
                    }

                    if (chunkIds.Count == 0)
                    {
                        _logger.LogDebug(
                            "No chunks found for file {FilePath} in index {IndexId}",
                            filePath, indexId);
                        continue;
                    }

                    // Remove vectors
                    foreach (var chunkId in chunkIds)
                    {
                        await using var cmd = _connection.CreateCommand();
                        cmd.Transaction = (SqliteTransaction)transaction;
                        cmd.CommandText = $"DELETE FROM vectors_{sanitizedId} WHERE id = @id";
                        cmd.Parameters.AddWithValue("@id", chunkId);
                        await cmd.ExecuteNonQueryAsync(ct);
                    }

                    // Remove chunk metadata (file deletion will cascade via FK)
                    await using (var cmd = _connection.CreateCommand())
                    {
                        cmd.Transaction = (SqliteTransaction)transaction;
                        cmd.CommandText = """
                            DELETE FROM chunk_metadata
                            WHERE index_id = @indexId AND file_id IN (
                                SELECT id FROM indexed_files
                                WHERE index_id = @indexId AND file_path = @filePath
                            )
                            """;
                        cmd.Parameters.AddWithValue("@indexId", indexId);
                        cmd.Parameters.AddWithValue("@filePath", filePath);
                        await cmd.ExecuteNonQueryAsync(ct);
                    }

                    totalRemoved += chunkIds.Count;
                    _logger.LogDebug(
                        "Removed {Count} chunks for file {FilePath}",
                        chunkIds.Count, filePath);
                }

                // Update index counts
                if (totalRemoved > 0)
                {
                    await using var cmd = _connection.CreateCommand();
                    cmd.Transaction = (SqliteTransaction)transaction;
                    cmd.CommandText = """
                        UPDATE vector_indexes SET
                            chunk_count = chunk_count - @count,
                            updated_at = datetime('now')
                        WHERE id = @id
                        """;
                    cmd.Parameters.AddWithValue("@count", totalRemoved);
                    cmd.Parameters.AddWithValue("@id", indexId);
                    await cmd.ExecuteNonQueryAsync(ct);
                }

                await transaction.CommitAsync(ct);

                _logger.LogInformation(
                    "Removed {Count} chunks for {FileCount} files from index {IndexId}",
                    totalRemoved, filePathList.Count, indexId);

                return totalRemoved;
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to remove chunks from index {IndexId}", indexId);
                await transaction.RollbackAsync(ct);
                throw;
            }
        }
        finally
        {
            _writeLock.Release();
        }
    }

    /// <inheritdoc />
    public async Task ClearIndexAsync(string indexId, CancellationToken ct = default)
    {
        EnsureInitialized();

        if (string.IsNullOrWhiteSpace(indexId))
            throw new ArgumentException("Index ID is required", nameof(indexId));

        var sanitizedId = SanitizeTableName(indexId);

        _logger.LogWarning("Clearing all chunks from index {IndexId}", indexId);

        await _writeLock.WaitAsync(ct);
        try
        {
            await using var transaction = await _connection!.BeginTransactionAsync(ct);
            try
            {
                // Clear vectors
                await using (var cmd = _connection.CreateCommand())
                {
                    cmd.Transaction = (SqliteTransaction)transaction;
                    cmd.CommandText = $"DELETE FROM vectors_{sanitizedId}";
                    await cmd.ExecuteNonQueryAsync(ct);
                }

                // Clear chunk metadata
                await using (var cmd = _connection.CreateCommand())
                {
                    cmd.Transaction = (SqliteTransaction)transaction;
                    cmd.CommandText = "DELETE FROM chunk_metadata WHERE index_id = @id";
                    cmd.Parameters.AddWithValue("@id", indexId);
                    await cmd.ExecuteNonQueryAsync(ct);
                }

                // Clear indexed files
                await using (var cmd = _connection.CreateCommand())
                {
                    cmd.Transaction = (SqliteTransaction)transaction;
                    cmd.CommandText = "DELETE FROM indexed_files WHERE index_id = @id";
                    cmd.Parameters.AddWithValue("@id", indexId);
                    await cmd.ExecuteNonQueryAsync(ct);
                }

                // Reset index counts
                await using (var cmd = _connection.CreateCommand())
                {
                    cmd.Transaction = (SqliteTransaction)transaction;
                    cmd.CommandText = """
                        UPDATE vector_indexes SET
                            chunk_count = 0,
                            file_count = 0,
                            total_file_size_bytes = 0,
                            updated_at = datetime('now')
                        WHERE id = @id
                        """;
                    cmd.Parameters.AddWithValue("@id", indexId);
                    await cmd.ExecuteNonQueryAsync(ct);
                }

                await transaction.CommitAsync(ct);

                _logger.LogInformation("Cleared all data from index {IndexId}", indexId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to clear index {IndexId}", indexId);
                await transaction.RollbackAsync(ct);
                throw;
            }
        }
        finally
        {
            _writeLock.Release();
        }
    }

    #endregion

    #region Reader Methods

    /// <summary>
    /// Reads a StoredChunk from a SqliteDataReader.
    /// </summary>
    private static StoredChunk ReadStoredChunkFromReader(SqliteDataReader reader)
    {
        return new StoredChunk
        {
            Id = reader.GetString(reader.GetOrdinal("id")),
            IndexId = reader.GetString(reader.GetOrdinal("index_id")),
            FileId = reader.GetString(reader.GetOrdinal("file_id")),
            Content = reader.GetString(reader.GetOrdinal("content")),
            FilePath = reader.GetString(reader.GetOrdinal("file_path")),
            StartLine = reader.GetInt32(reader.GetOrdinal("start_line")),
            EndLine = reader.GetInt32(reader.GetOrdinal("end_line")),
            StartOffset = reader.GetInt32(reader.GetOrdinal("start_offset")),
            EndOffset = reader.GetInt32(reader.GetOrdinal("end_offset")),
            ChunkType = Enum.Parse<ChunkType>(reader.GetString(reader.GetOrdinal("chunk_type"))),
            Language = reader.IsDBNull(reader.GetOrdinal("language"))
                ? null
                : reader.GetString(reader.GetOrdinal("language")),
            SymbolName = reader.IsDBNull(reader.GetOrdinal("symbol_name"))
                ? null
                : reader.GetString(reader.GetOrdinal("symbol_name")),
            SymbolType = reader.IsDBNull(reader.GetOrdinal("symbol_type"))
                ? null
                : Enum.Parse<SymbolType>(reader.GetString(reader.GetOrdinal("symbol_type"))),
            ParentSymbol = reader.IsDBNull(reader.GetOrdinal("parent_symbol"))
                ? null
                : reader.GetString(reader.GetOrdinal("parent_symbol")),
            TokenCount = reader.GetInt32(reader.GetOrdinal("token_count")),
            IndexedAt = DateTime.Parse(reader.GetString(reader.GetOrdinal("indexed_at")))
        };
    }

    #endregion

    #region Embedding Serialization

    /// <summary>
    /// Converts a float array embedding to a byte array for storage.
    /// </summary>
    /// <param name="embedding">The embedding vector.</param>
    /// <returns>Byte array representation.</returns>
    /// <remarks>
    /// Uses Buffer.BlockCopy for high-performance memory copy.
    /// A 384-dim embedding produces 1536 bytes (384 × 4 bytes per float).
    /// </remarks>
    private static byte[] EmbeddingToBlob(float[] embedding)
    {
        var bytes = new byte[embedding.Length * sizeof(float)];
        Buffer.BlockCopy(embedding, 0, bytes, 0, bytes.Length);
        return bytes;
    }

    /// <summary>
    /// Converts a byte array from storage back to a float array embedding.
    /// </summary>
    /// <param name="blob">The stored byte array.</param>
    /// <returns>The reconstructed embedding vector.</returns>
    private static float[] BlobToEmbedding(byte[] blob)
    {
        var embedding = new float[blob.Length / sizeof(float)];
        Buffer.BlockCopy(blob, 0, embedding, 0, blob.Length);
        return embedding;
    }

    #endregion
}
```

---

## Unit Test Plan

| Test | Description |
|------|-------------|
| `AddChunksAsync_EmptyList_DoesNothing` | Empty input handling |
| `AddChunksAsync_SingleChunk_InsertsCorrectly` | Basic insert |
| `AddChunksBatchAsync_MultipleBatches_InsertsAll` | Batch processing |
| `AddChunksBatchAsync_ReportsProgress_Correctly` | Progress events |
| `AddChunksBatchAsync_CancellationRequested_Throws` | Cancellation |
| `GetChunkAsync_ExistingChunk_ReturnsChunk` | Basic retrieval |
| `GetChunkAsync_NotFound_ReturnsNull` | Not found case |
| `GetChunkAsync_WithEmbedding_IncludesVector` | Embedding retrieval |
| `GetChunksForFileAsync_ReturnsAllChunks` | File chunk list |
| `RemoveChunksForFileAsync_RemovesCorrectly` | Single file removal |
| `RemoveChunksForFilesAsync_MultiplePaths_RemovesAll` | Batch removal |
| `RemoveChunksForFilesAsync_UpdatesIndexCount` | Count updated |
| `ClearIndexAsync_RemovesAllData` | Full clear |
| `ClearIndexAsync_ResetsCountsToZero` | Counts reset |
| `EmbeddingToBlob_ConvertsCorrectly` | Serialization |
| `BlobToEmbedding_ReconstructsCorrectly` | Deserialization |
| `EmbeddingRoundtrip_PreservesValues` | Round-trip test |

---

## File Summary

| File | Location | Purpose | Lines |
|------|----------|---------|-------|
| `SqliteVectorStore.ChunkOperations.cs` | `Services/VectorStore/` | Chunk CRUD operations | ~450 |

---

## Acceptance Criteria

| ID | Criterion |
|----|-----------|
| AC-1 | `AddChunksAsync` inserts both vectors and metadata |
| AC-2 | `AddChunksBatchAsync` processes in configurable batches |
| AC-3 | Progress reports all phases correctly |
| AC-4 | `GetChunkAsync` retrieves chunk with correct metadata |
| AC-5 | `GetChunkAsync` with `includeEmbedding=true` returns embedding |
| AC-6 | `RemoveChunksForFileAsync` removes vectors and metadata |
| AC-7 | `ClearIndexAsync` removes all data and resets counts |
| AC-8 | All write operations are transactional |
| AC-9 | Index chunk counts are updated correctly |
| AC-10 | Embedding serialization is lossless |

---

## Changelog Entry

```markdown
## v0.7.2f - Chunk Operations

### Added
- `SqliteVectorStore.ChunkOperations.cs` partial class
  - **Add Operations**
    - `AddChunksAsync()` - Simple chunk insertion
    - `AddChunksBatchAsync()` - Batch insert with progress
    - `InsertVectorAsync()` - Vector table insertion
    - `InsertChunkMetadataAsync()` - Metadata insertion
    - `UpdateIndexChunkCountAsync()` - Atomic count update
  - **Get Operations**
    - `GetChunkAsync()` - Get by ID with optional embedding
    - `GetChunksForFileAsync()` - Get all chunks for a file
    - `GetEmbeddingAsync()` - Retrieve embedding vector
  - **Remove Operations**
    - `RemoveChunksForFileAsync()` - Remove single file's chunks
    - `RemoveChunksForFilesAsync()` - Remove multiple files' chunks
    - `ClearIndexAsync()` - Clear all chunks from index
  - **Utilities**
    - `ReadStoredChunkFromReader()` - DB reader mapping
    - `EmbeddingToBlob()` - float[] → byte[] serialization
    - `BlobToEmbedding()` - byte[] → float[] deserialization

### Features
- Configurable batch size (BulkInsertBatchSize option)
- Progress reporting through all storage phases
- Transactional operations with rollback on error
- Automatic index count maintenance
- Thread-safe with write lock serialization

### Performance
- Buffer.BlockCopy for embedding serialization
- Batch processing to reduce transaction overhead
- Cancellation support at batch boundaries
```

---

## Timeline Estimate

| Version | Estimated Effort |
|---------|------------------|
| v0.7.2f | 0.75 day |
