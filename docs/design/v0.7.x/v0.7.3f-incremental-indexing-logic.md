# Design Specification: AIntern v0.7.3f "Incremental Indexing Logic"

## Overview

**Version**: v0.7.3f
**Parent**: v0.7.3 Indexing Pipeline
**Focus**: Intelligent change detection and incremental indexing to minimize re-processing of unchanged files

### Purpose

This sub-version implements the incremental indexing system:
1. `IncrementalIndexer` - Orchestrates incremental updates based on detected changes
2. `ChangeDetector` - Compares indexed files with current filesystem state
3. `FileScanner` - Scans workspace with filtering and hash computation
4. Supporting models for results, progress, and change summaries

### Dependencies

**From v0.7.2 (Vector Storage)**:
- `IVectorStore` for querying indexed files (v0.7.2a)
- `IndexedFile` model (v0.7.2h)
- `VectorIndexSettings` model (v0.7.2b)

**From v0.7.3b (Indexing Models & Options)**:
- `IndexingOptions` configuration
- `IndexingError` for error capture

**From v0.7.3d (File Processing Pipeline)**:
- `FileProcessor` for processing changed files
- `FileContentReader` for content reading
- `FileHasher` for hash computation
- `FileProcessingContext` model

**From v0.7.3e (Gitignore Pattern Matching)**:
- `IGitignoreParser` for file filtering

---

## Architecture

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                     v0.7.3f Incremental Indexing Logic                        │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  src/SeniorIntern.Services/Indexing/                                         │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │                                                                          ││
│  │  IncrementalIndexer                                                      ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Dependencies                                                      │  ││
│  │  │  ├── IVectorStore _vectorStore                                     │  ││
│  │  │  ├── FileScanner _fileScanner                                      │  ││
│  │  │  ├── FileProcessor _fileProcessor                                  │  ││
│  │  │  └── ILogger<IncrementalIndexer> _logger                          │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Methods                                                           │  ││
│  │  │  ├── IndexChangesAsync(indexId, progress, ct)                     │  ││
│  │  │  │   → IncrementalIndexResult                                      │  ││
│  │  │  ├── CheckForChangesAsync(indexId, ct)                            │  ││
│  │  │  │   → IndexChangesSummary                                         │  ││
│  │  │  └── UpdateIndexStatisticsAsync(indexId, ct) [private]            │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │                                                                          ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  ChangeDetector                                                          ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Methods                                                           │  ││
│  │  │  ├── DetectChangesAsync(indexedFiles, currentFiles, options)      │  ││
│  │  │  │   → DetectedChanges                                             │  ││
│  │  │  └── HasAnyChangesAsync(workspacePath, indexedFiles)              │  ││
│  │  │      → bool                                                        │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Change Detection Strategies                                       │  ││
│  │  │  ├── Hash comparison: Compare ContentHash with FileHash           │  ││
│  │  │  ├── Timestamp comparison: Compare LastModified with IndexedAt    │  ││
│  │  │  └── Optional: Detect file renames via hash matching              │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  FileScanner                                                             ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Dependencies                                                      │  ││
│  │  │  ├── IGitignoreParser _gitignoreParser                            │  ││
│  │  │  └── ILogger<FileScanner> _logger                                 │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Methods                                                           │  ││
│  │  │  ├── ScanAsync(workspacePath, settings, progress, ct)             │  ││
│  │  │  │   → IReadOnlyList<ScannedFile>                                  │  ││
│  │  │  ├── ScanWithHashesAsync(workspacePath, settings, progress, ct)   │  ││
│  │  │  │   → IReadOnlyList<ScannedFile>                                  │  ││
│  │  │  └── GetTotalFileSizeAsync(files) → long                          │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  Supporting Models                                                           │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  IncrementalIndexResult    → Result of incremental indexing             ││
│  │  IncrementalProgress       → Progress for incremental operations        ││
│  │  IncrementalPhase          → Phases: Scanning, ComputingHashes, ...     ││
│  │  IndexChangesSummary       → Summary of detected changes                 ││
│  │  DetectedChanges           → Detailed change detection result           ││
│  │  ChangeDetectionOptions    → Configuration for change detection         ││
│  │  ScannedFile               → File metadata from scanning                 ││
│  │  ScanProgress              → Progress for scanning operations            ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Incremental Indexing Flow

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                     Incremental Indexing Pipeline                             │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  IncrementalIndexer.IndexChangesAsync(indexId)                               │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase 1: SCANNING                                                      │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  FileScanner.ScanAsync(workspacePath, settings)                  │  │ │
│  │  │  ├── Load gitignore patterns                                      │  │ │
│  │  │  ├── Enumerate files matching include patterns                    │  │ │
│  │  │  ├── Apply exclude patterns and gitignore                        │  │ │
│  │  │  ├── Filter by size limits                                        │  │ │
│  │  │  └── Return List<ScannedFile> with metadata                      │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │  Phase: IncrementalPhase.Scanning                                       │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase 2: COMPUTING HASHES                                              │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  For each ScannedFile:                                            │  │ │
│  │  │  ├── Read file content                                            │  │ │
│  │  │  └── Compute SHA256 hash (ContentHash)                           │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │  Phase: IncrementalPhase.ComputingHashes                                │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase 3: DETECTING CHANGES                                             │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  ChangeDetector.DetectChangesAsync(indexedFiles, currentFiles)   │  │ │
│  │  │  ├── For each current file:                                       │  │ │
│  │  │  │   ├── Not in index? → ADDED                                   │  │ │
│  │  │  │   ├── Hash changed? → MODIFIED                                │  │ │
│  │  │  │   └── Hash same?    → UNCHANGED                               │  │ │
│  │  │  └── For each indexed file not in current → DELETED              │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │  Phase: IncrementalPhase.DetectingChanges                               │ │
│  │  Output: DetectedChanges { Added, Modified, Deleted, Unchanged }        │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ├── If no changes detected → Return early with NoChanges = true            │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase 4: REMOVING DELETED                                              │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  For each deleted file:                                           │  │ │
│  │  │  └── IVectorStore.RemoveChunksForFileAsync(indexId, filePath)    │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │  Phase: IncrementalPhase.RemovingDeleted                                │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase 5: PROCESSING CHANGES                                            │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  For modified files:                                              │  │ │
│  │  │  └── Remove old chunks first                                      │  │ │
│  │  │                                                                    │  │ │
│  │  │  For added + modified files:                                      │  │ │
│  │  │  └── FileProcessor.ProcessFilesAsync(contexts, parallelism)      │  │ │
│  │  │      ├── Read file                                                 │  │ │
│  │  │      ├── Chunk content                                             │  │ │
│  │  │      ├── Generate embeddings                                       │  │ │
│  │  │      └── Store in database                                         │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │  Phase: IncrementalPhase.Processing                                     │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Phase 6: UPDATE STATISTICS                                             │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  UpdateIndexStatisticsAsync(indexId)                              │  │ │
│  │  │  ├── Get current statistics from vector store                    │  │ │
│  │  │  ├── Update ChunkCount, FileCount, TotalFileSizeBytes            │  │ │
│  │  │  ├── Set UpdatedAt and LastIncrementalUpdateAt                   │  │ │
│  │  │  └── Persist via UpdateIndexAsync                                 │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │  Phase: IncrementalPhase.Complete                                       │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  Return IncrementalIndexResult                                               │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Files to Create

| File | Purpose |
|------|---------|
| `src/SeniorIntern.Services/Indexing/IncrementalIndexer.cs` | Main incremental indexing orchestrator |
| `src/SeniorIntern.Services/Indexing/ChangeDetector.cs` | File change detection logic |
| `src/SeniorIntern.Services/Indexing/FileScanner.cs` | Workspace file scanning with filtering |
| `src/SeniorIntern.Services/Indexing/IncrementalModels.cs` | Models for incremental indexing |

---

## Detailed Specifications

### 1. IncrementalIndexer.cs

**Location**: `src/SeniorIntern.Services/Indexing/IncrementalIndexer.cs`

```csharp
using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;
using SeniorIntern.Services.VectorStore;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Handles incremental indexing of changed files.
/// </summary>
/// <remarks>
/// <para>
/// Incremental indexing is significantly faster than full indexing because it:
/// <list type="bullet">
///   <item>Detects which files have changed via hash comparison</item>
///   <item>Only processes added and modified files</item>
///   <item>Removes chunks for deleted files</item>
///   <item>Skips unchanged files entirely</item>
/// </list>
/// </para>
/// <para>
/// Use <see cref="CheckForChangesAsync"/> to preview changes before indexing,
/// or <see cref="IndexChangesAsync"/> to perform the incremental update.
/// </para>
/// </remarks>
public sealed class IncrementalIndexer
{
    private readonly IVectorStore _vectorStore;
    private readonly FileScanner _fileScanner;
    private readonly FileProcessor _fileProcessor;
    private readonly ILogger<IncrementalIndexer> _logger;

    /// <summary>
    /// Initializes a new instance of the <see cref="IncrementalIndexer"/> class.
    /// </summary>
    public IncrementalIndexer(
        IVectorStore vectorStore,
        FileScanner fileScanner,
        FileProcessor fileProcessor,
        ILogger<IncrementalIndexer> logger)
    {
        _vectorStore = vectorStore ?? throw new ArgumentNullException(nameof(vectorStore));
        _fileScanner = fileScanner ?? throw new ArgumentNullException(nameof(fileScanner));
        _fileProcessor = fileProcessor ?? throw new ArgumentNullException(nameof(fileProcessor));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    /// <summary>
    /// Detect and process only changed files.
    /// </summary>
    /// <param name="indexId">ID of the index to update.</param>
    /// <param name="progress">Optional progress reporter.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Result summarizing the incremental update.</returns>
    /// <exception cref="ArgumentException">If index is not found.</exception>
    public async Task<IncrementalIndexResult> IndexChangesAsync(
        string indexId,
        IProgress<IncrementalProgress>? progress = null,
        CancellationToken ct = default)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(indexId);

        var index = await _vectorStore.GetIndexAsync(indexId, ct)
            ?? throw new ArgumentException($"Index not found: {indexId}", nameof(indexId));

        _logger.LogInformation("Starting incremental index for {IndexId}", indexId);

        // Phase 1: Scan current files
        progress?.Report(new IncrementalProgress
        {
            Phase = IncrementalPhase.Scanning,
            Message = "Scanning for file changes..."
        });

        var settings = index.Settings;
        var currentFiles = await _fileScanner.ScanWithHashesAsync(
            index.WorkspacePath, settings, null, ct);

        _logger.LogDebug("Scanned {Count} files", currentFiles.Count);

        // Phase 2: Computing hashes is included in scan
        progress?.Report(new IncrementalProgress
        {
            Phase = IncrementalPhase.ComputingHashes,
            Message = "Computing file hashes..."
        });

        var fileHashes = currentFiles.ToDictionary(f => f.RelativePath, f => f.ContentHash);

        // Phase 3: Detect changes
        progress?.Report(new IncrementalProgress
        {
            Phase = IncrementalPhase.DetectingChanges,
            Message = "Detecting changes..."
        });

        var changes = await _vectorStore.DetectFileChangesAsync(indexId, fileHashes, ct);

        _logger.LogInformation(
            "Detected changes: {Added} added, {Modified} modified, {Deleted} deleted, {Unchanged} unchanged",
            changes.AddedFiles.Count, changes.ModifiedFiles.Count,
            changes.DeletedFiles.Count, changes.UnchangedFiles.Count);

        // Early exit if no changes
        if (!changes.HasChanges)
        {
            _logger.LogInformation("No changes detected");
            return new IncrementalIndexResult
            {
                Success = true,
                NoChanges = true
            };
        }

        var result = new IncrementalIndexResult
        {
            Success = true,
            FilesAdded = changes.AddedFiles.Count,
            FilesModified = changes.ModifiedFiles.Count,
            FilesDeleted = changes.DeletedFiles.Count,
            FilesUnchanged = changes.UnchangedFiles.Count
        };

        var chunksRemoved = 0;
        var chunksAdded = 0;
        var errors = new List<IndexingError>();

        // Phase 4: Remove deleted files
        if (changes.DeletedFiles.Count > 0)
        {
            progress?.Report(new IncrementalProgress
            {
                Phase = IncrementalPhase.RemovingDeleted,
                Message = $"Removing {changes.DeletedFiles.Count} deleted files..."
            });

            chunksRemoved = await _vectorStore.RemoveChunksForFilesAsync(
                indexId, changes.DeletedFiles, ct);

            _logger.LogDebug("Removed {Count} chunks for deleted files", chunksRemoved);
        }

        // Phase 5: Process added and modified files
        var filesToProcess = changes.AddedFiles.Concat(changes.ModifiedFiles).ToList();
        if (filesToProcess.Count > 0)
        {
            // Remove old chunks for modified files first
            foreach (var file in changes.ModifiedFiles)
            {
                chunksRemoved += await _vectorStore.RemoveChunksForFileAsync(indexId, file, ct);
            }

            // Process files
            var options = settings.ToIndexingOptions();
            var contexts = filesToProcess.Select(f => new FileProcessingContext
            {
                IndexId = indexId,
                AbsolutePath = Path.Combine(index.WorkspacePath, f),
                RelativePath = f,
                Options = options
            }).ToList();

            var batchProgress = new Progress<BatchProgress>(p =>
            {
                progress?.Report(new IncrementalProgress
                {
                    Phase = IncrementalPhase.Processing,
                    ProcessedFiles = p.Processed,
                    TotalFiles = p.Total,
                    CurrentFile = p.CurrentFile,
                    PercentComplete = p.PercentComplete
                });
            });

            var processingResult = await _fileProcessor.ProcessFilesAsync(
                contexts,
                options.ParallelProcessing,
                batchProgress,
                ct);

            chunksAdded = processingResult.TotalChunks;
            errors = processingResult.Results
                .Where(r => r.Error != null)
                .Select(r => r.Error!)
                .ToList();
        }

        // Phase 6: Update index statistics
        await UpdateIndexStatisticsAsync(indexId, ct);

        result = result with
        {
            ChunksAdded = chunksAdded,
            ChunksRemoved = chunksRemoved,
            Errors = errors
        };

        progress?.Report(new IncrementalProgress
        {
            Phase = IncrementalPhase.Complete,
            Message = $"Incremental update complete: +{chunksAdded} -{chunksRemoved} chunks"
        });

        _logger.LogInformation(
            "Incremental index complete: +{Added} -{Removed} chunks",
            chunksAdded, chunksRemoved);

        return result;
    }

    /// <summary>
    /// Check if an index needs updating without performing the update.
    /// </summary>
    /// <param name="indexId">ID of the index to check.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Summary of detected changes.</returns>
    public async Task<IndexChangesSummary> CheckForChangesAsync(
        string indexId,
        CancellationToken ct = default)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(indexId);

        var index = await _vectorStore.GetIndexAsync(indexId, ct)
            ?? throw new ArgumentException($"Index not found: {indexId}", nameof(indexId));

        var currentFiles = await _fileScanner.ScanWithHashesAsync(
            index.WorkspacePath, index.Settings, null, ct);

        var fileHashes = currentFiles.ToDictionary(f => f.RelativePath, f => f.ContentHash);
        var changes = await _vectorStore.DetectFileChangesAsync(indexId, fileHashes, ct);

        return new IndexChangesSummary
        {
            HasChanges = changes.HasChanges,
            AddedCount = changes.AddedFiles.Count,
            ModifiedCount = changes.ModifiedFiles.Count,
            DeletedCount = changes.DeletedFiles.Count,
            UnchangedCount = changes.UnchangedFiles.Count,
            AddedFiles = changes.AddedFiles,
            ModifiedFiles = changes.ModifiedFiles,
            DeletedFiles = changes.DeletedFiles
        };
    }

    /// <summary>
    /// Update the index statistics after processing changes.
    /// </summary>
    private async Task UpdateIndexStatisticsAsync(string indexId, CancellationToken ct)
    {
        var stats = await _vectorStore.GetStatisticsAsync(indexId, ct);
        var index = await _vectorStore.GetIndexAsync(indexId, ct);

        if (index != null)
        {
            index.ChunkCount = stats.TotalChunks;
            index.FileCount = stats.TotalFiles;
            index.TotalFileSizeBytes = stats.TotalFileSizeBytes;
            index.UpdatedAt = DateTime.UtcNow;
            index.LastIncrementalUpdateAt = DateTime.UtcNow;

            await _vectorStore.UpdateIndexAsync(index, ct);
        }
    }
}
```

### 2. ChangeDetector.cs

**Location**: `src/SeniorIntern.Services/Indexing/ChangeDetector.cs`

```csharp
using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using SeniorIntern.Core.Models;
using SeniorIntern.Services.VectorStore;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Detects file changes for incremental indexing.
/// </summary>
/// <remarks>
/// <para>
/// Supports two change detection strategies:
/// <list type="bullet">
///   <item><b>Hash comparison</b>: Compare content hashes (accurate but slower)</item>
///   <item><b>Timestamp comparison</b>: Compare modification times (faster but less accurate)</item>
/// </list>
/// </para>
/// <para>
/// Hash comparison is recommended for most use cases as it correctly
/// handles cases where file content was restored to previous versions.
/// </para>
/// </remarks>
public sealed class ChangeDetector
{
    /// <summary>
    /// Detect changes between indexed files and current filesystem state.
    /// </summary>
    /// <param name="indexedFiles">Files currently in the index.</param>
    /// <param name="currentFiles">Files currently on disk.</param>
    /// <param name="options">Change detection options.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Detailed change detection result.</returns>
    public async Task<DetectedChanges> DetectChangesAsync(
        IReadOnlyList<IndexedFile> indexedFiles,
        IReadOnlyList<ScannedFile> currentFiles,
        ChangeDetectionOptions options,
        CancellationToken ct = default)
    {
        ArgumentNullException.ThrowIfNull(indexedFiles);
        ArgumentNullException.ThrowIfNull(currentFiles);
        ArgumentNullException.ThrowIfNull(options);

        var indexedByPath = indexedFiles.ToDictionary(f => f.FilePath);
        var currentByPath = currentFiles.ToDictionary(f => f.RelativePath);

        var added = new List<ScannedFile>();
        var modified = new List<(IndexedFile Old, ScannedFile New)>();
        var deleted = new List<IndexedFile>();
        var unchanged = new List<IndexedFile>();

        // Check each current file
        foreach (var current in currentFiles)
        {
            ct.ThrowIfCancellationRequested();

            // Skip files that are too new (still being written)
            if (options.MinFileAgeSeconds > 0)
            {
                var age = DateTime.UtcNow - current.LastModified;
                if (age.TotalSeconds < options.MinFileAgeSeconds)
                    continue;
            }

            if (!indexedByPath.TryGetValue(current.RelativePath, out var indexed))
            {
                // New file
                added.Add(current);
            }
            else
            {
                // Check if modified using configured strategy
                var isModified = options.UseHashComparison
                    ? current.ContentHash != indexed.FileHash
                    : current.LastModified > indexed.IndexedAt;

                if (isModified)
                {
                    modified.Add((indexed, current));
                }
                else
                {
                    unchanged.Add(indexed);
                }
            }
        }

        // Find deleted files
        foreach (var indexed in indexedFiles)
        {
            if (!currentByPath.ContainsKey(indexed.FilePath))
            {
                deleted.Add(indexed);
            }
        }

        // Optionally detect renames (hash matches for added/deleted pairs)
        if (options.DetectRenames)
        {
            await DetectRenamesAsync(added, deleted, ct);
        }

        return new DetectedChanges
        {
            Added = added,
            Modified = modified,
            Deleted = deleted,
            Unchanged = unchanged
        };
    }

    /// <summary>
    /// Quick check if any files have changed.
    /// </summary>
    /// <remarks>
    /// This method is faster than <see cref="DetectChangesAsync"/> but only
    /// checks for modifications and deletions, not new files.
    /// </remarks>
    /// <param name="workspacePath">Workspace root path.</param>
    /// <param name="indexedFiles">Currently indexed files.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>True if any changes detected.</returns>
    public async Task<bool> HasAnyChangesAsync(
        string workspacePath,
        IReadOnlyList<IndexedFile> indexedFiles,
        CancellationToken ct = default)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(workspacePath);
        ArgumentNullException.ThrowIfNull(indexedFiles);

        // Check for modified or deleted files
        foreach (var indexed in indexedFiles)
        {
            ct.ThrowIfCancellationRequested();

            var fullPath = Path.Combine(workspacePath, indexed.FilePath);

            if (!File.Exists(fullPath))
            {
                // File deleted
                return true;
            }

            var fileInfo = new FileInfo(fullPath);
            if (fileInfo.LastWriteTimeUtc > indexed.IndexedAt)
            {
                // File modified
                return true;
            }
        }

        // Note: This doesn't check for new files - would need full scan
        return await Task.FromResult(false);
    }

    /// <summary>
    /// Detect renamed files by matching hashes between added and deleted.
    /// </summary>
    private static Task DetectRenamesAsync(
        List<ScannedFile> added,
        List<IndexedFile> deleted,
        CancellationToken ct)
    {
        // Build hash lookup for added files
        var addedByHash = added
            .Where(f => !string.IsNullOrEmpty(f.ContentHash))
            .GroupBy(f => f.ContentHash)
            .ToDictionary(g => g.Key, g => g.ToList());

        var matchedDeleted = new List<IndexedFile>();

        foreach (var deletedFile in deleted)
        {
            ct.ThrowIfCancellationRequested();

            if (addedByHash.TryGetValue(deletedFile.FileHash, out var matches))
            {
                // Found a potential rename - remove from both lists
                var match = matches.FirstOrDefault();
                if (match != null)
                {
                    matches.Remove(match);
                    added.Remove(match);
                    matchedDeleted.Add(deletedFile);
                }
            }
        }

        foreach (var matched in matchedDeleted)
        {
            deleted.Remove(matched);
        }

        return Task.CompletedTask;
    }
}
```

### 3. FileScanner.cs

**Location**: `src/SeniorIntern.Services/Indexing/FileScanner.cs`

```csharp
using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Scans workspace directories for files matching indexing criteria.
/// </summary>
/// <remarks>
/// <para>
/// FileScanner applies multiple filters to discover indexable files:
/// <list type="bullet">
///   <item>Include patterns (glob matching)</item>
///   <item>Exclude patterns (glob matching)</item>
///   <item>Gitignore patterns</item>
///   <item>File size limits</item>
///   <item>Hidden file filtering</item>
/// </list>
/// </para>
/// </remarks>
public sealed class FileScanner
{
    private readonly IGitignoreParser _gitignoreParser;
    private readonly ILogger<FileScanner> _logger;

    /// <summary>
    /// Initializes a new instance of the <see cref="FileScanner"/> class.
    /// </summary>
    public FileScanner(
        IGitignoreParser gitignoreParser,
        ILogger<FileScanner> logger)
    {
        _gitignoreParser = gitignoreParser ?? throw new ArgumentNullException(nameof(gitignoreParser));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    /// <summary>
    /// Scan workspace for files matching settings, without computing hashes.
    /// </summary>
    /// <param name="workspacePath">Root directory to scan.</param>
    /// <param name="settings">Index settings with patterns and filters.</param>
    /// <param name="progress">Optional progress reporter.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of discovered files with metadata.</returns>
    public async Task<IReadOnlyList<ScannedFile>> ScanAsync(
        string workspacePath,
        VectorIndexSettings settings,
        IProgress<ScanProgress>? progress = null,
        CancellationToken ct = default)
    {
        return await ScanInternalAsync(workspacePath, settings, computeHashes: false, progress, ct);
    }

    /// <summary>
    /// Scan workspace for files and compute content hashes.
    /// </summary>
    /// <param name="workspacePath">Root directory to scan.</param>
    /// <param name="settings">Index settings with patterns and filters.</param>
    /// <param name="progress">Optional progress reporter.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of discovered files with metadata and hashes.</returns>
    public async Task<IReadOnlyList<ScannedFile>> ScanWithHashesAsync(
        string workspacePath,
        VectorIndexSettings settings,
        IProgress<ScanProgress>? progress = null,
        CancellationToken ct = default)
    {
        return await ScanInternalAsync(workspacePath, settings, computeHashes: true, progress, ct);
    }

    /// <summary>
    /// Get total size of a collection of files.
    /// </summary>
    public static long GetTotalFileSize(IEnumerable<ScannedFile> files)
    {
        return files.Sum(f => f.FileSize);
    }

    /// <summary>
    /// Internal scan implementation.
    /// </summary>
    private async Task<IReadOnlyList<ScannedFile>> ScanInternalAsync(
        string workspacePath,
        VectorIndexSettings settings,
        bool computeHashes,
        IProgress<ScanProgress>? progress,
        CancellationToken ct)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(workspacePath);
        ArgumentNullException.ThrowIfNull(settings);

        if (!Directory.Exists(workspacePath))
        {
            throw new DirectoryNotFoundException($"Workspace not found: {workspacePath}");
        }

        var files = new List<ScannedFile>();

        // Load gitignore patterns
        IGitignoreMatcher? gitignoreMatcher = null;
        if (settings.RespectGitignore)
        {
            gitignoreMatcher = _gitignoreParser.LoadFromDirectory(workspacePath);
            _logger.LogDebug("Loaded {Count} gitignore patterns", gitignoreMatcher.PatternCount);
        }

        // Configure enumeration
        var enumOptions = new EnumerationOptions
        {
            RecurseSubdirectories = settings.MaxDepth != 0,
            MaxRecursionDepth = settings.MaxDepth > 0 ? settings.MaxDepth : int.MaxValue,
            IgnoreInaccessible = true,
            AttributesToSkip = settings.IndexHiddenFiles
                ? FileAttributes.System
                : FileAttributes.Hidden | FileAttributes.System
        };

        var scannedCount = 0;
        var skippedCount = 0;

        await Task.Run(async () =>
        {
            foreach (var filePath in Directory.EnumerateFiles(workspacePath, "*", enumOptions))
            {
                ct.ThrowIfCancellationRequested();

                var relativePath = Path.GetRelativePath(workspacePath, filePath)
                    .Replace('\\', '/');

                // Apply gitignore
                if (gitignoreMatcher?.IsIgnored(relativePath) == true)
                {
                    skippedCount++;
                    continue;
                }

                // Check include patterns
                if (!MatchesAnyPattern(relativePath, settings.IncludePatterns))
                {
                    skippedCount++;
                    continue;
                }

                // Check exclude patterns
                if (MatchesAnyPattern(relativePath, settings.ExcludePatterns))
                {
                    skippedCount++;
                    continue;
                }

                // Check file size
                var fileInfo = new FileInfo(filePath);
                if (fileInfo.Length < settings.MinFileSizeBytes)
                {
                    skippedCount++;
                    continue;
                }
                if (fileInfo.Length > settings.MaxFileSizeKb * 1024)
                {
                    skippedCount++;
                    continue;
                }

                // Compute hash if requested
                string? contentHash = null;
                if (computeHashes)
                {
                    contentHash = await FileHasher.ComputeHashFromFileAsync(filePath, ct);
                }

                files.Add(new ScannedFile
                {
                    AbsolutePath = filePath,
                    RelativePath = relativePath,
                    FileSize = fileInfo.Length,
                    LastModified = fileInfo.LastWriteTimeUtc,
                    ContentHash = contentHash ?? string.Empty
                });

                scannedCount++;

                // Report progress periodically
                if (scannedCount % 100 == 0)
                {
                    progress?.Report(new ScanProgress
                    {
                        FilesScanned = scannedCount,
                        FilesSkipped = skippedCount,
                        CurrentFile = relativePath
                    });
                }
            }
        }, ct);

        _logger.LogInformation(
            "Scan complete: {Scanned} files matched, {Skipped} skipped",
            files.Count, skippedCount);

        return files;
    }

    /// <summary>
    /// Check if path matches any of the glob patterns.
    /// </summary>
    private static bool MatchesAnyPattern(string path, IReadOnlyList<string> patterns)
    {
        foreach (var pattern in patterns)
        {
            if (MatchGlobPattern(path, pattern))
                return true;
        }
        return false;
    }

    /// <summary>
    /// Simple glob pattern matching.
    /// </summary>
    private static bool MatchGlobPattern(string path, string pattern)
    {
        path = path.Replace('\\', '/');
        pattern = pattern.Replace('\\', '/');

        // Handle ** prefix
        if (pattern.StartsWith("**/"))
        {
            var rest = pattern[3..];
            var segments = path.Split('/');
            for (int i = 0; i < segments.Length; i++)
            {
                var subPath = string.Join('/', segments.Skip(i));
                if (MatchGlobPattern(subPath, rest))
                    return true;
            }
            return false;
        }

        // Handle ** suffix
        if (pattern.EndsWith("/**"))
        {
            var prefix = pattern[..^3];
            return path.StartsWith(prefix + "/") || path == prefix;
        }

        // Simple glob to regex
        var regexPattern = "^" + System.Text.RegularExpressions.Regex.Escape(pattern)
            .Replace("\\*", "[^/]*")
            .Replace("\\?", "[^/]") + "$";

        return System.Text.RegularExpressions.Regex.IsMatch(path, regexPattern);
    }
}
```

### 4. IncrementalModels.cs

**Location**: `src/SeniorIntern.Services/Indexing/IncrementalModels.cs`

```csharp
using System;
using System.Collections.Generic;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Result of incremental indexing.
/// </summary>
public sealed record IncrementalIndexResult
{
    /// <summary>Whether the operation completed successfully.</summary>
    public bool Success { get; init; }

    /// <summary>True if no changes were detected.</summary>
    public bool NoChanges { get; init; }

    /// <summary>Number of new files added.</summary>
    public int FilesAdded { get; init; }

    /// <summary>Number of files modified.</summary>
    public int FilesModified { get; init; }

    /// <summary>Number of files deleted.</summary>
    public int FilesDeleted { get; init; }

    /// <summary>Number of unchanged files.</summary>
    public int FilesUnchanged { get; init; }

    /// <summary>Number of chunks added.</summary>
    public int ChunksAdded { get; init; }

    /// <summary>Number of chunks removed.</summary>
    public int ChunksRemoved { get; init; }

    /// <summary>Net change in chunk count.</summary>
    public int ChunksDelta => ChunksAdded - ChunksRemoved;

    /// <summary>Errors that occurred during processing.</summary>
    public IReadOnlyList<IndexingError> Errors { get; init; } = [];

    /// <summary>Total files processed (added + modified).</summary>
    public int TotalProcessed => FilesAdded + FilesModified;
}

/// <summary>
/// Progress for incremental indexing.
/// </summary>
public sealed class IncrementalProgress
{
    /// <summary>Current phase of the operation.</summary>
    public IncrementalPhase Phase { get; init; }

    /// <summary>Human-readable status message.</summary>
    public string? Message { get; init; }

    /// <summary>Number of files processed so far.</summary>
    public int ProcessedFiles { get; init; }

    /// <summary>Total files to process.</summary>
    public int TotalFiles { get; init; }

    /// <summary>Current file being processed.</summary>
    public string? CurrentFile { get; init; }

    /// <summary>Completion percentage (0-100).</summary>
    public double PercentComplete { get; init; }
}

/// <summary>
/// Phases of incremental indexing.
/// </summary>
public enum IncrementalPhase
{
    /// <summary>Scanning filesystem for files.</summary>
    Scanning,

    /// <summary>Computing file content hashes.</summary>
    ComputingHashes,

    /// <summary>Comparing with index to detect changes.</summary>
    DetectingChanges,

    /// <summary>Removing chunks for deleted files.</summary>
    RemovingDeleted,

    /// <summary>Processing added and modified files.</summary>
    Processing,

    /// <summary>Operation completed.</summary>
    Complete
}

/// <summary>
/// Summary of detected changes for an index.
/// </summary>
public sealed class IndexChangesSummary
{
    /// <summary>Whether any changes were detected.</summary>
    public bool HasChanges { get; init; }

    /// <summary>Number of new files.</summary>
    public int AddedCount { get; init; }

    /// <summary>Number of modified files.</summary>
    public int ModifiedCount { get; init; }

    /// <summary>Number of deleted files.</summary>
    public int DeletedCount { get; init; }

    /// <summary>Number of unchanged files.</summary>
    public int UnchangedCount { get; init; }

    /// <summary>Paths of added files.</summary>
    public IReadOnlyList<string> AddedFiles { get; init; } = [];

    /// <summary>Paths of modified files.</summary>
    public IReadOnlyList<string> ModifiedFiles { get; init; } = [];

    /// <summary>Paths of deleted files.</summary>
    public IReadOnlyList<string> DeletedFiles { get; init; } = [];

    /// <summary>Total number of changes.</summary>
    public int TotalChanges => AddedCount + ModifiedCount + DeletedCount;
}

/// <summary>
/// Result of change detection.
/// </summary>
public sealed class DetectedChanges
{
    /// <summary>Files that are new (not in index).</summary>
    public IReadOnlyList<ScannedFile> Added { get; init; } = [];

    /// <summary>Files that have been modified (hash changed).</summary>
    public IReadOnlyList<(IndexedFile Old, ScannedFile New)> Modified { get; init; } = [];

    /// <summary>Files that have been deleted (in index but not on disk).</summary>
    public IReadOnlyList<IndexedFile> Deleted { get; init; } = [];

    /// <summary>Files that have not changed.</summary>
    public IReadOnlyList<IndexedFile> Unchanged { get; init; } = [];

    /// <summary>Whether any changes were detected.</summary>
    public bool HasChanges => Added.Count > 0 || Modified.Count > 0 || Deleted.Count > 0;

    /// <summary>Total number of changes.</summary>
    public int TotalChanges => Added.Count + Modified.Count + Deleted.Count;
}

/// <summary>
/// Options for change detection.
/// </summary>
public sealed class ChangeDetectionOptions
{
    /// <summary>
    /// Whether to use content hash comparison (more accurate but slower).
    /// </summary>
    /// <remarks>
    /// When false, uses timestamp comparison which is faster but may
    /// miss cases where file content was restored to a previous version.
    /// </remarks>
    public bool UseHashComparison { get; init; } = true;

    /// <summary>
    /// Whether to detect renamed files.
    /// </summary>
    /// <remarks>
    /// When true, files with matching hashes in added/deleted lists
    /// are treated as renames rather than separate add/delete operations.
    /// </remarks>
    public bool DetectRenames { get; init; } = false;

    /// <summary>
    /// Minimum file age in seconds to consider for indexing.
    /// </summary>
    /// <remarks>
    /// Helps avoid indexing files that are still being written.
    /// Set to 0 to disable this check.
    /// </remarks>
    public int MinFileAgeSeconds { get; init; } = 1;
}

/// <summary>
/// File metadata from scanning.
/// </summary>
public sealed class ScannedFile
{
    /// <summary>Absolute path to the file.</summary>
    public required string AbsolutePath { get; init; }

    /// <summary>Path relative to workspace root.</summary>
    public required string RelativePath { get; init; }

    /// <summary>File size in bytes.</summary>
    public long FileSize { get; init; }

    /// <summary>Last modification time (UTC).</summary>
    public DateTime LastModified { get; init; }

    /// <summary>Content hash (SHA256), empty if not computed.</summary>
    public string ContentHash { get; init; } = string.Empty;
}

/// <summary>
/// Progress for scanning operations.
/// </summary>
public sealed class ScanProgress
{
    /// <summary>Number of files scanned so far.</summary>
    public int FilesScanned { get; init; }

    /// <summary>Number of files skipped (filtered out).</summary>
    public int FilesSkipped { get; init; }

    /// <summary>Current file being scanned.</summary>
    public string? CurrentFile { get; init; }
}
```

---

## Unit Testing Requirements

| Class | Test Count | Focus Areas |
|-------|------------|-------------|
| `IncrementalIndexer` | 15-20 | Full workflow, no-change handling, error aggregation |
| `ChangeDetector` | 20-25 | Add/modify/delete detection, hash vs timestamp, renames |
| `FileScanner` | 15-20 | Pattern matching, gitignore, size limits |
| Models | 10-12 | Properties, computed values, equality |

**Total: ~60-77 tests**

### Test Scenarios

**IncrementalIndexer**:
- No changes detected → early exit
- Only additions → process new files
- Only modifications → remove old chunks, add new
- Only deletions → remove chunks
- Mixed changes → proper ordering
- Errors during processing → aggregated in result

**ChangeDetector**:
- Hash comparison accurately detects changes
- Timestamp comparison works as fallback
- Rename detection matches by hash
- MinFileAgeSeconds filters recent files
- Deleted file detection

**FileScanner**:
- Include patterns work correctly
- Exclude patterns take precedence
- Gitignore patterns respected
- Size limits enforced
- Hidden file filtering

---

## Acceptance Criteria

### Functional Requirements
- [ ] `IncrementalIndexer.IndexChangesAsync` correctly handles all change types
- [ ] `IncrementalIndexer.CheckForChangesAsync` provides accurate preview
- [ ] `ChangeDetector` detects added, modified, deleted, and unchanged files
- [ ] Hash comparison is accurate
- [ ] Timestamp comparison works as fallback
- [ ] `FileScanner` applies all filters correctly
- [ ] Progress is reported through all phases
- [ ] Index statistics are updated after processing

### Quality Requirements
- [ ] Early exit when no changes detected
- [ ] Modified files have old chunks removed before new chunks added
- [ ] Parallel processing used for file processing phase
- [ ] Proper cancellation token propagation
- [ ] All public members have XML documentation

---

## Future Considerations

Items explicitly deferred to later sub-versions:
- **v0.7.3g**: IndexingJobQueue implementation
- **v0.7.3h**: FileWatcherService implementation
- **v0.7.3i**: Progress tracking integration
