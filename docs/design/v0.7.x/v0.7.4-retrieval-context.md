# Design Specification: AIntern v0.7.4 "Retrieval & Context"

## Overview

This document provides a comprehensive design specification for v0.7.4 of The Senior Intern project. This version implements semantic search, context assembly for LLM prompts, relevance scoring with reranking strategies, and integration with the chat system. This is the layer that transforms raw vector search results into useful, contextual information for AI-assisted coding.

### Objectives
- Implement the `IKnowledgeService` interface for high-level knowledge retrieval
- Create query processing with embedding generation and vector search
- Build context assembly for LLM prompts with token budget management
- Implement multiple reranking strategies (keyword boost, RRF)
- Add context expansion for surrounding code visibility
- Create RAG-aware chat service integration
- Provide relevance scoring and result formatting

### Prerequisites
- v0.7.1 (Embedding Foundation) completed - provides `IEmbeddingService` and `IChunkingService`
- v0.7.2 (Vector Storage) completed - provides `IVectorStore` and search operations
- v0.7.3 (Indexing Pipeline) completed - provides `IIndexingService` for workspace indexing
- Understanding of RAG (Retrieval-Augmented Generation) concepts

### Architecture Context

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           Chat Interface                                 │
│                    (User asks code questions)                           │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                      RagAwareChatService (v0.7.4)                       │
│         Orchestrates RAG context injection into chat prompts            │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                       IKnowledgeService (v0.7.4)                        │
│    ┌──────────────────┐  ┌──────────────────┐  ┌──────────────────┐   │
│    │   QueryAsync()   │  │ BuildContext()   │  │ FindRelevant()   │   │
│    │  Semantic search │  │ Token budgeting  │  │ File discovery   │   │
│    └────────┬─────────┘  └────────┬─────────┘  └────────┬─────────┘   │
│             │                     │                     │              │
│             └──────────────┬──────┴──────────────┬──────┘              │
│                            ▼                     ▼                     │
│    ┌──────────────────────────────┐  ┌──────────────────────────────┐ │
│    │      Reranking Engine        │  │     Context Assembler        │ │
│    │  - Keyword Boost             │  │  - Markdown/XML/Plain        │ │
│    │  - Reciprocal Rank Fusion    │  │  - Token estimation          │ │
│    │  - (Future: Cross-encoder)   │  │  - Context expansion         │ │
│    └──────────────────────────────┘  └──────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                    ┌───────────────┴───────────────┐
                    ▼                               ▼
┌──────────────────────────────┐  ┌──────────────────────────────────────┐
│   IEmbeddingService (v0.7.1) │  │      IVectorStore (v0.7.2)           │
│   - Query embedding          │  │      - Vector similarity search      │
│   - Batch embedding          │  │      - Filtering by metadata         │
└──────────────────────────────┘  └──────────────────────────────────────┘
```

---

## Sub-version Breakdown

| Version | Focus | Files to Create | Files to Modify |
|---------|-------|-----------------|-----------------|
| v0.7.4a | Knowledge Service Interface | 2 | 0 |
| v0.7.4b | Query & Result Models | 3 | 0 |
| v0.7.4c | Context Building Models | 2 | 0 |
| v0.7.4d | Knowledge Service Implementation | 3 | 1 |
| v0.7.4e | Reranking Strategies | 4 | 0 |
| v0.7.4f | Context Assembly & Formatting | 3 | 0 |
| v0.7.4g | Context Expansion | 2 | 0 |
| v0.7.4h | RAG-Aware Chat Integration | 3 | 0 |
| v0.7.4i | Keyword Extraction & Highlighting | 2 | 0 |
| v0.7.4j | Unit Testing & Integration | 8 | 0 |

**Totals: 32 files to create, 1 file to modify**

---

## v0.7.4a: Knowledge Service Interface

### Objective
Define the high-level interface for knowledge retrieval operations, establishing the contract for querying the codebase and building context for LLM prompts.

### File: `src/SeniorIntern.Core/Interfaces/IKnowledgeService.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Core.Interfaces;

/// <summary>
/// High-level knowledge retrieval service for RAG (Retrieval-Augmented Generation).
/// Provides semantic search over indexed codebases and context assembly for LLM prompts.
/// </summary>
public interface IKnowledgeService
{
    /// <summary>
    /// Query the knowledge base with a natural language question.
    /// Returns relevant code chunks with relevance scores.
    /// </summary>
    /// <param name="question">The natural language query or code search term.</param>
    /// <param name="options">Query options including workspace, filters, and reranking.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Query result containing relevant chunks and metadata.</returns>
    Task<KnowledgeQueryResult> QueryAsync(
        string question,
        KnowledgeQueryOptions options,
        CancellationToken ct = default);

    /// <summary>
    /// Build context string for an LLM prompt from retrieved knowledge.
    /// Assembles relevant code into a formatted context block with token budgeting.
    /// </summary>
    /// <param name="question">The user's question to retrieve context for.</param>
    /// <param name="options">Context building options including format and token limits.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Formatted context string ready for LLM prompt injection.</returns>
    Task<string> BuildContextAsync(
        string question,
        ContextBuildOptions options,
        CancellationToken ct = default);

    /// <summary>
    /// Build context from pre-retrieved chunks (for custom retrieval pipelines).
    /// </summary>
    /// <param name="chunks">Pre-retrieved knowledge chunks.</param>
    /// <param name="options">Context building options.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Formatted context string.</returns>
    Task<string> BuildContextFromChunksAsync(
        IReadOnlyList<KnowledgeChunk> chunks,
        ContextBuildOptions options,
        CancellationToken ct = default);

    /// <summary>
    /// Get relevant files for a query without full content.
    /// Useful for showing file suggestions or navigation.
    /// </summary>
    /// <param name="query">The search query.</param>
    /// <param name="workspacePath">Workspace to search in.</param>
    /// <param name="maxFiles">Maximum number of files to return.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of relevant files with relevance scores.</returns>
    Task<IReadOnlyList<RelevantFile>> FindRelevantFilesAsync(
        string query,
        string workspacePath,
        int maxFiles = 10,
        CancellationToken ct = default);

    /// <summary>
    /// Check if knowledge base is available for a workspace.
    /// </summary>
    /// <param name="workspacePath">Path to the workspace.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>True if the workspace has been indexed.</returns>
    Task<bool> IsIndexedAsync(string workspacePath, CancellationToken ct = default);

    /// <summary>
    /// Get index health and statistics for a workspace.
    /// </summary>
    /// <param name="workspacePath">Path to the workspace.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Index health information.</returns>
    Task<KnowledgeIndexHealth> GetIndexHealthAsync(
        string workspacePath,
        CancellationToken ct = default);

    /// <summary>
    /// Get suggestions for similar queries based on indexed content.
    /// </summary>
    /// <param name="partialQuery">Partial query string.</param>
    /// <param name="workspacePath">Workspace to search in.</param>
    /// <param name="maxSuggestions">Maximum suggestions to return.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of query suggestions.</returns>
    Task<IReadOnlyList<string>> GetQuerySuggestionsAsync(
        string partialQuery,
        string workspacePath,
        int maxSuggestions = 5,
        CancellationToken ct = default);
}
```

### File: `src/SeniorIntern.Core/Interfaces/IRerankingStrategy.cs`

```csharp
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Core.Interfaces;

/// <summary>
/// Interface for reranking search results to improve relevance.
/// </summary>
public interface IRerankingStrategy
{
    /// <summary>
    /// The name of this reranking strategy.
    /// </summary>
    string Name { get; }

    /// <summary>
    /// Whether this strategy requires the original query text.
    /// </summary>
    bool RequiresQueryText { get; }

    /// <summary>
    /// Rerank search results based on the strategy's algorithm.
    /// </summary>
    /// <param name="results">Original search results.</param>
    /// <param name="query">The original query text.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Reranked results with updated scores.</returns>
    Task<IReadOnlyList<ChunkSearchResult>> RerankAsync(
        IReadOnlyList<ChunkSearchResult> results,
        string query,
        CancellationToken ct = default);
}
```

### Dependencies
- `SeniorIntern.Core.Models` - Knowledge query and result models (v0.7.4b)

### Implementation Notes
1. `IKnowledgeService` is the main entry point for RAG functionality
2. It abstracts away the complexity of embedding generation, vector search, and result processing
3. The interface supports both synchronous queries and streaming context building
4. `IRerankingStrategy` allows pluggable reranking algorithms

---

## v0.7.4b: Query & Result Models

### Objective
Define the data models for knowledge queries and results, including relevance scoring and metadata.

### File: `src/SeniorIntern.Core/Models/KnowledgeQueryOptions.cs`

```csharp
using System;
using System.Collections.Generic;

namespace SeniorIntern.Core.Models;

/// <summary>
/// Options for querying the knowledge base.
/// </summary>
public sealed class KnowledgeQueryOptions
{
    /// <summary>
    /// Workspace path to search in. Required.
    /// </summary>
    public string WorkspacePath { get; init; } = string.Empty;

    /// <summary>
    /// Maximum number of results to return.
    /// Default: 10
    /// </summary>
    public int MaxResults { get; init; } = 10;

    /// <summary>
    /// Minimum relevance score threshold (0.0 to 1.0).
    /// Results below this score will be filtered out.
    /// Default: 0.5
    /// </summary>
    public float MinRelevance { get; init; } = 0.5f;

    /// <summary>
    /// Whether to expand context around matched chunks.
    /// When true, surrounding lines will be included.
    /// Default: true
    /// </summary>
    public bool ExpandContext { get; init; } = true;

    /// <summary>
    /// Number of lines to include around matches when ExpandContext is true.
    /// Default: 10
    /// </summary>
    public int ContextLines { get; init; } = 10;

    /// <summary>
    /// File glob patterns to include in search.
    /// If null or empty, all indexed files are searched.
    /// Example: ["*.cs", "*.ts"]
    /// </summary>
    public IReadOnlyList<string>? FilePatterns { get; init; }

    /// <summary>
    /// Programming languages to filter results.
    /// If null or empty, all languages are included.
    /// Example: ["csharp", "typescript"]
    /// </summary>
    public IReadOnlyList<string>? Languages { get; init; }

    /// <summary>
    /// Whether to include code snippets in results.
    /// Default: true
    /// </summary>
    public bool IncludeSnippets { get; init; } = true;

    /// <summary>
    /// Reranking strategy to apply after initial retrieval.
    /// Default: None (use embedding similarity only)
    /// </summary>
    public RerankingStrategy Reranking { get; init; } = RerankingStrategy.None;

    /// <summary>
    /// Whether to deduplicate overlapping chunks from the same file.
    /// Default: true
    /// </summary>
    public bool DeduplicateChunks { get; init; } = true;

    /// <summary>
    /// Optional filter for specific directories within the workspace.
    /// Example: ["src/", "lib/"]
    /// </summary>
    public IReadOnlyList<string>? DirectoryFilters { get; init; }

    /// <summary>
    /// Whether to boost results containing exact keyword matches.
    /// This is separate from the Reranking strategy.
    /// Default: false
    /// </summary>
    public bool BoostExactMatches { get; init; } = false;

    /// <summary>
    /// Symbol types to filter results.
    /// If null or empty, all symbol types are included.
    /// </summary>
    public IReadOnlyList<SymbolType>? SymbolTypes { get; init; }
}

/// <summary>
/// Reranking strategy for search results.
/// </summary>
public enum RerankingStrategy
{
    /// <summary>
    /// Use embedding similarity only (no reranking).
    /// Fastest option but may miss keyword relevance.
    /// </summary>
    None = 0,

    /// <summary>
    /// Apply keyword matching bonus to results.
    /// Boosts results that contain query keywords.
    /// </summary>
    KeywordBoost = 1,

    /// <summary>
    /// Use Reciprocal Rank Fusion (RRF) to combine semantic and keyword rankings.
    /// Balances embedding similarity with keyword relevance.
    /// </summary>
    RRF = 2,

    /// <summary>
    /// Use a cross-encoder model for reranking.
    /// Most accurate but slowest. Reserved for future implementation.
    /// </summary>
    CrossEncoder = 3
}
```

### File: `src/SeniorIntern.Core/Models/KnowledgeQueryResult.cs`

```csharp
using System;
using System.Collections.Generic;

namespace SeniorIntern.Core.Models;

/// <summary>
/// Result of a knowledge base query.
/// </summary>
public sealed class KnowledgeQueryResult
{
    /// <summary>
    /// Retrieved code/text chunks with relevance scores.
    /// Ordered by relevance (highest first).
    /// </summary>
    public IReadOnlyList<KnowledgeChunk> Chunks { get; init; } = Array.Empty<KnowledgeChunk>();

    /// <summary>
    /// Unique file paths containing relevant information.
    /// </summary>
    public IReadOnlyList<string> RelevantFiles { get; init; } = Array.Empty<string>();

    /// <summary>
    /// Total time spent processing the query.
    /// </summary>
    public TimeSpan QueryTime { get; init; }

    /// <summary>
    /// Total number of chunks searched in the index.
    /// </summary>
    public int TotalChunksSearched { get; init; }

    /// <summary>
    /// Number of chunks that passed the minimum relevance threshold.
    /// </summary>
    public int ChunksAboveThreshold { get; init; }

    /// <summary>
    /// The embedding vector generated for the query.
    /// Useful for debugging or caching.
    /// </summary>
    public float[]? QueryEmbedding { get; init; }

    /// <summary>
    /// Whether the results were reranked.
    /// </summary>
    public bool WasReranked { get; init; }

    /// <summary>
    /// Reranking strategy that was applied.
    /// </summary>
    public RerankingStrategy RerankingApplied { get; init; }

    /// <summary>
    /// Whether the query hit the cache.
    /// </summary>
    public bool CacheHit { get; init; }

    /// <summary>
    /// Empty result singleton.
    /// </summary>
    public static KnowledgeQueryResult Empty { get; } = new()
    {
        Chunks = Array.Empty<KnowledgeChunk>(),
        RelevantFiles = Array.Empty<string>()
    };

    /// <summary>
    /// Whether the query returned any results.
    /// </summary>
    public bool HasResults => Chunks.Count > 0;
}

/// <summary>
/// A chunk of knowledge (code/text) with relevance metadata.
/// </summary>
public sealed class KnowledgeChunk
{
    /// <summary>
    /// The code/text content of this chunk.
    /// </summary>
    public string Content { get; init; } = string.Empty;

    /// <summary>
    /// File path relative to the workspace root.
    /// </summary>
    public string FilePath { get; init; } = string.Empty;

    /// <summary>
    /// Starting line number (1-based).
    /// </summary>
    public int StartLine { get; init; }

    /// <summary>
    /// Ending line number (1-based).
    /// </summary>
    public int EndLine { get; init; }

    /// <summary>
    /// Relevance score (0.0 to 1.0, higher is more relevant).
    /// </summary>
    public float Relevance { get; init; }

    /// <summary>
    /// Programming language of the content.
    /// </summary>
    public string? Language { get; init; }

    /// <summary>
    /// Symbol name if this chunk represents a code symbol.
    /// Example: "UserService", "CalculateTotal"
    /// </summary>
    public string? SymbolName { get; init; }

    /// <summary>
    /// Symbol type if applicable.
    /// </summary>
    public SymbolType? SymbolType { get; init; }

    /// <summary>
    /// Expanded context including surrounding lines.
    /// Only populated if ExpandContext was requested.
    /// </summary>
    public string? ExpandedContext { get; init; }

    /// <summary>
    /// Highlighted ranges in the content where keywords match.
    /// Tuples of (StartIndex, Length).
    /// </summary>
    public IReadOnlyList<TextHighlight>? Highlights { get; init; }

    /// <summary>
    /// Original similarity score before reranking.
    /// </summary>
    public float OriginalScore { get; init; }

    /// <summary>
    /// Internal chunk ID for reference.
    /// </summary>
    public string ChunkId { get; init; } = string.Empty;

    /// <summary>
    /// Hash of the source file when this chunk was indexed.
    /// </summary>
    public string? FileHash { get; init; }
}

/// <summary>
/// Represents a highlighted region in text.
/// </summary>
public sealed class TextHighlight
{
    /// <summary>
    /// Start index in the content string.
    /// </summary>
    public int Start { get; init; }

    /// <summary>
    /// Length of the highlighted region.
    /// </summary>
    public int Length { get; init; }

    /// <summary>
    /// The keyword or phrase that was matched.
    /// </summary>
    public string? MatchedKeyword { get; init; }
}

/// <summary>
/// A file that contains relevant information.
/// </summary>
public sealed class RelevantFile
{
    /// <summary>
    /// File path relative to workspace root.
    /// </summary>
    public string FilePath { get; init; } = string.Empty;

    /// <summary>
    /// Aggregate relevance score for this file.
    /// </summary>
    public float Relevance { get; init; }

    /// <summary>
    /// Number of matching chunks in this file.
    /// </summary>
    public int MatchCount { get; init; }

    /// <summary>
    /// Brief summary or first match preview.
    /// </summary>
    public string? Summary { get; init; }

    /// <summary>
    /// Programming language of the file.
    /// </summary>
    public string? Language { get; init; }

    /// <summary>
    /// Line numbers of matches in the file.
    /// </summary>
    public IReadOnlyList<int>? MatchLines { get; init; }
}
```

### File: `src/SeniorIntern.Core/Models/KnowledgeIndexHealth.cs`

```csharp
using System;

namespace SeniorIntern.Core.Models;

/// <summary>
/// Health and statistics for a knowledge index.
/// </summary>
public sealed class KnowledgeIndexHealth
{
    /// <summary>
    /// Whether the workspace has been indexed.
    /// </summary>
    public bool IsIndexed { get; init; }

    /// <summary>
    /// Unique identifier of the index.
    /// </summary>
    public string? IndexId { get; init; }

    /// <summary>
    /// Name of the index.
    /// </summary>
    public string? IndexName { get; init; }

    /// <summary>
    /// Total number of files in the index.
    /// </summary>
    public int TotalFiles { get; init; }

    /// <summary>
    /// Total number of chunks in the index.
    /// </summary>
    public int TotalChunks { get; init; }

    /// <summary>
    /// When the index was last updated.
    /// </summary>
    public DateTime? LastUpdated { get; init; }

    /// <summary>
    /// When the index was created.
    /// </summary>
    public DateTime? CreatedAt { get; init; }

    /// <summary>
    /// Number of files that have changed since last index.
    /// </summary>
    public int StaleFiles { get; init; }

    /// <summary>
    /// Whether the index needs to be rebuilt (too many stale files).
    /// </summary>
    public bool NeedsReindex { get; init; }

    /// <summary>
    /// Path to the embedding model used for this index.
    /// </summary>
    public string? EmbeddingModel { get; init; }

    /// <summary>
    /// Dimension of the embedding vectors.
    /// </summary>
    public int EmbeddingDimension { get; init; }

    /// <summary>
    /// Total size of the index in bytes.
    /// </summary>
    public long IndexSizeBytes { get; init; }

    /// <summary>
    /// Average chunks per file.
    /// </summary>
    public double AverageChunksPerFile => TotalFiles > 0 ? (double)TotalChunks / TotalFiles : 0;

    /// <summary>
    /// Percentage of stale files.
    /// </summary>
    public double StalePercentage => TotalFiles > 0 ? (double)StaleFiles / TotalFiles * 100 : 0;

    /// <summary>
    /// Human-readable index size.
    /// </summary>
    public string FormattedSize => FormatBytes(IndexSizeBytes);

    /// <summary>
    /// Status message for display.
    /// </summary>
    public string StatusMessage => GetStatusMessage();

    private string GetStatusMessage()
    {
        if (!IsIndexed)
            return "Not indexed";
        if (NeedsReindex)
            return $"Needs reindex ({StaleFiles} stale files)";
        if (StaleFiles > 0)
            return $"Up to date ({StaleFiles} files changed)";
        return "Up to date";
    }

    private static string FormatBytes(long bytes)
    {
        return bytes switch
        {
            < 1024 => $"{bytes} B",
            < 1024 * 1024 => $"{bytes / 1024.0:F1} KB",
            < 1024 * 1024 * 1024 => $"{bytes / (1024.0 * 1024):F1} MB",
            _ => $"{bytes / (1024.0 * 1024 * 1024):F2} GB"
        };
    }

    /// <summary>
    /// Empty health status for unindexed workspace.
    /// </summary>
    public static KnowledgeIndexHealth NotIndexed { get; } = new()
    {
        IsIndexed = false
    };
}
```

### Dependencies
- None (pure data models)

### Implementation Notes
1. `KnowledgeQueryOptions` provides comprehensive filtering and control over search behavior
2. `KnowledgeChunk` contains both the content and rich metadata for UI display
3. `TextHighlight` enables keyword highlighting in search results
4. `KnowledgeIndexHealth` provides dashboard-ready statistics

---

## v0.7.4c: Context Building Models

### Objective
Define models for context assembly, including format options and token budgeting.

### File: `src/SeniorIntern.Core/Models/ContextBuildOptions.cs`

```csharp
using System;
using System.Collections.Generic;

namespace SeniorIntern.Core.Models;

/// <summary>
/// Options for building context strings for LLM prompts.
/// </summary>
public sealed class ContextBuildOptions
{
    /// <summary>
    /// Workspace path to retrieve context from. Required.
    /// </summary>
    public string WorkspacePath { get; init; } = string.Empty;

    /// <summary>
    /// Maximum tokens to include in the context.
    /// Context will be truncated to fit within this budget.
    /// Default: 4000
    /// </summary>
    public int MaxTokens { get; init; } = 4000;

    /// <summary>
    /// Maximum number of chunks to include.
    /// Default: 10
    /// </summary>
    public int MaxChunks { get; init; } = 10;

    /// <summary>
    /// Minimum relevance score for included chunks.
    /// Default: 0.5
    /// </summary>
    public float MinRelevance { get; init; } = 0.5f;

    /// <summary>
    /// Whether to include file path headers above each chunk.
    /// Default: true
    /// </summary>
    public bool IncludeFileHeaders { get; init; } = true;

    /// <summary>
    /// Whether to include line numbers in headers.
    /// Default: true
    /// </summary>
    public bool IncludeLineNumbers { get; init; } = true;

    /// <summary>
    /// Output format for the context string.
    /// Default: Markdown
    /// </summary>
    public ContextFormat Format { get; init; } = ContextFormat.Markdown;

    /// <summary>
    /// Whether to expand context around matched chunks.
    /// Default: true
    /// </summary>
    public bool ExpandContext { get; init; } = true;

    /// <summary>
    /// Lines of context to include around matches.
    /// Default: 5
    /// </summary>
    public int ContextLines { get; init; } = 5;

    /// <summary>
    /// Whether to group chunks by file.
    /// When true, all chunks from the same file are grouped together.
    /// Default: true
    /// </summary>
    public bool GroupByFile { get; init; } = true;

    /// <summary>
    /// Whether to include relevance scores in output.
    /// Useful for debugging but may confuse the LLM.
    /// Default: false
    /// </summary>
    public bool IncludeScores { get; init; } = false;

    /// <summary>
    /// File patterns to filter context.
    /// </summary>
    public IReadOnlyList<string>? FilePatterns { get; init; }

    /// <summary>
    /// Language filters for context.
    /// </summary>
    public IReadOnlyList<string>? Languages { get; init; }

    /// <summary>
    /// Separator between chunks in the output.
    /// Default: "\n\n"
    /// </summary>
    public string ChunkSeparator { get; init; } = "\n\n";

    /// <summary>
    /// Optional header to prepend to the context.
    /// </summary>
    public string? ContextHeader { get; init; }

    /// <summary>
    /// Optional footer to append to the context.
    /// </summary>
    public string? ContextFooter { get; init; }

    /// <summary>
    /// Reranking strategy to use when retrieving chunks.
    /// Default: KeywordBoost
    /// </summary>
    public RerankingStrategy Reranking { get; init; } = RerankingStrategy.KeywordBoost;

    /// <summary>
    /// Token estimation method.
    /// Default: CharacterBased (fast approximation)
    /// </summary>
    public TokenEstimationMethod TokenEstimation { get; init; } = TokenEstimationMethod.CharacterBased;
}

/// <summary>
/// Output format for context strings.
/// </summary>
public enum ContextFormat
{
    /// <summary>
    /// Markdown format with code blocks and headers.
    /// Best for models that understand markdown.
    /// </summary>
    Markdown = 0,

    /// <summary>
    /// Plain text format with minimal formatting.
    /// Most compatible but loses structure.
    /// </summary>
    Plain = 1,

    /// <summary>
    /// XML format with structured tags.
    /// Best for models trained on XML-structured data.
    /// </summary>
    Xml = 2,

    /// <summary>
    /// JSON format for structured output.
    /// Useful for programmatic processing.
    /// </summary>
    Json = 3
}

/// <summary>
/// Method for estimating token count.
/// </summary>
public enum TokenEstimationMethod
{
    /// <summary>
    /// Estimate based on character count (~4 chars per token).
    /// Fast but less accurate.
    /// </summary>
    CharacterBased = 0,

    /// <summary>
    /// Estimate based on word count (~1.3 tokens per word).
    /// More accurate for natural language.
    /// </summary>
    WordBased = 1,

    /// <summary>
    /// Use actual tokenizer for exact count.
    /// Most accurate but slowest.
    /// </summary>
    Tokenizer = 2
}
```

### File: `src/SeniorIntern.Core/Models/ContextBuildResult.cs`

```csharp
using System;
using System.Collections.Generic;

namespace SeniorIntern.Core.Models;

/// <summary>
/// Result of context building operation.
/// </summary>
public sealed class ContextBuildResult
{
    /// <summary>
    /// The assembled context string.
    /// </summary>
    public string Context { get; init; } = string.Empty;

    /// <summary>
    /// Estimated token count of the context.
    /// </summary>
    public int EstimatedTokens { get; init; }

    /// <summary>
    /// Number of chunks included in the context.
    /// </summary>
    public int ChunksIncluded { get; init; }

    /// <summary>
    /// Number of chunks that were truncated due to token budget.
    /// </summary>
    public int ChunksTruncated { get; init; }

    /// <summary>
    /// Files included in the context.
    /// </summary>
    public IReadOnlyList<string> FilesIncluded { get; init; } = Array.Empty<string>();

    /// <summary>
    /// Whether the context was truncated to fit the token budget.
    /// </summary>
    public bool WasTruncated { get; init; }

    /// <summary>
    /// The format used for the context.
    /// </summary>
    public ContextFormat Format { get; init; }

    /// <summary>
    /// Time spent building the context.
    /// </summary>
    public TimeSpan BuildTime { get; init; }

    /// <summary>
    /// Average relevance score of included chunks.
    /// </summary>
    public float AverageRelevance { get; init; }

    /// <summary>
    /// Whether the context is empty.
    /// </summary>
    public bool IsEmpty => string.IsNullOrWhiteSpace(Context);

    /// <summary>
    /// Empty result singleton.
    /// </summary>
    public static ContextBuildResult Empty { get; } = new()
    {
        Context = string.Empty,
        FilesIncluded = Array.Empty<string>()
    };
}

/// <summary>
/// Represents a formatted chunk ready for context assembly.
/// </summary>
public sealed class FormattedChunk
{
    /// <summary>
    /// The formatted content (with headers, code blocks, etc.).
    /// </summary>
    public string FormattedContent { get; init; } = string.Empty;

    /// <summary>
    /// Estimated token count for this chunk.
    /// </summary>
    public int EstimatedTokens { get; init; }

    /// <summary>
    /// Source file path.
    /// </summary>
    public string FilePath { get; init; } = string.Empty;

    /// <summary>
    /// Relevance score of the source chunk.
    /// </summary>
    public float Relevance { get; init; }

    /// <summary>
    /// Original chunk for reference.
    /// </summary>
    public KnowledgeChunk? SourceChunk { get; init; }
}
```

### Dependencies
- `SeniorIntern.Core.Models.KnowledgeChunk` (from v0.7.4b)

### Implementation Notes
1. `ContextBuildOptions` provides fine-grained control over context formatting
2. Multiple output formats support different LLM preferences
3. Token budgeting ensures context fits within model limits
4. `ContextBuildResult` provides metadata for UI feedback

---

## v0.7.4d: Knowledge Service Implementation

### Objective
Implement the core `KnowledgeService` class that orchestrates retrieval, reranking, and context assembly.

### File: `src/SeniorIntern.Services/Knowledge/KnowledgeService.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge;

/// <summary>
/// High-level knowledge retrieval service for RAG.
/// Orchestrates embedding generation, vector search, reranking, and context assembly.
/// </summary>
public sealed class KnowledgeService : IKnowledgeService
{
    private readonly IVectorStore _vectorStore;
    private readonly IEmbeddingService _embeddingService;
    private readonly IRerankingStrategyFactory _rerankingFactory;
    private readonly IContextAssembler _contextAssembler;
    private readonly IContextExpander _contextExpander;
    private readonly ILogger<KnowledgeService> _logger;

    // Query cache for repeated queries
    private readonly QueryCache _queryCache;

    public KnowledgeService(
        IVectorStore vectorStore,
        IEmbeddingService embeddingService,
        IRerankingStrategyFactory rerankingFactory,
        IContextAssembler contextAssembler,
        IContextExpander contextExpander,
        ILogger<KnowledgeService> logger)
    {
        _vectorStore = vectorStore ?? throw new ArgumentNullException(nameof(vectorStore));
        _embeddingService = embeddingService ?? throw new ArgumentNullException(nameof(embeddingService));
        _rerankingFactory = rerankingFactory ?? throw new ArgumentNullException(nameof(rerankingFactory));
        _contextAssembler = contextAssembler ?? throw new ArgumentNullException(nameof(contextAssembler));
        _contextExpander = contextExpander ?? throw new ArgumentNullException(nameof(contextExpander));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
        _queryCache = new QueryCache(maxSize: 100, expiration: TimeSpan.FromMinutes(5));
    }

    /// <inheritdoc />
    public async Task<KnowledgeQueryResult> QueryAsync(
        string question,
        KnowledgeQueryOptions options,
        CancellationToken ct = default)
    {
        if (string.IsNullOrWhiteSpace(question))
            throw new ArgumentException("Question cannot be empty", nameof(question));

        if (string.IsNullOrWhiteSpace(options.WorkspacePath))
            throw new ArgumentException("WorkspacePath is required", nameof(options));

        var stopwatch = Stopwatch.StartNew();
        _logger.LogDebug("Querying knowledge base: {Question}", question);

        // Check cache first
        var cacheKey = ComputeCacheKey(question, options);
        if (_queryCache.TryGet(cacheKey, out var cachedResult))
        {
            _logger.LogDebug("Query cache hit for: {Question}", question);
            return cachedResult! with { CacheHit = true };
        }

        // Get index for workspace
        var index = await _vectorStore.GetIndexForWorkspaceAsync(options.WorkspacePath, ct);
        if (index == null)
        {
            _logger.LogWarning("No index found for workspace: {Path}", options.WorkspacePath);
            return KnowledgeQueryResult.Empty;
        }

        // Generate query embedding
        float[] queryEmbedding;
        try
        {
            queryEmbedding = await _embeddingService.EmbedAsync(question, ct);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to generate query embedding");
            throw new KnowledgeQueryException("Failed to generate query embedding", ex);
        }

        // Build vector search options
        var searchOptions = new VectorSearchOptions
        {
            TopK = options.MaxResults * 2, // Over-fetch for reranking
            MinScore = options.MinRelevance * 0.8f, // Lower threshold before reranking
            FilePatterns = options.FilePatterns,
            Languages = options.Languages,
            IncludeContent = true,
            Deduplicate = options.DeduplicateChunks
        };

        // Perform vector search
        var searchResults = await _vectorStore.SearchAsync(
            index.Id,
            queryEmbedding,
            searchOptions,
            ct);

        if (searchResults.Count == 0)
        {
            _logger.LogDebug("No results found for query: {Question}", question);
            return new KnowledgeQueryResult
            {
                QueryTime = stopwatch.Elapsed,
                TotalChunksSearched = index.ChunkCount,
                QueryEmbedding = queryEmbedding
            };
        }

        // Apply reranking if requested
        var rankedResults = searchResults;
        var wasReranked = false;

        if (options.Reranking != RerankingStrategy.None)
        {
            var reranker = _rerankingFactory.Create(options.Reranking);
            if (reranker != null)
            {
                rankedResults = await reranker.RerankAsync(searchResults, question, ct);
                wasReranked = true;
                _logger.LogDebug("Applied {Strategy} reranking", options.Reranking);
            }
        }

        // Filter by minimum relevance and take top results
        var topResults = rankedResults
            .Where(r => r.Score >= options.MinRelevance)
            .OrderByDescending(r => r.Score)
            .Take(options.MaxResults)
            .ToList();

        // Convert to KnowledgeChunks and expand context
        var chunks = new List<KnowledgeChunk>();
        foreach (var result in topResults)
        {
            var chunk = await ConvertToKnowledgeChunkAsync(
                result,
                options,
                ct);
            chunks.Add(chunk);
        }

        // Get unique files
        var relevantFiles = chunks
            .Select(c => c.FilePath)
            .Distinct()
            .ToList();

        stopwatch.Stop();

        var queryResult = new KnowledgeQueryResult
        {
            Chunks = chunks,
            RelevantFiles = relevantFiles,
            QueryTime = stopwatch.Elapsed,
            TotalChunksSearched = index.ChunkCount,
            ChunksAboveThreshold = topResults.Count,
            QueryEmbedding = queryEmbedding,
            WasReranked = wasReranked,
            RerankingApplied = options.Reranking,
            CacheHit = false
        };

        // Cache the result
        _queryCache.Set(cacheKey, queryResult);

        _logger.LogInformation(
            "Query completed in {Time}ms: {ResultCount} results from {TotalChunks} chunks",
            stopwatch.ElapsedMilliseconds,
            chunks.Count,
            index.ChunkCount);

        return queryResult;
    }

    /// <inheritdoc />
    public async Task<string> BuildContextAsync(
        string question,
        ContextBuildOptions options,
        CancellationToken ct = default)
    {
        var queryResult = await QueryAsync(question, new KnowledgeQueryOptions
        {
            WorkspacePath = options.WorkspacePath,
            MaxResults = options.MaxChunks,
            MinRelevance = options.MinRelevance,
            ExpandContext = options.ExpandContext,
            ContextLines = options.ContextLines,
            FilePatterns = options.FilePatterns,
            Languages = options.Languages,
            Reranking = options.Reranking
        }, ct);

        if (!queryResult.HasResults)
            return string.Empty;

        return await BuildContextFromChunksAsync(queryResult.Chunks, options, ct);
    }

    /// <inheritdoc />
    public async Task<string> BuildContextFromChunksAsync(
        IReadOnlyList<KnowledgeChunk> chunks,
        ContextBuildOptions options,
        CancellationToken ct = default)
    {
        if (chunks.Count == 0)
            return string.Empty;

        var result = await _contextAssembler.AssembleAsync(chunks, options, ct);
        return result.Context;
    }

    /// <inheritdoc />
    public async Task<IReadOnlyList<RelevantFile>> FindRelevantFilesAsync(
        string query,
        string workspacePath,
        int maxFiles = 10,
        CancellationToken ct = default)
    {
        var result = await QueryAsync(query, new KnowledgeQueryOptions
        {
            WorkspacePath = workspacePath,
            MaxResults = maxFiles * 3, // Get more chunks to aggregate by file
            MinRelevance = 0.4f, // Lower threshold for file discovery
            IncludeSnippets = false,
            ExpandContext = false
        }, ct);

        // Aggregate by file
        var fileGroups = result.Chunks
            .GroupBy(c => c.FilePath)
            .Select(g => new RelevantFile
            {
                FilePath = g.Key,
                Relevance = g.Max(c => c.Relevance),
                MatchCount = g.Count(),
                Summary = g.First().Content.Length > 100
                    ? g.First().Content[..100] + "..."
                    : g.First().Content,
                Language = g.First().Language,
                MatchLines = g.Select(c => c.StartLine).Distinct().OrderBy(l => l).ToList()
            })
            .OrderByDescending(f => f.Relevance)
            .ThenByDescending(f => f.MatchCount)
            .Take(maxFiles)
            .ToList();

        return fileGroups;
    }

    /// <inheritdoc />
    public async Task<bool> IsIndexedAsync(string workspacePath, CancellationToken ct = default)
    {
        var index = await _vectorStore.GetIndexForWorkspaceAsync(workspacePath, ct);
        return index != null;
    }

    /// <inheritdoc />
    public async Task<KnowledgeIndexHealth> GetIndexHealthAsync(
        string workspacePath,
        CancellationToken ct = default)
    {
        var index = await _vectorStore.GetIndexForWorkspaceAsync(workspacePath, ct);

        if (index == null)
            return KnowledgeIndexHealth.NotIndexed;

        var stats = await _vectorStore.GetStatisticsAsync(index.Id, ct);
        var staleCount = await _vectorStore.GetStaleFileCountAsync(index.Id, ct);

        return new KnowledgeIndexHealth
        {
            IsIndexed = true,
            IndexId = index.Id,
            IndexName = index.Name,
            TotalFiles = stats.FileCount,
            TotalChunks = stats.ChunkCount,
            LastUpdated = index.UpdatedAt,
            CreatedAt = index.CreatedAt,
            StaleFiles = staleCount,
            NeedsReindex = staleCount > stats.FileCount * 0.3, // >30% stale = needs reindex
            EmbeddingModel = index.Settings.EmbeddingModelPath,
            EmbeddingDimension = index.EmbeddingDimension,
            IndexSizeBytes = stats.TotalSizeBytes
        };
    }

    /// <inheritdoc />
    public async Task<IReadOnlyList<string>> GetQuerySuggestionsAsync(
        string partialQuery,
        string workspacePath,
        int maxSuggestions = 5,
        CancellationToken ct = default)
    {
        // For now, return symbol names that match the partial query
        // Future: Use query history or common patterns
        var index = await _vectorStore.GetIndexForWorkspaceAsync(workspacePath, ct);
        if (index == null)
            return Array.Empty<string>();

        var symbols = await _vectorStore.SearchSymbolsAsync(
            index.Id,
            partialQuery,
            maxSuggestions,
            ct);

        return symbols
            .Where(s => !string.IsNullOrEmpty(s))
            .Distinct()
            .Take(maxSuggestions)
            .ToList();
    }

    private async Task<KnowledgeChunk> ConvertToKnowledgeChunkAsync(
        ChunkSearchResult result,
        KnowledgeQueryOptions options,
        CancellationToken ct)
    {
        string? expandedContext = null;

        if (options.ExpandContext)
        {
            expandedContext = await _contextExpander.ExpandAsync(
                options.WorkspacePath,
                result.Chunk,
                options.ContextLines,
                ct);
        }

        return new KnowledgeChunk
        {
            Content = result.Chunk.Content,
            FilePath = result.Chunk.FilePath,
            StartLine = result.Chunk.StartLine,
            EndLine = result.Chunk.EndLine,
            Relevance = result.Score,
            Language = result.Chunk.Language,
            SymbolName = result.Chunk.SymbolName,
            SymbolType = result.Chunk.SymbolType,
            ExpandedContext = expandedContext,
            OriginalScore = result.OriginalScore,
            ChunkId = result.ChunkId,
            FileHash = result.Chunk.FileHash
        };
    }

    private static string ComputeCacheKey(string question, KnowledgeQueryOptions options)
    {
        // Simple cache key based on query and key options
        var keyParts = new[]
        {
            question,
            options.WorkspacePath,
            options.MaxResults.ToString(),
            options.MinRelevance.ToString("F2"),
            options.Reranking.ToString(),
            string.Join(",", options.FilePatterns ?? Array.Empty<string>()),
            string.Join(",", options.Languages ?? Array.Empty<string>())
        };

        return string.Join("|", keyParts);
    }
}
```

### File: `src/SeniorIntern.Services/Knowledge/KnowledgeService.Helpers.cs`

```csharp
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Threading;

namespace SeniorIntern.Services.Knowledge;

/// <summary>
/// Simple in-memory cache for query results.
/// </summary>
internal sealed class QueryCache
{
    private readonly ConcurrentDictionary<string, CacheEntry> _cache = new();
    private readonly int _maxSize;
    private readonly TimeSpan _expiration;
    private int _accessCounter;

    public QueryCache(int maxSize, TimeSpan expiration)
    {
        _maxSize = maxSize;
        _expiration = expiration;
    }

    public bool TryGet<T>(string key, out T? value) where T : class
    {
        value = default;

        if (!_cache.TryGetValue(key, out var entry))
            return false;

        if (DateTime.UtcNow > entry.ExpiresAt)
        {
            _cache.TryRemove(key, out _);
            return false;
        }

        entry.LastAccess = Interlocked.Increment(ref _accessCounter);
        value = entry.Value as T;
        return value != null;
    }

    public void Set<T>(string key, T value) where T : class
    {
        // Evict old entries if at capacity
        if (_cache.Count >= _maxSize)
        {
            EvictOldest();
        }

        var entry = new CacheEntry
        {
            Value = value,
            ExpiresAt = DateTime.UtcNow.Add(_expiration),
            LastAccess = Interlocked.Increment(ref _accessCounter)
        };

        _cache.AddOrUpdate(key, entry, (_, _) => entry);
    }

    public void Clear()
    {
        _cache.Clear();
    }

    private void EvictOldest()
    {
        // Find and remove the entry with the lowest access counter
        var oldest = default(KeyValuePair<string, CacheEntry>);
        var oldestAccess = int.MaxValue;

        foreach (var kvp in _cache)
        {
            if (kvp.Value.LastAccess < oldestAccess)
            {
                oldest = kvp;
                oldestAccess = kvp.Value.LastAccess;
            }
        }

        if (oldest.Key != null)
        {
            _cache.TryRemove(oldest.Key, out _);
        }
    }

    private sealed class CacheEntry
    {
        public object Value { get; init; } = null!;
        public DateTime ExpiresAt { get; init; }
        public int LastAccess { get; set; }
    }
}

/// <summary>
/// Exception thrown when a knowledge query fails.
/// </summary>
public sealed class KnowledgeQueryException : Exception
{
    public KnowledgeQueryException(string message) : base(message) { }
    public KnowledgeQueryException(string message, Exception inner) : base(message, inner) { }
}
```

### File: `src/SeniorIntern.Services/Knowledge/Interfaces/IRerankingStrategyFactory.cs`

```csharp
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Interfaces;

/// <summary>
/// Factory for creating reranking strategy instances.
/// </summary>
public interface IRerankingStrategyFactory
{
    /// <summary>
    /// Create a reranking strategy instance.
    /// </summary>
    /// <param name="strategy">The strategy type to create.</param>
    /// <returns>The strategy instance, or null if not supported.</returns>
    IRerankingStrategy? Create(RerankingStrategy strategy);

    /// <summary>
    /// Check if a strategy is supported.
    /// </summary>
    bool IsSupported(RerankingStrategy strategy);
}
```

### File to Modify: `src/SeniorIntern.Services/DependencyInjection.cs`

Add registration for knowledge service:

```csharp
// Add in the ConfigureServices method:
services.AddSingleton<IKnowledgeService, KnowledgeService>();
services.AddSingleton<IRerankingStrategyFactory, RerankingStrategyFactory>();
services.AddSingleton<IContextAssembler, ContextAssembler>();
services.AddSingleton<IContextExpander, FileContextExpander>();
```

### Dependencies
- `IVectorStore` from v0.7.2
- `IEmbeddingService` from v0.7.1
- All models from v0.7.4b and v0.7.4c

### Implementation Notes
1. Query caching improves performance for repeated queries
2. Over-fetching before reranking ensures best results after filtering
3. The service coordinates multiple components without tight coupling
4. Exception handling provides clear error messages

---

## v0.7.4e: Reranking Strategies

### Objective
Implement multiple reranking strategies to improve search result relevance beyond pure embedding similarity.

### File: `src/SeniorIntern.Services/Knowledge/Reranking/RerankingStrategyFactory.cs`

```csharp
using System;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;
using SeniorIntern.Services.Knowledge.Interfaces;

namespace SeniorIntern.Services.Knowledge.Reranking;

/// <summary>
/// Factory for creating reranking strategy instances.
/// </summary>
public sealed class RerankingStrategyFactory : IRerankingStrategyFactory
{
    private readonly ILogger<RerankingStrategyFactory> _logger;
    private readonly ILoggerFactory _loggerFactory;

    public RerankingStrategyFactory(
        ILogger<RerankingStrategyFactory> logger,
        ILoggerFactory loggerFactory)
    {
        _logger = logger;
        _loggerFactory = loggerFactory;
    }

    /// <inheritdoc />
    public IRerankingStrategy? Create(RerankingStrategy strategy)
    {
        return strategy switch
        {
            RerankingStrategy.None => null,
            RerankingStrategy.KeywordBoost => new KeywordBoostStrategy(
                _loggerFactory.CreateLogger<KeywordBoostStrategy>()),
            RerankingStrategy.RRF => new ReciprocalRankFusionStrategy(
                _loggerFactory.CreateLogger<ReciprocalRankFusionStrategy>()),
            RerankingStrategy.CrossEncoder => CreateCrossEncoderStrategy(),
            _ => throw new ArgumentOutOfRangeException(nameof(strategy))
        };
    }

    /// <inheritdoc />
    public bool IsSupported(RerankingStrategy strategy)
    {
        return strategy switch
        {
            RerankingStrategy.None => true,
            RerankingStrategy.KeywordBoost => true,
            RerankingStrategy.RRF => true,
            RerankingStrategy.CrossEncoder => false, // Not yet implemented
            _ => false
        };
    }

    private IRerankingStrategy? CreateCrossEncoderStrategy()
    {
        _logger.LogWarning("CrossEncoder reranking is not yet implemented");
        return null;
    }
}
```

### File: `src/SeniorIntern.Services/Knowledge/Reranking/KeywordBoostStrategy.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text.RegularExpressions;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Reranking;

/// <summary>
/// Reranking strategy that boosts results containing query keywords.
/// </summary>
public sealed class KeywordBoostStrategy : IRerankingStrategy
{
    private readonly ILogger<KeywordBoostStrategy> _logger;

    // Configuration
    private const float BoostPerKeyword = 0.05f;  // 5% boost per keyword match
    private const float ExactMatchBoost = 0.10f;  // 10% boost for exact phrase match
    private const float MaxBoost = 0.30f;         // Maximum 30% total boost

    // Stop words to filter from query
    private static readonly HashSet<string> StopWords = new(StringComparer.OrdinalIgnoreCase)
    {
        "a", "an", "the", "is", "are", "was", "were", "be", "been",
        "being", "have", "has", "had", "do", "does", "did", "will",
        "would", "could", "should", "may", "might", "must", "shall",
        "can", "need", "dare", "ought", "used", "to", "of", "in",
        "for", "on", "with", "at", "by", "from", "as", "into",
        "through", "during", "before", "after", "above", "below",
        "between", "under", "again", "further", "then", "once",
        "where", "how", "what", "which", "who", "whom", "this",
        "that", "these", "those", "am", "or", "and", "but", "if",
        "because", "until", "while", "about", "against", "each",
        "few", "more", "most", "other", "some", "such", "no", "nor",
        "not", "only", "own", "same", "so", "than", "too", "very",
        "just", "also", "now", "here", "there", "when", "why", "all",
        "any", "both", "each", "every"
    };

    public string Name => "KeywordBoost";
    public bool RequiresQueryText => true;

    public KeywordBoostStrategy(ILogger<KeywordBoostStrategy> logger)
    {
        _logger = logger;
    }

    /// <inheritdoc />
    public Task<IReadOnlyList<ChunkSearchResult>> RerankAsync(
        IReadOnlyList<ChunkSearchResult> results,
        string query,
        CancellationToken ct = default)
    {
        if (results.Count == 0)
            return Task.FromResult(results);

        var keywords = ExtractKeywords(query);
        if (keywords.Count == 0)
        {
            _logger.LogDebug("No keywords extracted from query, skipping reranking");
            return Task.FromResult(results);
        }

        _logger.LogDebug("Reranking with {Count} keywords: {Keywords}",
            keywords.Count, string.Join(", ", keywords));

        var reranked = results
            .Select(r => ApplyKeywordBoost(r, keywords, query))
            .OrderByDescending(r => r.Score)
            .ToList();

        return Task.FromResult<IReadOnlyList<ChunkSearchResult>>(reranked);
    }

    private ChunkSearchResult ApplyKeywordBoost(
        ChunkSearchResult result,
        List<string> keywords,
        string originalQuery)
    {
        var content = result.Chunk.Content;
        var totalBoost = 0f;

        // Check for exact phrase match
        if (content.Contains(originalQuery, StringComparison.OrdinalIgnoreCase))
        {
            totalBoost += ExactMatchBoost;
        }

        // Count keyword matches
        var keywordMatchCount = 0;
        foreach (var keyword in keywords)
        {
            if (ContainsKeyword(content, keyword))
            {
                keywordMatchCount++;
            }
        }

        totalBoost += keywordMatchCount * BoostPerKeyword;

        // Apply max boost cap
        totalBoost = Math.Min(totalBoost, MaxBoost);

        if (totalBoost > 0)
        {
            var newScore = Math.Min(1.0f, result.Score + totalBoost);
            return result with
            {
                Score = newScore,
                OriginalScore = result.OriginalScore > 0 ? result.OriginalScore : result.Score
            };
        }

        return result;
    }

    private static bool ContainsKeyword(string content, string keyword)
    {
        // Use word boundary matching for more accurate results
        var pattern = $@"\b{Regex.Escape(keyword)}\b";
        return Regex.IsMatch(content, pattern, RegexOptions.IgnoreCase);
    }

    private static List<string> ExtractKeywords(string query)
    {
        // Split on whitespace and punctuation
        var words = Regex.Split(query, @"[\s\.,;:!?\-\(\)\[\]{}""']+")
            .Where(w => !string.IsNullOrEmpty(w))
            .ToList();

        // Filter stop words and short words
        var keywords = words
            .Where(w => w.Length > 2 && !StopWords.Contains(w))
            .Select(w => w.ToLowerInvariant())
            .Distinct()
            .ToList();

        // Also extract camelCase/PascalCase parts
        var additionalKeywords = new List<string>();
        foreach (var word in words.Where(w => w.Length > 3))
        {
            var parts = SplitCamelCase(word);
            additionalKeywords.AddRange(parts
                .Where(p => p.Length > 2 && !StopWords.Contains(p))
                .Select(p => p.ToLowerInvariant()));
        }

        keywords.AddRange(additionalKeywords);
        return keywords.Distinct().ToList();
    }

    private static IEnumerable<string> SplitCamelCase(string input)
    {
        // Split "UserService" into ["User", "Service"]
        return Regex.Split(input, @"(?<!^)(?=[A-Z])")
            .Where(s => !string.IsNullOrEmpty(s));
    }
}
```

### File: `src/SeniorIntern.Services/Knowledge/Reranking/ReciprocalRankFusionStrategy.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text.RegularExpressions;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Reranking;

/// <summary>
/// Reranking strategy using Reciprocal Rank Fusion (RRF).
/// Combines semantic similarity ranking with keyword-based ranking.
/// </summary>
public sealed class ReciprocalRankFusionStrategy : IRerankingStrategy
{
    private readonly ILogger<ReciprocalRankFusionStrategy> _logger;

    // RRF constant (typically 60, controls how much to penalize lower ranks)
    private const float K = 60f;

    // Weight for semantic vs keyword ranking (1.0 = equal weight)
    private const float SemanticWeight = 1.0f;
    private const float KeywordWeight = 0.8f;

    private static readonly HashSet<string> StopWords = new(StringComparer.OrdinalIgnoreCase)
    {
        "a", "an", "the", "is", "are", "was", "were", "be", "been",
        "being", "have", "has", "had", "do", "does", "did", "will",
        "would", "could", "should", "may", "might", "must", "shall",
        "can", "need", "to", "of", "in", "for", "on", "with", "at",
        "by", "from", "as", "into", "through", "during", "before",
        "after", "where", "how", "what", "which", "who", "this",
        "that", "or", "and", "but", "if", "not", "all", "any"
    };

    public string Name => "RRF";
    public bool RequiresQueryText => true;

    public ReciprocalRankFusionStrategy(ILogger<ReciprocalRankFusionStrategy> logger)
    {
        _logger = logger;
    }

    /// <inheritdoc />
    public Task<IReadOnlyList<ChunkSearchResult>> RerankAsync(
        IReadOnlyList<ChunkSearchResult> results,
        string query,
        CancellationToken ct = default)
    {
        if (results.Count == 0)
            return Task.FromResult(results);

        var keywords = ExtractKeywords(query);
        if (keywords.Count == 0)
        {
            _logger.LogDebug("No keywords for RRF, using semantic ranking only");
            return Task.FromResult(results);
        }

        _logger.LogDebug("Applying RRF with {Count} keywords", keywords.Count);

        // Create semantic ranking (already sorted by score)
        var semanticRanks = results
            .Select((r, i) => (Result: r, Rank: i + 1))
            .ToDictionary(x => x.Result.ChunkId, x => x.Rank);

        // Create keyword ranking based on keyword frequency
        var keywordScores = results
            .Select(r => (
                Result: r,
                Score: CalculateKeywordScore(r.Chunk.Content, keywords)
            ))
            .OrderByDescending(x => x.Score)
            .Select((x, i) => (x.Result, Rank: i + 1))
            .ToDictionary(x => x.Result.ChunkId, x => x.Rank);

        // Calculate RRF scores
        var reranked = results
            .Select(r =>
            {
                var semanticRank = semanticRanks[r.ChunkId];
                var keywordRank = keywordScores.GetValueOrDefault(r.ChunkId, results.Count);

                var rrfScore = CalculateRRFScore(semanticRank, keywordRank);

                return r with
                {
                    Score = rrfScore,
                    OriginalScore = r.OriginalScore > 0 ? r.OriginalScore : r.Score
                };
            })
            .OrderByDescending(r => r.Score)
            .ToList();

        // Normalize scores to 0-1 range
        if (reranked.Count > 0)
        {
            var maxScore = reranked.Max(r => r.Score);
            var minScore = reranked.Min(r => r.Score);
            var range = maxScore - minScore;

            if (range > 0)
            {
                reranked = reranked
                    .Select(r => r with { Score = (r.Score - minScore) / range })
                    .ToList();
            }
        }

        return Task.FromResult<IReadOnlyList<ChunkSearchResult>>(reranked);
    }

    private static float CalculateRRFScore(int semanticRank, int keywordRank)
    {
        // RRF formula: sum of 1/(k + rank) for each ranking
        var semanticContribution = SemanticWeight * (1f / (K + semanticRank));
        var keywordContribution = KeywordWeight * (1f / (K + keywordRank));

        return semanticContribution + keywordContribution;
    }

    private static float CalculateKeywordScore(string content, List<string> keywords)
    {
        var score = 0f;
        var contentLower = content.ToLowerInvariant();

        foreach (var keyword in keywords)
        {
            // Count occurrences (case-insensitive)
            var count = CountOccurrences(contentLower, keyword.ToLowerInvariant());
            score += count;

            // Bonus for word boundary matches
            var wordBoundaryCount = CountWordBoundaryMatches(content, keyword);
            score += wordBoundaryCount * 0.5f;
        }

        return score;
    }

    private static int CountOccurrences(string content, string keyword)
    {
        var count = 0;
        var index = 0;

        while ((index = content.IndexOf(keyword, index, StringComparison.Ordinal)) != -1)
        {
            count++;
            index += keyword.Length;
        }

        return count;
    }

    private static int CountWordBoundaryMatches(string content, string keyword)
    {
        var pattern = $@"\b{Regex.Escape(keyword)}\b";
        return Regex.Matches(content, pattern, RegexOptions.IgnoreCase).Count;
    }

    private static List<string> ExtractKeywords(string query)
    {
        return Regex.Split(query, @"[\s\.,;:!?\-\(\)\[\]{}""']+")
            .Where(w => w.Length > 2 && !StopWords.Contains(w))
            .Select(w => w.ToLowerInvariant())
            .Distinct()
            .ToList();
    }
}
```

### File: `src/SeniorIntern.Services/Knowledge/Reranking/CrossEncoderStrategy.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Reranking;

/// <summary>
/// Reranking strategy using a cross-encoder model.
/// Reserved for future implementation - provides placeholder for architecture.
/// </summary>
public sealed class CrossEncoderStrategy : IRerankingStrategy
{
    private readonly ILogger<CrossEncoderStrategy> _logger;

    public string Name => "CrossEncoder";
    public bool RequiresQueryText => true;

    public CrossEncoderStrategy(ILogger<CrossEncoderStrategy> logger)
    {
        _logger = logger;
    }

    /// <inheritdoc />
    public Task<IReadOnlyList<ChunkSearchResult>> RerankAsync(
        IReadOnlyList<ChunkSearchResult> results,
        string query,
        CancellationToken ct = default)
    {
        // TODO: Implement cross-encoder reranking
        // This would involve:
        // 1. Loading a cross-encoder model (e.g., ms-marco-MiniLM)
        // 2. Scoring each (query, chunk) pair
        // 3. Sorting by cross-encoder scores

        _logger.LogWarning("CrossEncoder reranking is not yet implemented, returning original results");
        return Task.FromResult(results);
    }
}
```

### Dependencies
- `IRerankingStrategy` from v0.7.4a
- `ChunkSearchResult` from v0.7.2

### Implementation Notes
1. `KeywordBoostStrategy` is fast and works well for code search
2. `ReciprocalRankFusionStrategy` combines multiple signals for better accuracy
3. `CrossEncoderStrategy` is a placeholder for future high-accuracy reranking
4. All strategies preserve the original score for reference

---

## v0.7.4f: Context Assembly & Formatting

### Objective
Implement context assembly with multiple output formats and token budget management.

### File: `src/SeniorIntern.Services/Knowledge/Context/IContextAssembler.cs`

```csharp
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Context;

/// <summary>
/// Interface for assembling context strings from knowledge chunks.
/// </summary>
public interface IContextAssembler
{
    /// <summary>
    /// Assemble chunks into a formatted context string.
    /// </summary>
    /// <param name="chunks">Knowledge chunks to assemble.</param>
    /// <param name="options">Assembly options.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Assembly result with context string and metadata.</returns>
    Task<ContextBuildResult> AssembleAsync(
        IReadOnlyList<KnowledgeChunk> chunks,
        ContextBuildOptions options,
        CancellationToken ct = default);
}
```

### File: `src/SeniorIntern.Services/Knowledge/Context/ContextAssembler.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Text;
using System.Text.Json;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Context;

/// <summary>
/// Assembles knowledge chunks into formatted context strings for LLM prompts.
/// </summary>
public sealed class ContextAssembler : IContextAssembler
{
    private readonly ITokenEstimator _tokenEstimator;
    private readonly ILogger<ContextAssembler> _logger;

    public ContextAssembler(
        ITokenEstimator tokenEstimator,
        ILogger<ContextAssembler> logger)
    {
        _tokenEstimator = tokenEstimator;
        _logger = logger;
    }

    /// <inheritdoc />
    public Task<ContextBuildResult> AssembleAsync(
        IReadOnlyList<KnowledgeChunk> chunks,
        ContextBuildOptions options,
        CancellationToken ct = default)
    {
        if (chunks.Count == 0)
            return Task.FromResult(ContextBuildResult.Empty);

        var stopwatch = Stopwatch.StartNew();

        // Optionally group by file
        var orderedChunks = options.GroupByFile
            ? GroupAndOrderChunks(chunks)
            : chunks.ToList();

        // Format chunks
        var formattedChunks = orderedChunks
            .Select(c => FormatChunk(c, options))
            .ToList();

        // Build context with token budget
        var (context, included, truncated) = BuildWithTokenBudget(
            formattedChunks,
            options);

        var filesIncluded = included
            .Select(c => c.FilePath)
            .Distinct()
            .ToList();

        var avgRelevance = included.Count > 0
            ? included.Average(c => c.Relevance)
            : 0f;

        stopwatch.Stop();

        var result = new ContextBuildResult
        {
            Context = context,
            EstimatedTokens = _tokenEstimator.EstimateTokens(context, options.TokenEstimation),
            ChunksIncluded = included.Count,
            ChunksTruncated = truncated,
            FilesIncluded = filesIncluded,
            WasTruncated = truncated > 0,
            Format = options.Format,
            BuildTime = stopwatch.Elapsed,
            AverageRelevance = avgRelevance
        };

        _logger.LogDebug(
            "Built context: {Chunks} chunks, ~{Tokens} tokens, {Time}ms",
            result.ChunksIncluded,
            result.EstimatedTokens,
            stopwatch.ElapsedMilliseconds);

        return Task.FromResult(result);
    }

    private List<KnowledgeChunk> GroupAndOrderChunks(IReadOnlyList<KnowledgeChunk> chunks)
    {
        // Group by file, order groups by max relevance, order chunks within group by line number
        return chunks
            .GroupBy(c => c.FilePath)
            .OrderByDescending(g => g.Max(c => c.Relevance))
            .SelectMany(g => g.OrderBy(c => c.StartLine))
            .ToList();
    }

    private FormattedChunk FormatChunk(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var formatted = options.Format switch
        {
            ContextFormat.Markdown => FormatMarkdown(chunk, options),
            ContextFormat.Xml => FormatXml(chunk, options),
            ContextFormat.Json => FormatJson(chunk, options),
            ContextFormat.Plain => FormatPlain(chunk, options),
            _ => FormatMarkdown(chunk, options)
        };

        return new FormattedChunk
        {
            FormattedContent = formatted,
            EstimatedTokens = _tokenEstimator.EstimateTokens(formatted, options.TokenEstimation),
            FilePath = chunk.FilePath,
            Relevance = chunk.Relevance,
            SourceChunk = chunk
        };
    }

    private static string FormatMarkdown(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var sb = new StringBuilder();

        if (options.IncludeFileHeaders)
        {
            sb.AppendLine($"### {chunk.FilePath}");
            if (options.IncludeLineNumbers)
            {
                sb.AppendLine($"Lines {chunk.StartLine}-{chunk.EndLine}");
            }
            if (options.IncludeScores)
            {
                sb.AppendLine($"Relevance: {chunk.Relevance:P0}");
            }
            sb.AppendLine();
        }

        var language = chunk.Language ?? "text";
        var content = chunk.ExpandedContext ?? chunk.Content;

        sb.AppendLine($"```{language}");
        sb.AppendLine(content);
        sb.AppendLine("```");

        return sb.ToString();
    }

    private static string FormatXml(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var content = chunk.ExpandedContext ?? chunk.Content;
        var escapedContent = System.Security.SecurityElement.Escape(content);

        var attributes = new List<string>
        {
            $"file=\"{System.Security.SecurityElement.Escape(chunk.FilePath)}\""
        };

        if (options.IncludeLineNumbers)
        {
            attributes.Add($"lines=\"{chunk.StartLine}-{chunk.EndLine}\"");
        }

        if (!string.IsNullOrEmpty(chunk.Language))
        {
            attributes.Add($"language=\"{chunk.Language}\"");
        }

        if (options.IncludeScores)
        {
            attributes.Add($"relevance=\"{chunk.Relevance:F2}\"");
        }

        return $"<code-context {string.Join(" ", attributes)}>\n{escapedContent}\n</code-context>";
    }

    private static string FormatJson(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var obj = new Dictionary<string, object>
        {
            ["file"] = chunk.FilePath,
            ["content"] = chunk.ExpandedContext ?? chunk.Content
        };

        if (options.IncludeLineNumbers)
        {
            obj["startLine"] = chunk.StartLine;
            obj["endLine"] = chunk.EndLine;
        }

        if (!string.IsNullOrEmpty(chunk.Language))
        {
            obj["language"] = chunk.Language;
        }

        if (options.IncludeScores)
        {
            obj["relevance"] = chunk.Relevance;
        }

        return JsonSerializer.Serialize(obj, new JsonSerializerOptions { WriteIndented = true });
    }

    private static string FormatPlain(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var sb = new StringBuilder();

        if (options.IncludeFileHeaders)
        {
            sb.Append($"File: {chunk.FilePath}");
            if (options.IncludeLineNumbers)
            {
                sb.Append($" (lines {chunk.StartLine}-{chunk.EndLine})");
            }
            sb.AppendLine();
            sb.AppendLine(new string('-', 40));
        }

        sb.AppendLine(chunk.ExpandedContext ?? chunk.Content);

        return sb.ToString();
    }

    private (string Context, List<FormattedChunk> Included, int Truncated) BuildWithTokenBudget(
        List<FormattedChunk> chunks,
        ContextBuildOptions options)
    {
        var sb = new StringBuilder();
        var included = new List<FormattedChunk>();
        var currentTokens = 0;
        var truncated = 0;

        // Add header if specified
        if (!string.IsNullOrEmpty(options.ContextHeader))
        {
            sb.AppendLine(options.ContextHeader);
            sb.AppendLine();
            currentTokens += _tokenEstimator.EstimateTokens(
                options.ContextHeader, options.TokenEstimation);
        }

        // Reserve tokens for footer
        var footerTokens = 0;
        if (!string.IsNullOrEmpty(options.ContextFooter))
        {
            footerTokens = _tokenEstimator.EstimateTokens(
                options.ContextFooter, options.TokenEstimation) + 10; // buffer
        }

        var availableTokens = options.MaxTokens - footerTokens;

        foreach (var chunk in chunks)
        {
            var chunkTokens = chunk.EstimatedTokens +
                _tokenEstimator.EstimateTokens(options.ChunkSeparator, options.TokenEstimation);

            if (currentTokens + chunkTokens > availableTokens)
            {
                truncated++;
                continue;
            }

            if (included.Count > 0)
            {
                sb.Append(options.ChunkSeparator);
            }

            sb.Append(chunk.FormattedContent);
            included.Add(chunk);
            currentTokens += chunkTokens;

            // Stop if we've hit max chunks
            if (included.Count >= options.MaxChunks)
                break;
        }

        // Add footer if specified
        if (!string.IsNullOrEmpty(options.ContextFooter))
        {
            sb.AppendLine();
            sb.AppendLine(options.ContextFooter);
        }

        return (sb.ToString().TrimEnd(), included, truncated);
    }
}
```

### File: `src/SeniorIntern.Services/Knowledge/Context/TokenEstimator.cs`

```csharp
using System;
using System.Text.RegularExpressions;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Context;

/// <summary>
/// Interface for estimating token counts.
/// </summary>
public interface ITokenEstimator
{
    /// <summary>
    /// Estimate the number of tokens in a text string.
    /// </summary>
    int EstimateTokens(string text, TokenEstimationMethod method = TokenEstimationMethod.CharacterBased);
}

/// <summary>
/// Token count estimation utilities.
/// </summary>
public sealed class TokenEstimator : ITokenEstimator
{
    // Approximations based on typical LLM tokenizers
    private const float CharsPerToken = 4.0f;
    private const float WordsPerToken = 0.75f;

    /// <inheritdoc />
    public int EstimateTokens(string text, TokenEstimationMethod method = TokenEstimationMethod.CharacterBased)
    {
        if (string.IsNullOrEmpty(text))
            return 0;

        return method switch
        {
            TokenEstimationMethod.CharacterBased => EstimateByCharacters(text),
            TokenEstimationMethod.WordBased => EstimateByWords(text),
            TokenEstimationMethod.Tokenizer => EstimateWithTokenizer(text),
            _ => EstimateByCharacters(text)
        };
    }

    private static int EstimateByCharacters(string text)
    {
        // Simple approximation: ~4 characters per token
        // Adjusted for code which tends to have more tokens per character
        var baseEstimate = (int)Math.Ceiling(text.Length / CharsPerToken);

        // Code tends to tokenize differently - adjust for special characters
        var specialCharCount = CountSpecialCharacters(text);
        var adjustment = specialCharCount / 3; // Special chars often become separate tokens

        return baseEstimate + adjustment;
    }

    private static int EstimateByWords(string text)
    {
        // Count words using whitespace splitting
        var words = Regex.Split(text, @"\s+");
        var wordCount = 0;

        foreach (var word in words)
        {
            if (string.IsNullOrEmpty(word))
                continue;

            // Words typically become 1-2 tokens
            wordCount++;

            // Long words or camelCase may become multiple tokens
            if (word.Length > 10)
                wordCount++;

            if (HasMixedCase(word))
                wordCount++;
        }

        return (int)Math.Ceiling(wordCount / WordsPerToken);
    }

    private static int EstimateWithTokenizer(string text)
    {
        // TODO: Implement actual tokenizer-based estimation
        // This would use tiktoken or similar library
        // For now, fall back to character-based
        return EstimateByCharacters(text);
    }

    private static int CountSpecialCharacters(string text)
    {
        var count = 0;
        foreach (var c in text)
        {
            if (!char.IsLetterOrDigit(c) && !char.IsWhiteSpace(c))
                count++;
        }
        return count;
    }

    private static bool HasMixedCase(string word)
    {
        var hasUpper = false;
        var hasLower = false;

        foreach (var c in word)
        {
            if (char.IsUpper(c)) hasUpper = true;
            if (char.IsLower(c)) hasLower = true;
            if (hasUpper && hasLower) return true;
        }

        return false;
    }
}
```

### Dependencies
- `KnowledgeChunk`, `ContextBuildOptions`, `ContextBuildResult` from v0.7.4b/c

### Implementation Notes
1. Multiple output formats support different LLM preferences
2. Token budgeting ensures context fits within model limits
3. Grouping by file improves coherence of related code
4. Token estimation can be upgraded to use actual tokenizers

---

## v0.7.4g: Context Expansion

### Objective
Implement context expansion to include surrounding code lines for better understanding.

### File: `src/SeniorIntern.Services/Knowledge/Context/IContextExpander.cs`

```csharp
using System.Threading;
using System.Threading.Tasks;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Context;

/// <summary>
/// Interface for expanding context around code chunks.
/// </summary>
public interface IContextExpander
{
    /// <summary>
    /// Expand context around a chunk by reading surrounding lines.
    /// </summary>
    /// <param name="workspacePath">Base workspace path.</param>
    /// <param name="chunk">The chunk to expand context for.</param>
    /// <param name="contextLines">Number of lines to include before and after.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Expanded content string, or original content if expansion fails.</returns>
    Task<string> ExpandAsync(
        string workspacePath,
        TextChunk chunk,
        int contextLines,
        CancellationToken ct = default);

    /// <summary>
    /// Expand context for a KnowledgeChunk.
    /// </summary>
    Task<string> ExpandAsync(
        string workspacePath,
        KnowledgeChunk chunk,
        int contextLines,
        CancellationToken ct = default);
}
```

### File: `src/SeniorIntern.Services/Knowledge/Context/FileContextExpander.cs`

```csharp
using System;
using System.Collections.Concurrent;
using System.IO;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Context;

/// <summary>
/// Expands context by reading surrounding lines from source files.
/// </summary>
public sealed class FileContextExpander : IContextExpander
{
    private readonly ILogger<FileContextExpander> _logger;

    // Cache file contents to avoid repeated reads
    private readonly ConcurrentDictionary<string, string[]> _fileCache = new();
    private readonly int _maxCacheSize = 100;
    private readonly TimeSpan _cacheExpiration = TimeSpan.FromMinutes(5);

    public FileContextExpander(ILogger<FileContextExpander> logger)
    {
        _logger = logger;
    }

    /// <inheritdoc />
    public async Task<string> ExpandAsync(
        string workspacePath,
        TextChunk chunk,
        int contextLines,
        CancellationToken ct = default)
    {
        if (contextLines <= 0)
            return chunk.Content;

        try
        {
            var fullPath = Path.Combine(workspacePath, chunk.FilePath);
            var lines = await GetFileLinesAsync(fullPath, ct);

            if (lines == null || lines.Length == 0)
                return chunk.Content;

            // Calculate expanded range (convert to 0-based index)
            var startIndex = Math.Max(0, chunk.StartLine - contextLines - 1);
            var endIndex = Math.Min(lines.Length, chunk.EndLine + contextLines);

            // Extract lines
            var expandedLines = lines
                .Skip(startIndex)
                .Take(endIndex - startIndex)
                .ToArray();

            return string.Join('\n', expandedLines);
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Failed to expand context for {File}", chunk.FilePath);
            return chunk.Content;
        }
    }

    /// <inheritdoc />
    public Task<string> ExpandAsync(
        string workspacePath,
        KnowledgeChunk chunk,
        int contextLines,
        CancellationToken ct = default)
    {
        // Convert KnowledgeChunk to TextChunk for expansion
        var textChunk = new TextChunk
        {
            Content = chunk.Content,
            FilePath = chunk.FilePath,
            StartLine = chunk.StartLine,
            EndLine = chunk.EndLine
        };

        return ExpandAsync(workspacePath, textChunk, contextLines, ct);
    }

    private async Task<string[]?> GetFileLinesAsync(string fullPath, CancellationToken ct)
    {
        // Check cache first
        if (_fileCache.TryGetValue(fullPath, out var cachedLines))
            return cachedLines;

        // Check if file exists
        if (!File.Exists(fullPath))
        {
            _logger.LogDebug("File not found for context expansion: {Path}", fullPath);
            return null;
        }

        try
        {
            var lines = await File.ReadAllLinesAsync(fullPath, ct);

            // Cache if not too large
            if (lines.Length <= 10000 && _fileCache.Count < _maxCacheSize)
            {
                _fileCache.TryAdd(fullPath, lines);
            }

            return lines;
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Failed to read file for context expansion: {Path}", fullPath);
            return null;
        }
    }

    /// <summary>
    /// Clear the file cache.
    /// </summary>
    public void ClearCache()
    {
        _fileCache.Clear();
    }

    /// <summary>
    /// Remove a specific file from cache (e.g., when file changes).
    /// </summary>
    public void InvalidateFile(string fullPath)
    {
        _fileCache.TryRemove(fullPath, out _);
    }
}
```

### Dependencies
- `TextChunk` from v0.7.1
- `KnowledgeChunk` from v0.7.4b

### Implementation Notes
1. File caching improves performance for repeated reads
2. Graceful fallback to original content if expansion fails
3. Cache can be invalidated when files change

---

## v0.7.4h: RAG-Aware Chat Integration

### Objective
Integrate the knowledge service with the chat system to enable RAG-enhanced responses.

### File: `src/SeniorIntern.Services/Chat/IRagChatService.cs`

```csharp
using System.Collections.Generic;
using System.Threading;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Chat;

/// <summary>
/// Interface for RAG-enhanced chat service.
/// </summary>
public interface IRagChatService
{
    /// <summary>
    /// Generate a response with RAG context.
    /// </summary>
    /// <param name="conversationId">Conversation to add message to.</param>
    /// <param name="userMessage">The user's message.</param>
    /// <param name="options">RAG chat options.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Async enumerable of response tokens.</returns>
    IAsyncEnumerable<string> GenerateWithRagAsync(
        System.Guid conversationId,
        string userMessage,
        RagChatOptions options,
        CancellationToken ct = default);

    /// <summary>
    /// Get the context that would be used for a query (without generating response).
    /// Useful for debugging or preview.
    /// </summary>
    /// <param name="userMessage">The user's message.</param>
    /// <param name="options">RAG chat options.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>The context that would be injected.</returns>
    System.Threading.Tasks.Task<RagContextPreview> PreviewContextAsync(
        string userMessage,
        RagChatOptions options,
        CancellationToken ct = default);
}
```

### File: `src/SeniorIntern.Services/Chat/RagChatService.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Chat;

/// <summary>
/// Chat service with RAG (Retrieval-Augmented Generation) support.
/// Integrates knowledge retrieval with LLM response generation.
/// </summary>
public sealed class RagChatService : IRagChatService
{
    private readonly ILlmService _llmService;
    private readonly IKnowledgeService _knowledgeService;
    private readonly IConversationService _conversationService;
    private readonly ILogger<RagChatService> _logger;

    private const string DefaultSystemPrompt = @"
You are The Senior Intern, a helpful coding assistant with knowledge of the user's codebase.
Provide clear, concise answers with code examples when appropriate.
When referencing code from the provided context, mention the file path and line numbers.";

    private const string RagInstructions = @"
You have been provided with relevant code context from the user's codebase.
Use this context to provide accurate, specific answers about their code.
When referencing code:
- Mention the file path and line numbers
- Quote relevant code snippets when helpful
- If the context doesn't contain relevant information, say so and provide general guidance
- Don't make up code that isn't in the context unless clearly creating new code";

    public RagChatService(
        ILlmService llmService,
        IKnowledgeService knowledgeService,
        IConversationService conversationService,
        ILogger<RagChatService> logger)
    {
        _llmService = llmService ?? throw new ArgumentNullException(nameof(llmService));
        _knowledgeService = knowledgeService ?? throw new ArgumentNullException(nameof(knowledgeService));
        _conversationService = conversationService ?? throw new ArgumentNullException(nameof(conversationService));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    /// <inheritdoc />
    public async IAsyncEnumerable<string> GenerateWithRagAsync(
        Guid conversationId,
        string userMessage,
        RagChatOptions options,
        [EnumeratorCancellation] CancellationToken ct = default)
    {
        var conversation = await _conversationService.GetConversationAsync(conversationId, ct);
        if (conversation == null)
            throw new InvalidOperationException($"Conversation not found: {conversationId}");

        // Retrieve RAG context if enabled and workspace is indexed
        string? ragContext = null;
        if (options.EnableRag && !string.IsNullOrEmpty(options.WorkspacePath))
        {
            ragContext = await RetrieveContextAsync(userMessage, options, ct);
        }

        // Build messages with RAG context injected
        var messages = BuildMessagesWithRag(
            conversation.Messages,
            userMessage,
            ragContext,
            options);

        _logger.LogDebug(
            "Generating RAG response: {MessageCount} messages, context: {HasContext}",
            messages.Count(),
            ragContext != null);

        // Stream response from LLM
        await foreach (var token in _llmService.GenerateStreamingAsync(
            messages, options.InferenceOptions, ct))
        {
            yield return token;
        }
    }

    /// <inheritdoc />
    public async Task<RagContextPreview> PreviewContextAsync(
        string userMessage,
        RagChatOptions options,
        CancellationToken ct = default)
    {
        if (!options.EnableRag || string.IsNullOrEmpty(options.WorkspacePath))
        {
            return new RagContextPreview
            {
                IsEnabled = false,
                Reason = options.EnableRag
                    ? "No workspace path configured"
                    : "RAG is disabled"
            };
        }

        var isIndexed = await _knowledgeService.IsIndexedAsync(options.WorkspacePath, ct);
        if (!isIndexed)
        {
            return new RagContextPreview
            {
                IsEnabled = false,
                Reason = "Workspace is not indexed"
            };
        }

        var queryResult = await _knowledgeService.QueryAsync(userMessage, new KnowledgeQueryOptions
        {
            WorkspacePath = options.WorkspacePath,
            MaxResults = options.MaxRagChunks,
            MinRelevance = options.MinRelevance,
            ExpandContext = true
        }, ct);

        var context = await _knowledgeService.BuildContextFromChunksAsync(
            queryResult.Chunks,
            new ContextBuildOptions
            {
                MaxTokens = options.MaxRagTokens,
                Format = ContextFormat.Markdown
            },
            ct);

        return new RagContextPreview
        {
            IsEnabled = true,
            Context = context,
            ChunksFound = queryResult.Chunks.Count,
            FilesFound = queryResult.RelevantFiles.Count,
            QueryTime = queryResult.QueryTime,
            RelevantFiles = queryResult.RelevantFiles.ToList()
        };
    }

    private async Task<string?> RetrieveContextAsync(
        string userMessage,
        RagChatOptions options,
        CancellationToken ct)
    {
        try
        {
            var isIndexed = await _knowledgeService.IsIndexedAsync(options.WorkspacePath!, ct);
            if (!isIndexed)
            {
                _logger.LogDebug("Workspace not indexed, skipping RAG");
                return null;
            }

            var context = await _knowledgeService.BuildContextAsync(
                userMessage,
                new ContextBuildOptions
                {
                    WorkspacePath = options.WorkspacePath!,
                    MaxTokens = options.MaxRagTokens,
                    MaxChunks = options.MaxRagChunks,
                    MinRelevance = options.MinRelevance,
                    Format = ContextFormat.Markdown,
                    IncludeFileHeaders = true,
                    IncludeLineNumbers = true
                },
                ct);

            if (string.IsNullOrWhiteSpace(context))
            {
                _logger.LogDebug("No relevant context found for query");
                return null;
            }

            _logger.LogDebug("Retrieved RAG context: {Length} chars", context.Length);
            return context;
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Failed to retrieve RAG context, continuing without");
            return null;
        }
    }

    private IEnumerable<ChatMessage> BuildMessagesWithRag(
        IEnumerable<ChatMessage> history,
        string userMessage,
        string? ragContext,
        RagChatOptions options)
    {
        // Build system prompt with RAG context
        var systemPrompt = options.SystemPrompt ?? DefaultSystemPrompt;

        if (!string.IsNullOrEmpty(ragContext))
        {
            systemPrompt = $"{systemPrompt}\n\n{RagInstructions}\n\n## Relevant Code Context\n\n{ragContext}";
        }

        yield return new ChatMessage
        {
            Role = MessageRole.System,
            Content = systemPrompt
        };

        // Include conversation history (limited)
        foreach (var msg in history.TakeLast(options.MaxHistoryMessages))
        {
            yield return msg;
        }

        // Current user message
        yield return new ChatMessage
        {
            Role = MessageRole.User,
            Content = userMessage
        };
    }
}
```

### File: `src/SeniorIntern.Core/Models/RagChatModels.cs`

```csharp
using System;
using System.Collections.Generic;

namespace SeniorIntern.Core.Models;

/// <summary>
/// Options for RAG-enhanced chat.
/// </summary>
public sealed class RagChatOptions
{
    /// <summary>
    /// Whether to enable RAG context injection.
    /// Default: true
    /// </summary>
    public bool EnableRag { get; init; } = true;

    /// <summary>
    /// Workspace path to retrieve context from.
    /// </summary>
    public string? WorkspacePath { get; init; }

    /// <summary>
    /// Maximum tokens to use for RAG context.
    /// Default: 4000
    /// </summary>
    public int MaxRagTokens { get; init; } = 4000;

    /// <summary>
    /// Maximum chunks to retrieve for context.
    /// Default: 10
    /// </summary>
    public int MaxRagChunks { get; init; } = 10;

    /// <summary>
    /// Minimum relevance score for included context.
    /// Default: 0.5
    /// </summary>
    public float MinRelevance { get; init; } = 0.5f;

    /// <summary>
    /// Maximum conversation history messages to include.
    /// Default: 20
    /// </summary>
    public int MaxHistoryMessages { get; init; } = 20;

    /// <summary>
    /// Custom system prompt (replaces default).
    /// </summary>
    public string? SystemPrompt { get; init; }

    /// <summary>
    /// Inference options for the LLM.
    /// </summary>
    public InferenceOptions InferenceOptions { get; init; } = new();

    /// <summary>
    /// Whether to include RAG metadata in response (for debugging).
    /// Default: false
    /// </summary>
    public bool IncludeMetadata { get; init; } = false;
}

/// <summary>
/// Preview of RAG context for a query.
/// </summary>
public sealed class RagContextPreview
{
    /// <summary>
    /// Whether RAG is enabled and available.
    /// </summary>
    public bool IsEnabled { get; init; }

    /// <summary>
    /// Reason if RAG is not enabled.
    /// </summary>
    public string? Reason { get; init; }

    /// <summary>
    /// The context that would be injected.
    /// </summary>
    public string? Context { get; init; }

    /// <summary>
    /// Number of chunks found.
    /// </summary>
    public int ChunksFound { get; init; }

    /// <summary>
    /// Number of files containing matches.
    /// </summary>
    public int FilesFound { get; init; }

    /// <summary>
    /// Time to retrieve context.
    /// </summary>
    public TimeSpan QueryTime { get; init; }

    /// <summary>
    /// List of relevant file paths.
    /// </summary>
    public IReadOnlyList<string> RelevantFiles { get; init; } = Array.Empty<string>();

    /// <summary>
    /// Estimated token count of context.
    /// </summary>
    public int EstimatedTokens { get; init; }
}
```

### Dependencies
- `IKnowledgeService` from v0.7.4a
- `ILlmService`, `IConversationService` from existing chat infrastructure
- `ContextBuildOptions` from v0.7.4c

### Implementation Notes
1. RAG context is injected into the system prompt
2. Graceful degradation if retrieval fails
3. Preview functionality allows users to see what context would be used
4. Token budget management ensures context doesn't overwhelm the prompt

---

## v0.7.4i: Keyword Extraction & Highlighting

### Objective
Implement keyword extraction for queries and highlighting in search results.

### File: `src/SeniorIntern.Services/Knowledge/KeywordExtractor.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text.RegularExpressions;

namespace SeniorIntern.Services.Knowledge;

/// <summary>
/// Extracts keywords from queries for highlighting and reranking.
/// </summary>
public sealed class KeywordExtractor
{
    private static readonly HashSet<string> StopWords = new(StringComparer.OrdinalIgnoreCase)
    {
        // Common English stop words
        "a", "an", "the", "is", "are", "was", "were", "be", "been",
        "being", "have", "has", "had", "do", "does", "did", "will",
        "would", "could", "should", "may", "might", "must", "shall",
        "can", "need", "to", "of", "in", "for", "on", "with", "at",
        "by", "from", "as", "into", "through", "during", "before",
        "after", "where", "how", "what", "which", "who", "this",
        "that", "or", "and", "but", "if", "not", "all", "any",
        // Programming-related common words
        "function", "method", "class", "var", "let", "const", "return",
        "public", "private", "protected", "static", "void", "int",
        "string", "bool", "true", "false", "null", "new", "get", "set"
    };

    private static readonly HashSet<string> ProgrammingKeywords = new(StringComparer.OrdinalIgnoreCase)
    {
        // Keep these even though they're common in code
        "async", "await", "interface", "abstract", "override", "virtual",
        "sealed", "readonly", "const", "enum", "struct", "namespace",
        "using", "import", "export", "default", "extends", "implements"
    };

    /// <summary>
    /// Extract keywords from a query string.
    /// </summary>
    /// <param name="query">The query string.</param>
    /// <param name="includeCodeTerms">Whether to preserve code-related terms.</param>
    /// <returns>List of extracted keywords.</returns>
    public IReadOnlyList<string> Extract(string query, bool includeCodeTerms = true)
    {
        if (string.IsNullOrWhiteSpace(query))
            return Array.Empty<string>();

        var keywords = new List<string>();

        // Split on whitespace and common delimiters
        var tokens = Regex.Split(query, @"[\s\.,;:!?\-\(\)\[\]{}""'`]+")
            .Where(t => !string.IsNullOrEmpty(t))
            .ToList();

        foreach (var token in tokens)
        {
            // Skip stop words (unless they're programming keywords we want to keep)
            if (StopWords.Contains(token) && !ProgrammingKeywords.Contains(token))
                continue;

            // Skip very short tokens
            if (token.Length < 2)
                continue;

            // Add the token
            keywords.Add(token.ToLowerInvariant());

            // Split camelCase and PascalCase
            if (HasMixedCase(token))
            {
                var parts = SplitCamelCase(token);
                keywords.AddRange(parts
                    .Where(p => p.Length >= 2 && !StopWords.Contains(p))
                    .Select(p => p.ToLowerInvariant()));
            }

            // Split snake_case
            if (token.Contains('_'))
            {
                var parts = token.Split('_', StringSplitOptions.RemoveEmptyEntries);
                keywords.AddRange(parts
                    .Where(p => p.Length >= 2 && !StopWords.Contains(p))
                    .Select(p => p.ToLowerInvariant()));
            }
        }

        return keywords.Distinct().ToList();
    }

    /// <summary>
    /// Extract quoted phrases as exact match terms.
    /// </summary>
    public IReadOnlyList<string> ExtractQuotedPhrases(string query)
    {
        var phrases = new List<string>();
        var matches = Regex.Matches(query, @"""([^""]+)""");

        foreach (Match match in matches)
        {
            if (match.Groups.Count > 1)
            {
                phrases.Add(match.Groups[1].Value);
            }
        }

        return phrases;
    }

    private static bool HasMixedCase(string word)
    {
        var hasUpper = false;
        var hasLower = false;

        foreach (var c in word)
        {
            if (char.IsUpper(c)) hasUpper = true;
            if (char.IsLower(c)) hasLower = true;
            if (hasUpper && hasLower) return true;
        }

        return false;
    }

    private static IEnumerable<string> SplitCamelCase(string input)
    {
        // Split "UserService" into ["User", "Service"]
        return Regex.Split(input, @"(?<!^)(?=[A-Z])")
            .Where(s => !string.IsNullOrEmpty(s));
    }
}
```

### File: `src/SeniorIntern.Services/Knowledge/TextHighlighter.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text.RegularExpressions;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge;

/// <summary>
/// Highlights keywords in text content.
/// </summary>
public sealed class TextHighlighter
{
    private readonly KeywordExtractor _keywordExtractor;

    public TextHighlighter(KeywordExtractor keywordExtractor)
    {
        _keywordExtractor = keywordExtractor;
    }

    /// <summary>
    /// Find highlight positions for keywords in content.
    /// </summary>
    /// <param name="content">The content to search.</param>
    /// <param name="query">The original query.</param>
    /// <returns>List of highlight positions.</returns>
    public IReadOnlyList<TextHighlight> FindHighlights(string content, string query)
    {
        if (string.IsNullOrWhiteSpace(content) || string.IsNullOrWhiteSpace(query))
            return Array.Empty<TextHighlight>();

        var highlights = new List<TextHighlight>();

        // First, check for exact phrase matches (quoted)
        var phrases = _keywordExtractor.ExtractQuotedPhrases(query);
        foreach (var phrase in phrases)
        {
            highlights.AddRange(FindMatches(content, phrase, isExact: true));
        }

        // Then find keyword matches
        var keywords = _keywordExtractor.Extract(query);
        foreach (var keyword in keywords)
        {
            highlights.AddRange(FindMatches(content, keyword, isExact: false));
        }

        // Remove overlapping highlights (prefer longer matches)
        return RemoveOverlaps(highlights);
    }

    /// <summary>
    /// Apply highlight markers to content.
    /// </summary>
    /// <param name="content">The content to highlight.</param>
    /// <param name="highlights">Highlight positions.</param>
    /// <param name="openTag">Opening tag/marker.</param>
    /// <param name="closeTag">Closing tag/marker.</param>
    /// <returns>Content with highlight markers.</returns>
    public string ApplyHighlights(
        string content,
        IReadOnlyList<TextHighlight> highlights,
        string openTag = "**",
        string closeTag = "**")
    {
        if (highlights.Count == 0)
            return content;

        // Sort by position (descending) to insert from end to start
        var sortedHighlights = highlights
            .OrderByDescending(h => h.Start)
            .ToList();

        var result = content;
        foreach (var highlight in sortedHighlights)
        {
            var end = highlight.Start + highlight.Length;
            if (end <= result.Length)
            {
                result = result.Insert(end, closeTag);
                result = result.Insert(highlight.Start, openTag);
            }
        }

        return result;
    }

    private static IEnumerable<TextHighlight> FindMatches(string content, string term, bool isExact)
    {
        var pattern = isExact
            ? Regex.Escape(term)
            : $@"\b{Regex.Escape(term)}\b";

        var matches = Regex.Matches(content, pattern, RegexOptions.IgnoreCase);

        foreach (Match match in matches)
        {
            yield return new TextHighlight
            {
                Start = match.Index,
                Length = match.Length,
                MatchedKeyword = term
            };
        }
    }

    private static IReadOnlyList<TextHighlight> RemoveOverlaps(List<TextHighlight> highlights)
    {
        if (highlights.Count <= 1)
            return highlights;

        // Sort by start position, then by length (longer first)
        var sorted = highlights
            .OrderBy(h => h.Start)
            .ThenByDescending(h => h.Length)
            .ToList();

        var result = new List<TextHighlight>();
        var currentEnd = -1;

        foreach (var highlight in sorted)
        {
            // Skip if this highlight overlaps with the previous one
            if (highlight.Start < currentEnd)
                continue;

            result.Add(highlight);
            currentEnd = highlight.Start + highlight.Length;
        }

        return result;
    }
}
```

### Dependencies
- `TextHighlight` from v0.7.4b

### Implementation Notes
1. Keyword extraction handles camelCase, PascalCase, and snake_case
2. Quoted phrases are treated as exact matches
3. Overlapping highlights are resolved by preferring longer matches
4. Highlighting can be applied with customizable markers

---

## v0.7.4j: Unit Testing & Integration

### Objective
Create comprehensive unit tests and integration tests for all v0.7.4 components.

### File: `tests/SeniorIntern.Tests/Knowledge/KnowledgeServiceTests.cs`

```csharp
using System;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using Moq;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;
using SeniorIntern.Services.Knowledge;
using SeniorIntern.Services.Knowledge.Context;
using SeniorIntern.Services.Knowledge.Interfaces;
using Xunit;

namespace SeniorIntern.Tests.Knowledge;

public class KnowledgeServiceTests
{
    private readonly Mock<IVectorStore> _vectorStoreMock;
    private readonly Mock<IEmbeddingService> _embeddingServiceMock;
    private readonly Mock<IRerankingStrategyFactory> _rerankingFactoryMock;
    private readonly Mock<IContextAssembler> _contextAssemblerMock;
    private readonly Mock<IContextExpander> _contextExpanderMock;
    private readonly Mock<ILogger<KnowledgeService>> _loggerMock;
    private readonly KnowledgeService _service;

    public KnowledgeServiceTests()
    {
        _vectorStoreMock = new Mock<IVectorStore>();
        _embeddingServiceMock = new Mock<IEmbeddingService>();
        _rerankingFactoryMock = new Mock<IRerankingStrategyFactory>();
        _contextAssemblerMock = new Mock<IContextAssembler>();
        _contextExpanderMock = new Mock<IContextExpander>();
        _loggerMock = new Mock<ILogger<KnowledgeService>>();

        _service = new KnowledgeService(
            _vectorStoreMock.Object,
            _embeddingServiceMock.Object,
            _rerankingFactoryMock.Object,
            _contextAssemblerMock.Object,
            _contextExpanderMock.Object,
            _loggerMock.Object);
    }

    [Fact]
    public async Task QueryAsync_WithEmptyQuestion_ThrowsArgumentException()
    {
        var options = new KnowledgeQueryOptions { WorkspacePath = "/test" };

        await Assert.ThrowsAsync<ArgumentException>(() =>
            _service.QueryAsync("", options));
    }

    [Fact]
    public async Task QueryAsync_WithNoWorkspacePath_ThrowsArgumentException()
    {
        var options = new KnowledgeQueryOptions { WorkspacePath = "" };

        await Assert.ThrowsAsync<ArgumentException>(() =>
            _service.QueryAsync("test query", options));
    }

    [Fact]
    public async Task QueryAsync_WithNoIndex_ReturnsEmptyResult()
    {
        _vectorStoreMock
            .Setup(v => v.GetIndexForWorkspaceAsync(It.IsAny<string>(), It.IsAny<CancellationToken>()))
            .ReturnsAsync((VectorIndex?)null);

        var options = new KnowledgeQueryOptions { WorkspacePath = "/test" };
        var result = await _service.QueryAsync("test query", options);

        Assert.False(result.HasResults);
        Assert.Empty(result.Chunks);
    }

    [Fact]
    public async Task QueryAsync_WithValidQuery_ReturnsResults()
    {
        // Arrange
        var index = new VectorIndex
        {
            Id = "test-index",
            WorkspacePath = "/test",
            ChunkCount = 100
        };

        var embedding = new float[] { 0.1f, 0.2f, 0.3f };
        var searchResults = new[]
        {
            new ChunkSearchResult
            {
                ChunkId = "chunk1",
                Score = 0.9f,
                Chunk = new TextChunk { Content = "test content", FilePath = "test.cs" }
            }
        };

        _vectorStoreMock
            .Setup(v => v.GetIndexForWorkspaceAsync("/test", It.IsAny<CancellationToken>()))
            .ReturnsAsync(index);

        _embeddingServiceMock
            .Setup(e => e.EmbedAsync(It.IsAny<string>(), It.IsAny<CancellationToken>()))
            .ReturnsAsync(embedding);

        _vectorStoreMock
            .Setup(v => v.SearchAsync(
                "test-index",
                It.IsAny<float[]>(),
                It.IsAny<VectorSearchOptions>(),
                It.IsAny<CancellationToken>()))
            .ReturnsAsync(searchResults);

        _contextExpanderMock
            .Setup(c => c.ExpandAsync(
                It.IsAny<string>(),
                It.IsAny<TextChunk>(),
                It.IsAny<int>(),
                It.IsAny<CancellationToken>()))
            .ReturnsAsync("expanded content");

        var options = new KnowledgeQueryOptions
        {
            WorkspacePath = "/test",
            MaxResults = 10,
            MinRelevance = 0.5f
        };

        // Act
        var result = await _service.QueryAsync("test query", options);

        // Assert
        Assert.True(result.HasResults);
        Assert.Single(result.Chunks);
        Assert.Equal(0.9f, result.Chunks[0].Relevance);
    }

    [Fact]
    public async Task IsIndexedAsync_WithIndex_ReturnsTrue()
    {
        _vectorStoreMock
            .Setup(v => v.GetIndexForWorkspaceAsync("/test", It.IsAny<CancellationToken>()))
            .ReturnsAsync(new VectorIndex { Id = "test" });

        var result = await _service.IsIndexedAsync("/test");

        Assert.True(result);
    }

    [Fact]
    public async Task IsIndexedAsync_WithoutIndex_ReturnsFalse()
    {
        _vectorStoreMock
            .Setup(v => v.GetIndexForWorkspaceAsync("/test", It.IsAny<CancellationToken>()))
            .ReturnsAsync((VectorIndex?)null);

        var result = await _service.IsIndexedAsync("/test");

        Assert.False(result);
    }
}
```

### File: `tests/SeniorIntern.Tests/Knowledge/Reranking/KeywordBoostStrategyTests.cs`

```csharp
using System.Collections.Generic;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using Moq;
using SeniorIntern.Core.Models;
using SeniorIntern.Services.Knowledge.Reranking;
using Xunit;

namespace SeniorIntern.Tests.Knowledge.Reranking;

public class KeywordBoostStrategyTests
{
    private readonly KeywordBoostStrategy _strategy;

    public KeywordBoostStrategyTests()
    {
        var loggerMock = new Mock<ILogger<KeywordBoostStrategy>>();
        _strategy = new KeywordBoostStrategy(loggerMock.Object);
    }

    [Fact]
    public async Task RerankAsync_WithEmptyResults_ReturnsEmpty()
    {
        var results = new List<ChunkSearchResult>();

        var reranked = await _strategy.RerankAsync(results, "test query");

        Assert.Empty(reranked);
    }

    [Fact]
    public async Task RerankAsync_BoostsKeywordMatches()
    {
        var results = new List<ChunkSearchResult>
        {
            new()
            {
                ChunkId = "1",
                Score = 0.8f,
                Chunk = new TextChunk { Content = "This is some unrelated content" }
            },
            new()
            {
                ChunkId = "2",
                Score = 0.7f,
                Chunk = new TextChunk { Content = "This contains UserService code" }
            }
        };

        var reranked = await _strategy.RerankAsync(results, "UserService");

        // The second result should now be first due to keyword boost
        Assert.Equal("2", reranked[0].ChunkId);
    }

    [Fact]
    public async Task RerankAsync_ExactMatchGetsHigherBoost()
    {
        var results = new List<ChunkSearchResult>
        {
            new()
            {
                ChunkId = "1",
                Score = 0.8f,
                Chunk = new TextChunk { Content = "User authentication service" }
            },
            new()
            {
                ChunkId = "2",
                Score = 0.75f,
                Chunk = new TextChunk { Content = "find user by email" }
            }
        };

        var reranked = await _strategy.RerankAsync(results, "find user by email");

        // Exact phrase match should boost second result
        Assert.Equal("2", reranked[0].ChunkId);
    }
}
```

### File: `tests/SeniorIntern.Tests/Knowledge/Reranking/RRFStrategyTests.cs`

```csharp
using System.Collections.Generic;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using Moq;
using SeniorIntern.Core.Models;
using SeniorIntern.Services.Knowledge.Reranking;
using Xunit;

namespace SeniorIntern.Tests.Knowledge.Reranking;

public class RRFStrategyTests
{
    private readonly ReciprocalRankFusionStrategy _strategy;

    public RRFStrategyTests()
    {
        var loggerMock = new Mock<ILogger<ReciprocalRankFusionStrategy>>();
        _strategy = new ReciprocalRankFusionStrategy(loggerMock.Object);
    }

    [Fact]
    public async Task RerankAsync_CombinesSemanticAndKeywordRankings()
    {
        var results = new List<ChunkSearchResult>
        {
            new()
            {
                ChunkId = "1",
                Score = 0.9f, // High semantic score
                Chunk = new TextChunk { Content = "Generic database operations" }
            },
            new()
            {
                ChunkId = "2",
                Score = 0.7f, // Lower semantic score
                Chunk = new TextChunk { Content = "UserRepository UserRepository UserRepository" } // Many keyword matches
            },
            new()
            {
                ChunkId = "3",
                Score = 0.8f,
                Chunk = new TextChunk { Content = "UserRepository implementation" }
            }
        };

        var reranked = await _strategy.RerankAsync(results, "UserRepository");

        // Result 2 has more keyword matches, should be boosted despite lower semantic score
        Assert.Equal("2", reranked[0].ChunkId);
    }

    [Fact]
    public async Task RerankAsync_NormalizesScores()
    {
        var results = new List<ChunkSearchResult>
        {
            new()
            {
                ChunkId = "1",
                Score = 0.9f,
                Chunk = new TextChunk { Content = "test content" }
            },
            new()
            {
                ChunkId = "2",
                Score = 0.5f,
                Chunk = new TextChunk { Content = "other test content" }
            }
        };

        var reranked = await _strategy.RerankAsync(results, "test");

        // Scores should be normalized between 0 and 1
        Assert.True(reranked[0].Score <= 1.0f);
        Assert.True(reranked[0].Score >= 0.0f);
    }
}
```

### File: `tests/SeniorIntern.Tests/Knowledge/Context/ContextAssemblerTests.cs`

```csharp
using System.Collections.Generic;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using Moq;
using SeniorIntern.Core.Models;
using SeniorIntern.Services.Knowledge.Context;
using Xunit;

namespace SeniorIntern.Tests.Knowledge.Context;

public class ContextAssemblerTests
{
    private readonly ContextAssembler _assembler;

    public ContextAssemblerTests()
    {
        var tokenEstimator = new TokenEstimator();
        var loggerMock = new Mock<ILogger<ContextAssembler>>();
        _assembler = new ContextAssembler(tokenEstimator, loggerMock.Object);
    }

    [Fact]
    public async Task AssembleAsync_WithEmptyChunks_ReturnsEmpty()
    {
        var chunks = new List<KnowledgeChunk>();
        var options = new ContextBuildOptions();

        var result = await _assembler.AssembleAsync(chunks, options);

        Assert.True(result.IsEmpty);
    }

    [Fact]
    public async Task AssembleAsync_FormatsMarkdown()
    {
        var chunks = new List<KnowledgeChunk>
        {
            new()
            {
                Content = "public class Test { }",
                FilePath = "Test.cs",
                StartLine = 1,
                EndLine = 1,
                Language = "csharp",
                Relevance = 0.9f
            }
        };

        var options = new ContextBuildOptions
        {
            Format = ContextFormat.Markdown,
            IncludeFileHeaders = true,
            IncludeLineNumbers = true
        };

        var result = await _assembler.AssembleAsync(chunks, options);

        Assert.Contains("### Test.cs", result.Context);
        Assert.Contains("```csharp", result.Context);
        Assert.Contains("public class Test { }", result.Context);
    }

    [Fact]
    public async Task AssembleAsync_FormatsXml()
    {
        var chunks = new List<KnowledgeChunk>
        {
            new()
            {
                Content = "public class Test { }",
                FilePath = "Test.cs",
                StartLine = 1,
                EndLine = 1,
                Relevance = 0.9f
            }
        };

        var options = new ContextBuildOptions
        {
            Format = ContextFormat.Xml
        };

        var result = await _assembler.AssembleAsync(chunks, options);

        Assert.Contains("<code-context", result.Context);
        Assert.Contains("file=\"Test.cs\"", result.Context);
    }

    [Fact]
    public async Task AssembleAsync_RespectsTokenBudget()
    {
        var chunks = new List<KnowledgeChunk>();
        for (var i = 0; i < 100; i++)
        {
            chunks.Add(new KnowledgeChunk
            {
                Content = new string('x', 1000), // Large content
                FilePath = $"File{i}.cs",
                StartLine = 1,
                EndLine = 100,
                Relevance = 0.9f - (i * 0.001f)
            });
        }

        var options = new ContextBuildOptions
        {
            Format = ContextFormat.Plain,
            MaxTokens = 500,
            MaxChunks = 100
        };

        var result = await _assembler.AssembleAsync(chunks, options);

        Assert.True(result.EstimatedTokens <= 500);
        Assert.True(result.WasTruncated);
    }

    [Fact]
    public async Task AssembleAsync_GroupsByFile()
    {
        var chunks = new List<KnowledgeChunk>
        {
            new() { Content = "chunk1", FilePath = "B.cs", StartLine = 10, Relevance = 0.9f },
            new() { Content = "chunk2", FilePath = "A.cs", StartLine = 1, Relevance = 0.8f },
            new() { Content = "chunk3", FilePath = "B.cs", StartLine = 1, Relevance = 0.7f }
        };

        var options = new ContextBuildOptions
        {
            Format = ContextFormat.Plain,
            GroupByFile = true
        };

        var result = await _assembler.AssembleAsync(chunks, options);

        // B.cs chunks should be together and B.cs should come first (higher max relevance)
        var bIndex = result.Context.IndexOf("B.cs");
        var aIndex = result.Context.IndexOf("A.cs");
        Assert.True(bIndex < aIndex);
    }
}
```

### File: `tests/SeniorIntern.Tests/Knowledge/Context/TokenEstimatorTests.cs`

```csharp
using SeniorIntern.Core.Models;
using SeniorIntern.Services.Knowledge.Context;
using Xunit;

namespace SeniorIntern.Tests.Knowledge.Context;

public class TokenEstimatorTests
{
    private readonly TokenEstimator _estimator = new();

    [Fact]
    public void EstimateTokens_EmptyString_ReturnsZero()
    {
        var result = _estimator.EstimateTokens("");
        Assert.Equal(0, result);
    }

    [Fact]
    public void EstimateTokens_CharacterBased_ApproximatesCorrectly()
    {
        // ~4 characters per token
        var text = new string('a', 100);
        var result = _estimator.EstimateTokens(text, TokenEstimationMethod.CharacterBased);

        // Should be around 25 tokens (100/4)
        Assert.InRange(result, 20, 35);
    }

    [Fact]
    public void EstimateTokens_WordBased_ApproximatesCorrectly()
    {
        var text = "This is a test sentence with some words";
        var result = _estimator.EstimateTokens(text, TokenEstimationMethod.WordBased);

        // 8 words, ~1.3 tokens per word = ~10-11 tokens
        Assert.InRange(result, 8, 15);
    }

    [Fact]
    public void EstimateTokens_CodeWithSpecialChars_AdjustsEstimate()
    {
        var code = "public void Method() { return x + y; }";
        var plainText = "public void method return plus";

        var codeTokens = _estimator.EstimateTokens(code, TokenEstimationMethod.CharacterBased);
        var plainTokens = _estimator.EstimateTokens(plainText, TokenEstimationMethod.CharacterBased);

        // Code should have more tokens due to special characters
        Assert.True(codeTokens > plainTokens);
    }
}
```

### File: `tests/SeniorIntern.Tests/Knowledge/KeywordExtractorTests.cs`

```csharp
using SeniorIntern.Services.Knowledge;
using Xunit;

namespace SeniorIntern.Tests.Knowledge;

public class KeywordExtractorTests
{
    private readonly KeywordExtractor _extractor = new();

    [Fact]
    public void Extract_EmptyQuery_ReturnsEmpty()
    {
        var result = _extractor.Extract("");
        Assert.Empty(result);
    }

    [Fact]
    public void Extract_FiltersStopWords()
    {
        var result = _extractor.Extract("the quick brown fox");

        Assert.DoesNotContain("the", result);
        Assert.Contains("quick", result);
        Assert.Contains("brown", result);
        Assert.Contains("fox", result);
    }

    [Fact]
    public void Extract_SplitsCamelCase()
    {
        var result = _extractor.Extract("UserService");

        Assert.Contains("user", result);
        Assert.Contains("service", result);
        Assert.Contains("userservice", result);
    }

    [Fact]
    public void Extract_SplitsSnakeCase()
    {
        var result = _extractor.Extract("get_user_by_id");

        Assert.Contains("get", result);
        Assert.Contains("user", result);
    }

    [Fact]
    public void ExtractQuotedPhrases_FindsExactPhrases()
    {
        var result = _extractor.ExtractQuotedPhrases("find \"user service\" in code");

        Assert.Single(result);
        Assert.Equal("user service", result[0]);
    }

    [Fact]
    public void ExtractQuotedPhrases_FindsMultiplePhrases()
    {
        var result = _extractor.ExtractQuotedPhrases("\"first phrase\" and \"second phrase\"");

        Assert.Equal(2, result.Count);
    }
}
```

### File: `tests/SeniorIntern.Tests/Knowledge/TextHighlighterTests.cs`

```csharp
using SeniorIntern.Services.Knowledge;
using Xunit;

namespace SeniorIntern.Tests.Knowledge;

public class TextHighlighterTests
{
    private readonly TextHighlighter _highlighter;

    public TextHighlighterTests()
    {
        _highlighter = new TextHighlighter(new KeywordExtractor());
    }

    [Fact]
    public void FindHighlights_FindsKeywordMatches()
    {
        var content = "This is a UserService implementation";
        var query = "UserService";

        var highlights = _highlighter.FindHighlights(content, query);

        Assert.NotEmpty(highlights);
        Assert.Contains(highlights, h => h.MatchedKeyword == "userservice");
    }

    [Fact]
    public void FindHighlights_CaseInsensitive()
    {
        var content = "USERSERVICE implementation";
        var query = "userservice";

        var highlights = _highlighter.FindHighlights(content, query);

        Assert.NotEmpty(highlights);
    }

    [Fact]
    public void ApplyHighlights_InsertsMarkers()
    {
        var content = "Call UserService here";
        var query = "UserService";

        var highlights = _highlighter.FindHighlights(content, query);
        var result = _highlighter.ApplyHighlights(content, highlights);

        Assert.Contains("**UserService**", result);
    }

    [Fact]
    public void FindHighlights_RemovesOverlaps()
    {
        var content = "UserServiceImpl";
        var query = "UserService Service";

        var highlights = _highlighter.FindHighlights(content, query);

        // Should not have overlapping highlights
        for (var i = 0; i < highlights.Count - 1; i++)
        {
            var current = highlights[i];
            var next = highlights[i + 1];
            Assert.True(current.Start + current.Length <= next.Start);
        }
    }
}
```

### File: `tests/SeniorIntern.Tests/Knowledge/Integration/KnowledgeServiceIntegrationTests.cs`

```csharp
using System;
using System.IO;
using System.Threading.Tasks;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;
using Xunit;

namespace SeniorIntern.Tests.Knowledge.Integration;

/// <summary>
/// Integration tests that test the full knowledge retrieval pipeline.
/// These tests require actual dependencies and are slower to run.
/// </summary>
public class KnowledgeServiceIntegrationTests : IAsyncLifetime
{
    private IServiceProvider? _serviceProvider;
    private string? _testWorkspace;

    public async Task InitializeAsync()
    {
        // Create test workspace with sample files
        _testWorkspace = Path.Combine(Path.GetTempPath(), $"test-workspace-{Guid.NewGuid()}");
        Directory.CreateDirectory(_testWorkspace);

        await File.WriteAllTextAsync(
            Path.Combine(_testWorkspace, "UserService.cs"),
            @"
namespace TestApp;

public class UserService
{
    private readonly IUserRepository _repository;

    public UserService(IUserRepository repository)
    {
        _repository = repository;
    }

    public async Task<User> GetUserByIdAsync(int id)
    {
        return await _repository.FindByIdAsync(id);
    }

    public async Task<User> CreateUserAsync(string name, string email)
    {
        var user = new User { Name = name, Email = email };
        return await _repository.SaveAsync(user);
    }
}
");

        await File.WriteAllTextAsync(
            Path.Combine(_testWorkspace, "User.cs"),
            @"
namespace TestApp;

public class User
{
    public int Id { get; set; }
    public string Name { get; set; }
    public string Email { get; set; }
}
");

        // Set up DI container with real services
        // Note: In a real test, we'd set up the full service collection
        // For now, this is a placeholder showing the pattern
    }

    public Task DisposeAsync()
    {
        if (_testWorkspace != null && Directory.Exists(_testWorkspace))
        {
            Directory.Delete(_testWorkspace, recursive: true);
        }
        return Task.CompletedTask;
    }

    [Fact(Skip = "Integration test - requires full service setup")]
    public async Task FullPipeline_IndexAndQuery_ReturnsResults()
    {
        // This test would:
        // 1. Index the test workspace
        // 2. Query for "UserService"
        // 3. Verify relevant chunks are returned

        var knowledgeService = _serviceProvider!.GetRequiredService<IKnowledgeService>();

        var result = await knowledgeService.QueryAsync(
            "How do I get a user by ID?",
            new KnowledgeQueryOptions
            {
                WorkspacePath = _testWorkspace!,
                MaxResults = 5,
                MinRelevance = 0.5f
            });

        Assert.True(result.HasResults);
        Assert.Contains(result.Chunks, c => c.FilePath.Contains("UserService"));
    }

    [Fact(Skip = "Integration test - requires full service setup")]
    public async Task BuildContext_WithTokenBudget_FitsWithinLimit()
    {
        var knowledgeService = _serviceProvider!.GetRequiredService<IKnowledgeService>();

        var context = await knowledgeService.BuildContextAsync(
            "Tell me about User management",
            new ContextBuildOptions
            {
                WorkspacePath = _testWorkspace!,
                MaxTokens = 500,
                Format = ContextFormat.Markdown
            });

        // Verify context is not empty and reasonably sized
        Assert.NotEmpty(context);
        Assert.True(context.Length < 2500); // ~500 tokens * 5 chars/token
    }
}
```

### Dependencies
- xUnit testing framework
- Moq for mocking
- All v0.7.4 components

### Implementation Notes
1. Unit tests mock dependencies for isolation
2. Integration tests use real file system with temp directories
3. Tests cover edge cases like empty inputs, token limits, and overlapping highlights
4. Skip attribute on integration tests allows selective running

---

## Implementation Summary

### Files to Create (32 total)

| Sub-version | File Path | Purpose |
|-------------|-----------|---------|
| v0.7.4a | `src/SeniorIntern.Core/Interfaces/IKnowledgeService.cs` | Main knowledge service interface |
| v0.7.4a | `src/SeniorIntern.Core/Interfaces/IRerankingStrategy.cs` | Reranking strategy interface |
| v0.7.4b | `src/SeniorIntern.Core/Models/KnowledgeQueryOptions.cs` | Query options model |
| v0.7.4b | `src/SeniorIntern.Core/Models/KnowledgeQueryResult.cs` | Query result and chunk models |
| v0.7.4b | `src/SeniorIntern.Core/Models/KnowledgeIndexHealth.cs` | Index health model |
| v0.7.4c | `src/SeniorIntern.Core/Models/ContextBuildOptions.cs` | Context assembly options |
| v0.7.4c | `src/SeniorIntern.Core/Models/ContextBuildResult.cs` | Context assembly result |
| v0.7.4d | `src/SeniorIntern.Services/Knowledge/KnowledgeService.cs` | Main service implementation |
| v0.7.4d | `src/SeniorIntern.Services/Knowledge/KnowledgeService.Helpers.cs` | Helper classes (cache, exceptions) |
| v0.7.4d | `src/SeniorIntern.Services/Knowledge/Interfaces/IRerankingStrategyFactory.cs` | Factory interface |
| v0.7.4e | `src/SeniorIntern.Services/Knowledge/Reranking/RerankingStrategyFactory.cs` | Factory implementation |
| v0.7.4e | `src/SeniorIntern.Services/Knowledge/Reranking/KeywordBoostStrategy.cs` | Keyword boost reranking |
| v0.7.4e | `src/SeniorIntern.Services/Knowledge/Reranking/ReciprocalRankFusionStrategy.cs` | RRF reranking |
| v0.7.4e | `src/SeniorIntern.Services/Knowledge/Reranking/CrossEncoderStrategy.cs` | Cross-encoder placeholder |
| v0.7.4f | `src/SeniorIntern.Services/Knowledge/Context/IContextAssembler.cs` | Context assembler interface |
| v0.7.4f | `src/SeniorIntern.Services/Knowledge/Context/ContextAssembler.cs` | Context assembly implementation |
| v0.7.4f | `src/SeniorIntern.Services/Knowledge/Context/TokenEstimator.cs` | Token estimation utilities |
| v0.7.4g | `src/SeniorIntern.Services/Knowledge/Context/IContextExpander.cs` | Context expander interface |
| v0.7.4g | `src/SeniorIntern.Services/Knowledge/Context/FileContextExpander.cs` | File-based context expansion |
| v0.7.4h | `src/SeniorIntern.Services/Chat/IRagChatService.cs` | RAG chat interface |
| v0.7.4h | `src/SeniorIntern.Services/Chat/RagChatService.cs` | RAG chat implementation |
| v0.7.4h | `src/SeniorIntern.Core/Models/RagChatModels.cs` | RAG chat options/preview models |
| v0.7.4i | `src/SeniorIntern.Services/Knowledge/KeywordExtractor.cs` | Keyword extraction |
| v0.7.4i | `src/SeniorIntern.Services/Knowledge/TextHighlighter.cs` | Text highlighting |
| v0.7.4j | `tests/SeniorIntern.Tests/Knowledge/KnowledgeServiceTests.cs` | Knowledge service unit tests |
| v0.7.4j | `tests/SeniorIntern.Tests/Knowledge/Reranking/KeywordBoostStrategyTests.cs` | Keyword boost tests |
| v0.7.4j | `tests/SeniorIntern.Tests/Knowledge/Reranking/RRFStrategyTests.cs` | RRF strategy tests |
| v0.7.4j | `tests/SeniorIntern.Tests/Knowledge/Context/ContextAssemblerTests.cs` | Context assembler tests |
| v0.7.4j | `tests/SeniorIntern.Tests/Knowledge/Context/TokenEstimatorTests.cs` | Token estimator tests |
| v0.7.4j | `tests/SeniorIntern.Tests/Knowledge/KeywordExtractorTests.cs` | Keyword extractor tests |
| v0.7.4j | `tests/SeniorIntern.Tests/Knowledge/TextHighlighterTests.cs` | Text highlighter tests |
| v0.7.4j | `tests/SeniorIntern.Tests/Knowledge/Integration/KnowledgeServiceIntegrationTests.cs` | Integration tests |

### Files to Modify (1 total)

| File Path | Changes |
|-----------|---------|
| `src/SeniorIntern.Services/DependencyInjection.cs` | Add service registrations for knowledge service, reranking factory, context assembler, context expander |

### NuGet Packages

No new NuGet packages required for v0.7.4. All dependencies are satisfied by previous versions:
- v0.7.1 provides embedding capabilities
- v0.7.2 provides vector storage
- v0.7.3 provides indexing infrastructure

### Key Interfaces

```
IKnowledgeService          - High-level RAG API
├── QueryAsync()           - Semantic search with reranking
├── BuildContextAsync()    - Context assembly for LLM
├── FindRelevantFilesAsync()- File discovery
├── IsIndexedAsync()       - Index availability check
└── GetIndexHealthAsync()  - Index statistics

IRerankingStrategy         - Pluggable reranking
├── KeywordBoostStrategy   - Keyword matching bonus
├── RRFStrategy            - Reciprocal Rank Fusion
└── CrossEncoderStrategy   - (Future) Neural reranking

IContextAssembler          - Context formatting
├── Markdown format        - Code blocks with headers
├── XML format             - Structured tags
├── JSON format            - Programmatic processing
└── Plain format           - Minimal formatting

IRagChatService            - Chat integration
├── GenerateWithRagAsync() - RAG-enhanced responses
└── PreviewContextAsync()  - Debug/preview context
```

### Architecture Notes

1. **Separation of Concerns**: Query processing, reranking, and context assembly are separate components
2. **Extensibility**: New reranking strategies can be added without modifying core logic
3. **Performance**: Query caching and file caching reduce repeated operations
4. **Graceful Degradation**: RAG fails gracefully if retrieval fails
5. **Token Management**: Context assembly respects token budgets for LLM compatibility

---

## Dependencies Graph

```
v0.7.4 Retrieval & Context
├── v0.7.1 Embedding Foundation
│   └── IEmbeddingService (query embedding generation)
├── v0.7.2 Vector Storage
│   └── IVectorStore (similarity search)
└── v0.7.3 Indexing Pipeline
    └── IIndexingService (workspace indexing)
```

---

## Success Criteria

- [ ] `IKnowledgeService` correctly retrieves relevant code chunks
- [ ] Reranking strategies improve result relevance for keyword queries
- [ ] Context assembly produces well-formatted output within token limits
- [ ] RAG-aware chat service injects context into LLM prompts
- [ ] All unit tests pass
- [ ] Integration tests demonstrate end-to-end functionality
- [ ] Performance: Query latency < 500ms for indexed workspaces
- [ ] Memory: Context caching does not cause memory leaks
