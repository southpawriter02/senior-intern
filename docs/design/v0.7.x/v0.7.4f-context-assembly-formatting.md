# Design Specification: AIntern v0.7.4f "Context Assembly & Formatting"

## Overview

**Version**: v0.7.4f  
**Parent**: v0.7.4 Retrieval & Context  
**Focus**: Implement context assembly with multiple output formats and token budget management

### Purpose

This sub-version implements context assembly for LLM prompts:
1. `IContextAssembler` - Interface for context assembly (already in Core per v0.7.4a)
2. `ContextAssembler` - Implementation with format-specific formatting
3. `ITokenEstimator` - Interface for token count estimation
4. `TokenEstimator` - Implementation with CharacterBased, WordBased, and Tokenizer methods

### Dependencies

**From v0.7.4a (Knowledge Service Interface)**:
- `IContextAssembler` interface definition (in Core)

**From v0.7.4b (Query & Result Models)**:
- `KnowledgeChunk` for source chunk data

**From v0.7.4c (Context Building Models)**:
- `ContextBuildOptions` for configuration
- `ContextBuildResult` for output
- `FormattedChunk` for formatted output
- `ContextFormat` enum
- `TokenEstimationMethod` enum

---

## Architecture

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                     v0.7.4f Context Assembly & Formatting                     │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  src/SeniorIntern.Services/Knowledge/Context/                                │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │                                                                          ││
│  │  ContextAssembler : IContextAssembler                                    ││
│  │  ├── Dependencies                                                        ││
│  │  │   ├── ITokenEstimator _tokenEstimator                                 ││
│  │  │   └── ILogger<ContextAssembler> _logger                               ││
│  │  │                                                                        ││
│  │  ├── AssembleAsync(chunks, options)                                      ││
│  │  │   └── Orchestrates the assembly pipeline                              ││
│  │  │                                                                        ││
│  │  ├── Private Helpers                                                     ││
│  │  │   ├── GroupAndOrderChunks()  → Group by file, order by relevance      ││
│  │  │   ├── FormatChunk()          → Dispatch to format-specific method     ││
│  │  │   ├── FormatMarkdown()       → Code blocks with headers               ││
│  │  │   ├── FormatXml()            → XML tags with attributes               ││
│  │  │   ├── FormatJson()           → JSON object structure                  ││
│  │  │   ├── FormatPlain()          → Minimal formatting                     ││
│  │  │   └── BuildWithTokenBudget() → Apply token limits                     ││
│  │  │                                                                        ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  ITokenEstimator                                                         ││
│  │  └── EstimateTokens(text, method) → int                                  ││
│  │                                                                          ││
│  │  TokenEstimator : ITokenEstimator                                        ││
│  │  ├── Constants                                                           ││
│  │  │   ├── CharsPerToken = 4.0f                                            ││
│  │  │   └── WordsPerToken = 0.75f                                           ││
│  │  ├── EstimateTokens(text, method)                                        ││
│  │  │   ├── CharacterBased  → length/4 + special char adjustment            ││
│  │  │   ├── WordBased       → word count with camelCase adjustment          ││
│  │  │   └── Tokenizer       → (placeholder, falls back to CharacterBased)  ││
│  │  └── Private Helpers                                                     ││
│  │      ├── CountSpecialCharacters()                                        ││
│  │      └── HasMixedCase()                                                  ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Assembly Pipeline Flow

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                        Context Assembly Pipeline                              │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  Input: IReadOnlyList<KnowledgeChunk>, ContextBuildOptions                   │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  1. Empty Check                                                          │ │
│  │     - If no chunks → return ContextBuildResult.Empty                     │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  2. Group & Order (if GroupByFile = true)                                │ │
│  │     - Group by FilePath                                                  │ │
│  │     - Order groups by max relevance (descending)                         │ │
│  │     - Order chunks within group by StartLine (ascending)                 │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  3. Format Chunks                                                        │ │
│  │     - For each chunk, call FormatChunk()                                 │ │
│  │     - Dispatch to format-specific method:                                │ │
│  │       ├── Markdown → FormatMarkdown()                                    │ │
│  │       ├── Xml      → FormatXml()                                         │ │
│  │       ├── Json     → FormatJson()                                        │ │
│  │       └── Plain    → FormatPlain()                                       │ │
│  │     - Wrap in FormattedChunk with token estimate                         │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  4. Build With Token Budget                                              │ │
│  │     - Add ContextHeader (if set)                                         │ │
│  │     - Reserve tokens for ContextFooter                                   │ │
│  │     - For each FormattedChunk:                                           │ │
│  │       ├── Check if within MaxTokens budget                               │ │
│  │       ├── If fits: add to output, track included                         │ │
│  │       └── If exceeds: increment truncated count                          │ │
│  │     - Stop at MaxChunks limit                                            │ │
│  │     - Add ContextFooter (if set)                                         │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  5. Build Result                                                         │ │
│  │     - Compute EstimatedTokens for final context                          │ │
│  │     - Extract unique FilesIncluded                                       │ │
│  │     - Calculate AverageRelevance                                         │ │
│  │     - Record BuildTime                                                   │ │
│  │     - Set WasTruncated flag                                              │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  Output: ContextBuildResult                                                  │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Files to Create

| File | Purpose |
|------|---------|
| `src/SeniorIntern.Services/Knowledge/Context/ContextAssembler.cs` | Multi-format context assembly with token budgeting |
| `src/SeniorIntern.Services/Knowledge/Context/TokenEstimator.cs` | Token count estimation utilities |

---

## Detailed Specifications

### 1. ContextAssembler.cs

**Location**: `src/SeniorIntern.Services/Knowledge/Context/ContextAssembler.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Text;
using System.Text.Json;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Context;

/// <summary>
/// Assembles knowledge chunks into formatted context strings for LLM prompts.
/// </summary>
/// <remarks>
/// <para>
/// The context assembler handles:
/// <list type="bullet">
///   <item>Multiple output formats (Markdown, XML, JSON, Plain)</item>
///   <item>Token budget management to fit model context windows</item>
///   <item>Optional file grouping for coherence</item>
///   <item>Custom headers and footers</item>
/// </list>
/// </para>
/// </remarks>
public sealed class ContextAssembler : IContextAssembler
{
    private readonly ITokenEstimator _tokenEstimator;
    private readonly ILogger<ContextAssembler> _logger;

    public ContextAssembler(
        ITokenEstimator tokenEstimator,
        ILogger<ContextAssembler> logger)
    {
        _tokenEstimator = tokenEstimator;
        _logger = logger;
    }

    /// <inheritdoc />
    public Task<ContextBuildResult> AssembleAsync(
        IReadOnlyList<KnowledgeChunk> chunks,
        ContextBuildOptions options,
        CancellationToken ct = default)
    {
        if (chunks.Count == 0)
            return Task.FromResult(ContextBuildResult.Empty);

        var stopwatch = Stopwatch.StartNew();

        // Group by file if requested
        var orderedChunks = options.GroupByFile
            ? GroupAndOrderChunks(chunks)
            : chunks.ToList();

        // Format each chunk
        var formattedChunks = orderedChunks
            .Select(c => FormatChunk(c, options))
            .ToList();

        // Apply token budget
        var (context, included, truncated) = BuildWithTokenBudget(formattedChunks, options);

        var filesIncluded = included.Select(c => c.FilePath).Distinct().ToList();
        var avgRelevance = included.Count > 0 ? included.Average(c => c.Relevance) : 0f;

        stopwatch.Stop();

        var result = new ContextBuildResult
        {
            Context = context,
            EstimatedTokens = _tokenEstimator.EstimateTokens(context, options.TokenEstimation),
            ChunksIncluded = included.Count,
            ChunksTruncated = truncated,
            FilesIncluded = filesIncluded,
            WasTruncated = truncated > 0,
            Format = options.Format,
            BuildTime = stopwatch.Elapsed,
            AverageRelevance = avgRelevance
        };

        _logger.LogDebug(
            "Built context: {Chunks} chunks, ~{Tokens} tokens, {Time}ms",
            result.ChunksIncluded, result.EstimatedTokens, stopwatch.ElapsedMilliseconds);

        return Task.FromResult(result);
    }

    /// <inheritdoc />
    public FormattedChunk FormatChunk(
        KnowledgeChunk chunk,
        ContextFormat format,
        bool includeFileHeader = true,
        bool includeLineNumbers = true)
    {
        var options = new ContextBuildOptions
        {
            Format = format,
            IncludeFileHeaders = includeFileHeader,
            IncludeLineNumbers = includeLineNumbers
        };
        return FormatChunk(chunk, options);
    }

    /// <inheritdoc />
    public int EstimateTokens(string text, TokenEstimationMethod method)
        => _tokenEstimator.EstimateTokens(text, method);

    #region Private Helpers

    private List<KnowledgeChunk> GroupAndOrderChunks(IReadOnlyList<KnowledgeChunk> chunks)
    {
        return chunks
            .GroupBy(c => c.FilePath)
            .OrderByDescending(g => g.Max(c => c.Relevance))
            .SelectMany(g => g.OrderBy(c => c.StartLine))
            .ToList();
    }

    private FormattedChunk FormatChunk(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var formatted = options.Format switch
        {
            ContextFormat.Markdown => FormatMarkdown(chunk, options),
            ContextFormat.Xml => FormatXml(chunk, options),
            ContextFormat.Json => FormatJson(chunk, options),
            ContextFormat.Plain => FormatPlain(chunk, options),
            _ => FormatMarkdown(chunk, options)
        };

        return new FormattedChunk
        {
            FormattedContent = formatted,
            EstimatedTokens = _tokenEstimator.EstimateTokens(formatted, options.TokenEstimation),
            FilePath = chunk.FilePath,
            StartLine = chunk.StartLine,
            EndLine = chunk.EndLine,
            Relevance = chunk.Relevance,
            Language = chunk.Language,
            SourceChunk = chunk
        };
    }

    private static string FormatMarkdown(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var sb = new StringBuilder();

        if (options.IncludeFileHeaders)
        {
            sb.AppendLine($"### {chunk.FilePath}");
            if (options.IncludeLineNumbers)
                sb.AppendLine($"Lines {chunk.StartLine}-{chunk.EndLine}");
            if (options.IncludeScores)
                sb.AppendLine($"Relevance: {chunk.Relevance:P0}");
            sb.AppendLine();
        }

        var language = chunk.Language ?? "text";
        var content = chunk.ExpandedContext ?? chunk.Content;

        sb.AppendLine($"```{language}");
        sb.AppendLine(content);
        sb.AppendLine("```");

        return sb.ToString();
    }

    private static string FormatXml(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var content = chunk.ExpandedContext ?? chunk.Content;
        var escapedContent = System.Security.SecurityElement.Escape(content);
        var escapedPath = System.Security.SecurityElement.Escape(chunk.FilePath);

        var attributes = new List<string> { $"file=\"{escapedPath}\"" };

        if (options.IncludeLineNumbers)
            attributes.Add($"lines=\"{chunk.StartLine}-{chunk.EndLine}\"");
        if (!string.IsNullOrEmpty(chunk.Language))
            attributes.Add($"language=\"{chunk.Language}\"");
        if (options.IncludeScores)
            attributes.Add($"relevance=\"{chunk.Relevance:F2}\"");

        return $"<code-context {string.Join(" ", attributes)}>\n{escapedContent}\n</code-context>";
    }

    private static string FormatJson(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var obj = new Dictionary<string, object>
        {
            ["file"] = chunk.FilePath,
            ["content"] = chunk.ExpandedContext ?? chunk.Content
        };

        if (options.IncludeLineNumbers)
        {
            obj["startLine"] = chunk.StartLine;
            obj["endLine"] = chunk.EndLine;
        }
        if (!string.IsNullOrEmpty(chunk.Language))
            obj["language"] = chunk.Language;
        if (options.IncludeScores)
            obj["relevance"] = chunk.Relevance;

        return JsonSerializer.Serialize(obj, new JsonSerializerOptions { WriteIndented = true });
    }

    private static string FormatPlain(KnowledgeChunk chunk, ContextBuildOptions options)
    {
        var sb = new StringBuilder();

        if (options.IncludeFileHeaders)
        {
            sb.Append($"File: {chunk.FilePath}");
            if (options.IncludeLineNumbers)
                sb.Append($" (lines {chunk.StartLine}-{chunk.EndLine})");
            sb.AppendLine();
            sb.AppendLine(new string('-', 40));
        }

        sb.AppendLine(chunk.ExpandedContext ?? chunk.Content);
        return sb.ToString();
    }

    private (string Context, List<FormattedChunk> Included, int Truncated) BuildWithTokenBudget(
        List<FormattedChunk> chunks, ContextBuildOptions options)
    {
        var sb = new StringBuilder();
        var included = new List<FormattedChunk>();
        var currentTokens = 0;
        var truncated = 0;

        // Add header
        if (!string.IsNullOrEmpty(options.ContextHeader))
        {
            sb.AppendLine(options.ContextHeader);
            sb.AppendLine();
            currentTokens += _tokenEstimator.EstimateTokens(options.ContextHeader, options.TokenEstimation);
        }

        // Reserve for footer
        var footerTokens = 0;
        if (!string.IsNullOrEmpty(options.ContextFooter))
            footerTokens = _tokenEstimator.EstimateTokens(options.ContextFooter, options.TokenEstimation) + 10;

        var availableTokens = options.MaxTokens - footerTokens;

        foreach (var chunk in chunks)
        {
            var sepTokens = _tokenEstimator.EstimateTokens(options.ChunkSeparator, options.TokenEstimation);
            var chunkTokens = chunk.EstimatedTokens + sepTokens;

            if (currentTokens + chunkTokens > availableTokens)
            {
                truncated++;
                continue;
            }

            if (included.Count > 0)
                sb.Append(options.ChunkSeparator);

            sb.Append(chunk.FormattedContent);
            included.Add(chunk);
            currentTokens += chunkTokens;

            if (included.Count >= options.MaxChunks)
                break;
        }

        // Add footer
        if (!string.IsNullOrEmpty(options.ContextFooter))
        {
            sb.AppendLine();
            sb.AppendLine(options.ContextFooter);
        }

        return (sb.ToString().TrimEnd(), included, truncated);
    }

    #endregion
}
```

---

### 2. TokenEstimator.cs

**Location**: `src/SeniorIntern.Services/Knowledge/Context/TokenEstimator.cs`

```csharp
using System;
using System.Text.RegularExpressions;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Knowledge.Context;

/// <summary>
/// Interface for estimating token counts.
/// </summary>
public interface ITokenEstimator
{
    /// <summary>
    /// Estimate the number of tokens in a text string.
    /// </summary>
    /// <param name="text">Text to estimate tokens for.</param>
    /// <param name="method">Estimation method to use.</param>
    /// <returns>Estimated token count.</returns>
    int EstimateTokens(string text, TokenEstimationMethod method = TokenEstimationMethod.CharacterBased);
}

/// <summary>
/// Token count estimation utilities.
/// </summary>
/// <remarks>
/// <para>
/// Provides multiple estimation methods:
/// <list type="bullet">
///   <item>CharacterBased: ~4 characters per token (fast, good for code)</item>
///   <item>WordBased: ~0.75 words per token (better for prose)</item>
///   <item>Tokenizer: Placeholder for actual tokenization</item>
/// </list>
/// </para>
/// <para>
/// CharacterBased includes adjustments for special characters common in code,
/// which tend to tokenize into separate tokens.
/// </para>
/// </remarks>
public sealed class TokenEstimator : ITokenEstimator
{
    private const float CharsPerToken = 4.0f;
    private const float WordsPerToken = 0.75f;

    /// <inheritdoc />
    public int EstimateTokens(string text, TokenEstimationMethod method = TokenEstimationMethod.CharacterBased)
    {
        if (string.IsNullOrEmpty(text))
            return 0;

        return method switch
        {
            TokenEstimationMethod.CharacterBased => EstimateByCharacters(text),
            TokenEstimationMethod.WordBased => EstimateByWords(text),
            TokenEstimationMethod.Tokenizer => EstimateWithTokenizer(text),
            _ => EstimateByCharacters(text)
        };
    }

    private static int EstimateByCharacters(string text)
    {
        var baseEstimate = (int)Math.Ceiling(text.Length / CharsPerToken);
        var specialCharCount = CountSpecialCharacters(text);
        var adjustment = specialCharCount / 3;
        return baseEstimate + adjustment;
    }

    private static int EstimateByWords(string text)
    {
        var words = Regex.Split(text, @"\s+");
        var wordCount = 0;

        foreach (var word in words)
        {
            if (string.IsNullOrEmpty(word)) continue;
            wordCount++;
            if (word.Length > 10) wordCount++;
            if (HasMixedCase(word)) wordCount++;
        }

        return (int)Math.Ceiling(wordCount / WordsPerToken);
    }

    private static int EstimateWithTokenizer(string text)
    {
        // TODO: Implement actual tokenizer (tiktoken or similar)
        return EstimateByCharacters(text);
    }

    private static int CountSpecialCharacters(string text)
    {
        var count = 0;
        foreach (var c in text)
        {
            if (!char.IsLetterOrDigit(c) && !char.IsWhiteSpace(c))
                count++;
        }
        return count;
    }

    private static bool HasMixedCase(string word)
    {
        bool hasUpper = false, hasLower = false;
        foreach (var c in word)
        {
            if (char.IsUpper(c)) hasUpper = true;
            if (char.IsLower(c)) hasLower = true;
            if (hasUpper && hasLower) return true;
        }
        return false;
    }
}
```

---

## Output Format Examples

### Markdown Format

```markdown
### src/Services/UserService.cs
Lines 42-58
Relevance: 85%

```csharp
public async Task<User> GetUserAsync(int id)
{
    var user = await _repository.FindByIdAsync(id);
    if (user == null)
        throw new UserNotFoundException(id);
    return user;
}
```
```

### XML Format

```xml
<code-context file="src/Services/UserService.cs" lines="42-58" language="csharp" relevance="0.85">
public async Task&lt;User&gt; GetUserAsync(int id)
{
    var user = await _repository.FindByIdAsync(id);
    ...
}
</code-context>
```

### JSON Format

```json
{
  "file": "src/Services/UserService.cs",
  "content": "public async Task<User> GetUserAsync(int id) { ... }",
  "startLine": 42,
  "endLine": 58,
  "language": "csharp",
  "relevance": 0.85
}
```

### Plain Format

```
File: src/Services/UserService.cs (lines 42-58)
----------------------------------------
public async Task<User> GetUserAsync(int id)
{
    var user = await _repository.FindByIdAsync(id);
    ...
}
```

---

## Unit Testing Requirements

| Component | Test Count | Focus Areas |
|-----------|------------|-------------|
| `ContextAssembler.AssembleAsync` | 12-15 | Empty handling, grouping, budgeting |
| `ContextAssembler.Format*` | 10-12 | Each format, options handling |
| `TokenEstimator` | 10-12 | Each method, edge cases, accuracy |

**Total: ~32-39 tests**

### Test Scenarios

```
ContextAssembler Tests:
├── AssembleAsync_EmptyChunks_ReturnsEmpty
├── AssembleAsync_WithGroupByFile_GroupsCorrectly
├── AssembleAsync_WithMaxTokens_TruncatesAppropriately
├── AssembleAsync_WithMaxChunks_LimitsCount
├── AssembleAsync_WithHeader_PrependsHeader
├── AssembleAsync_WithFooter_AppendsFooter
├── AssembleAsync_TracksChunksIncluded
├── AssembleAsync_TracksChunksTruncated
├── AssembleAsync_CalculatesAverageRelevance
└── AssembleAsync_RecordsBuildTime

Format Tests:
├── FormatMarkdown_IncludesCodeBlock
├── FormatMarkdown_IncludesFileHeader
├── FormatMarkdown_IncludesLineNumbers
├── FormatXml_EscapesContent
├── FormatXml_IncludesAttributes
├── FormatJson_ValidJson
├── FormatPlain_MinimalFormatting
└── FormatChunk_UsesExpandedContext

TokenEstimator Tests:
├── EstimateByCharacters_EmptyString_ReturnsZero
├── EstimateByCharacters_SimpleText_ApproximatelyCorrect
├── EstimateByCharacters_WithSpecialChars_AdjustsEstimate
├── EstimateByWords_CountsWords
├── EstimateByWords_LongWords_AddsExtra
├── EstimateByWords_CamelCase_AddsExtra
└── EstimateWithTokenizer_FallsBackToCharacterBased
```

---

## Acceptance Criteria

### Functional Requirements
- [ ] `ContextAssembler.AssembleAsync` groups chunks by file when `GroupByFile = true`
- [ ] `ContextAssembler.AssembleAsync` orders groups by max relevance
- [ ] `ContextAssembler.AssembleAsync` respects `MaxTokens` budget
- [ ] `ContextAssembler.AssembleAsync` respects `MaxChunks` limit
- [ ] `ContextAssembler.AssembleAsync` adds header/footer when provided
- [ ] `FormatMarkdown` produces valid markdown with code blocks
- [ ] `FormatXml` properly escapes content and attributes
- [ ] `FormatJson` produces valid JSON
- [ ] `FormatPlain` uses minimal formatting
- [ ] `TokenEstimator` adjusts for special characters in code

### Quality Requirements
- [ ] All public methods have XML documentation
- [ ] Logging at Debug level for assembly operations
- [ ] Thread-safe (stateless formatting methods)
- [ ] Uses `ExpandedContext` when available, falls back to `Content`

---

## Future Considerations

Items deferred to later versions:
- **Future**: Actual tokenizer integration (tiktoken)
- **Future**: Model-specific token estimation profiles
- **Future**: Hybrid formats (e.g., markdown with JSON metadata)
