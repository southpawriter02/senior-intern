# Design Specification: AIntern v0.7.4h "RAG-Aware Chat Integration"

## Overview

**Version**: v0.7.4h  
**Parent**: v0.7.4 Retrieval & Context  
**Focus**: Integrate the knowledge service with the chat system to enable RAG-enhanced responses

### Purpose

This sub-version integrates RAG capabilities into the chat workflow:
1. `IRagChatService` - Interface for RAG-enhanced chat operations
2. `RagChatService` - Implementation orchestrating knowledge retrieval and LLM response
3. `RagChatOptions` - Configuration for RAG chat behavior
4. `RagContextPreview` - Preview model for debugging/UI display

### Dependencies

**From v0.7.4a (Knowledge Service Interface)**:
- `IKnowledgeService` for knowledge retrieval

**From v0.7.4c (Context Building Models)**:
- `ContextBuildOptions`, `ContextFormat` for context assembly

**From Existing Infrastructure**:
- `ILlmService` for LLM inference
- `IConversationService` for conversation management
- `ChatMessage`, `MessageRole`, `InferenceOptions` from chat models

---

## Architecture

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                     v0.7.4h RAG-Aware Chat Integration                        │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  src/SeniorIntern.Services/Chat/                                             │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │                                                                          ││
│  │  IRagChatService                                                         ││
│  │  ├── GenerateWithRagAsync(conversationId, userMessage, options)          ││
│  │  │   └── Returns: IAsyncEnumerable<string> (streaming tokens)            ││
│  │  └── PreviewContextAsync(userMessage, options)                           ││
│  │      └── Returns: RagContextPreview (debugging/UI)                       ││
│  │                                                                          ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │                                                                          ││
│  │  RagChatService : IRagChatService                                        ││
│  │  ├── Dependencies (injected)                                             ││
│  │  │   ├── ILlmService _llmService                                         ││
│  │  │   ├── IKnowledgeService _knowledgeService                             ││
│  │  │   ├── IConversationService _conversationService                       ││
│  │  │   └── ILogger<RagChatService> _logger                                 ││
│  │  │                                                                        ││
│  │  ├── Constants                                                           ││
│  │  │   ├── DefaultSystemPrompt (The Senior Intern persona)                 ││
│  │  │   └── RagInstructions (how to use code context)                       ││
│  │  │                                                                        ││
│  │  ├── GenerateWithRagAsync()                                              ││
│  │  │   ├── Get conversation                                                ││
│  │  │   ├── Retrieve RAG context (if enabled)                               ││
│  │  │   ├── Build messages with context                                     ││
│  │  │   └── Stream LLM response                                             ││
│  │  │                                                                        ││
│  │  ├── PreviewContextAsync()                                               ││
│  │  │   ├── Check RAG availability                                          ││
│  │  │   ├── Query knowledge service                                         ││
│  │  │   └── Return preview with metadata                                    ││
│  │  │                                                                        ││
│  │  └── Private Helpers                                                     ││
│  │      ├── RetrieveContextAsync()                                          ││
│  │      └── BuildMessagesWithRag()                                          ││
│  │                                                                          ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  src/SeniorIntern.Core/Models/                                               │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │                                                                          ││
│  │  RagChatOptions                                                          ││
│  │  ├── EnableRag: bool                    (default: true)                  ││
│  │  ├── WorkspacePath: string?             (required for RAG)               ││
│  │  ├── MaxRagTokens: int                  (default: 4000)                  ││
│  │  ├── MaxRagChunks: int                  (default: 10)                    ││
│  │  ├── MinRelevance: float                (default: 0.5)                   ││
│  │  ├── MaxHistoryMessages: int            (default: 20)                    ││
│  │  ├── SystemPrompt: string?              (custom prompt)                  ││
│  │  ├── InferenceOptions: InferenceOptions (LLM settings)                   ││
│  │  └── IncludeMetadata: bool              (default: false)                 ││
│  │                                                                          ││
│  │  RagContextPreview                                                       ││
│  │  ├── IsEnabled: bool                    (RAG available?)                 ││
│  │  ├── Reason: string?                    (why disabled)                   ││
│  │  ├── Context: string?                   (context content)                ││
│  │  ├── ChunksFound: int                   (result count)                   ││
│  │  ├── FilesFound: int                    (unique files)                   ││
│  │  ├── QueryTime: TimeSpan                (retrieval time)                 ││
│  │  ├── RelevantFiles: IReadOnlyList<string>                                ││
│  │  └── EstimatedTokens: int               (token count)                    ││
│  │                                                                          ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## RAG Chat Pipeline Flow

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                        GenerateWithRagAsync Pipeline                          │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  Input: (conversationId, userMessage, RagChatOptions)                        │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  1. Get Conversation                                                     │ │
│  │     - _conversationService.GetConversationAsync(conversationId)          │ │
│  │     - Throw if not found                                                 │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  2. Retrieve RAG Context (if enabled)                                    │ │
│  │     - Check options.EnableRag && options.WorkspacePath                   │ │
│  │     - If enabled: call RetrieveContextAsync()                            │ │
│  │       ├── Check IsIndexedAsync()                                         │ │
│  │       ├── Call BuildContextAsync() with options                          │ │
│  │       └── Return context string or null                                  │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  3. Build Messages With RAG                                              │ │
│  │     - Create system message:                                             │ │
│  │       ├── Use custom or DefaultSystemPrompt                              │ │
│  │       ├── Append RagInstructions (if context available)                  │ │
│  │       └── Append "## Relevant Code Context" + context                    │ │
│  │     - Include conversation history (limited by MaxHistoryMessages)       │ │
│  │     - Add current user message                                           │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  4. Stream LLM Response                                                  │ │
│  │     - _llmService.GenerateStreamingAsync(messages, inferenceOptions)     │ │
│  │     - Yield each token as received                                       │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│     │                                                                        │
│     ▼                                                                        │
│  Output: IAsyncEnumerable<string> (streaming tokens)                         │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Message Structure

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                     System Message Structure (with RAG)                       │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  [System Prompt]                                                         │ │
│  │                                                                          │ │
│  │  You are The Senior Intern, a helpful coding assistant with knowledge    │ │
│  │  of the user's codebase. Provide clear, concise answers with code        │ │
│  │  examples when appropriate. When referencing code from the provided      │ │
│  │  context, mention the file path and line numbers.                        │ │
│  │                                                                          │ │
│  │  [RAG Instructions] (if context present)                                 │ │
│  │                                                                          │ │
│  │  You have been provided with relevant code context from the user's       │ │
│  │  codebase. Use this context to provide accurate, specific answers        │ │
│  │  about their code.                                                       │ │
│  │  When referencing code:                                                  │ │
│  │  - Mention the file path and line numbers                                │ │
│  │  - Quote relevant code snippets when helpful                             │ │
│  │  - If the context doesn't contain relevant information, say so           │ │
│  │  - Don't make up code that isn't in the context unless creating new      │ │
│  │                                                                          │ │
│  │  ## Relevant Code Context                                                │ │
│  │                                                                          │ │
│  │  ### src/Services/UserService.cs                                         │ │
│  │  Lines 42-58                                                             │ │
│  │                                                                          │ │
│  │  ```csharp                                                               │ │
│  │  public async Task<User> GetUserAsync(int id)                            │ │
│  │  {                                                                       │ │
│  │      // implementation...                                                │ │
│  │  }                                                                       │ │
│  │  ```                                                                     │ │
│  │                                                                          │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  [Conversation History - up to MaxHistoryMessages]                           │
│                                                                              │
│  [Current User Message]                                                      │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Files to Create

| File | Purpose |
|------|---------|
| `src/SeniorIntern.Services/Chat/IRagChatService.cs` | Interface for RAG-enhanced chat |
| `src/SeniorIntern.Services/Chat/RagChatService.cs` | Implementation with RAG context injection |
| `src/SeniorIntern.Core/Models/RagChatModels.cs` | RagChatOptions and RagContextPreview |

---

## Detailed Specifications

### 1. IRagChatService.cs

**Location**: `src/SeniorIntern.Services/Chat/IRagChatService.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Chat;

/// <summary>
/// Interface for RAG-enhanced chat service.
/// </summary>
public interface IRagChatService
{
    /// <summary>
    /// Generate a streaming response with RAG context.
    /// </summary>
    /// <param name="conversationId">Conversation to add message to.</param>
    /// <param name="userMessage">The user's message.</param>
    /// <param name="options">RAG chat options.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Async enumerable of response tokens.</returns>
    IAsyncEnumerable<string> GenerateWithRagAsync(
        Guid conversationId,
        string userMessage,
        RagChatOptions options,
        CancellationToken ct = default);

    /// <summary>
    /// Preview the context that would be used for a query.
    /// Useful for debugging or UI preview.
    /// </summary>
    /// <param name="userMessage">The user's message.</param>
    /// <param name="options">RAG chat options.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Preview of the RAG context.</returns>
    Task<RagContextPreview> PreviewContextAsync(
        string userMessage,
        RagChatOptions options,
        CancellationToken ct = default);
}
```

---

### 2. RagChatService.cs

**Location**: `src/SeniorIntern.Services/Chat/RagChatService.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Chat;

/// <summary>
/// Chat service with RAG (Retrieval-Augmented Generation) support.
/// Integrates knowledge retrieval with LLM response generation.
/// </summary>
/// <remarks>
/// <para>
/// This service orchestrates:
/// <list type="bullet">
///   <item>Knowledge retrieval via IKnowledgeService</item>
///   <item>Context injection into system prompts</item>
///   <item>Streaming LLM response generation</item>
/// </list>
/// </para>
/// <para>
/// RAG context is gracefully optional - if retrieval fails or no
/// relevant context is found, the chat continues without it.
/// </para>
/// </remarks>
public sealed class RagChatService : IRagChatService
{
    private readonly ILlmService _llmService;
    private readonly IKnowledgeService _knowledgeService;
    private readonly IConversationService _conversationService;
    private readonly ILogger<RagChatService> _logger;

    private const string DefaultSystemPrompt = """
        You are The Senior Intern, a helpful coding assistant with knowledge of the user's codebase.
        Provide clear, concise answers with code examples when appropriate.
        When referencing code from the provided context, mention the file path and line numbers.
        """;

    private const string RagInstructions = """
        You have been provided with relevant code context from the user's codebase.
        Use this context to provide accurate, specific answers about their code.
        When referencing code:
        - Mention the file path and line numbers
        - Quote relevant code snippets when helpful
        - If the context doesn't contain relevant information, say so and provide general guidance
        - Don't make up code that isn't in the context unless clearly creating new code
        """;

    public RagChatService(
        ILlmService llmService,
        IKnowledgeService knowledgeService,
        IConversationService conversationService,
        ILogger<RagChatService> logger)
    {
        _llmService = llmService ?? throw new ArgumentNullException(nameof(llmService));
        _knowledgeService = knowledgeService ?? throw new ArgumentNullException(nameof(knowledgeService));
        _conversationService = conversationService ?? throw new ArgumentNullException(nameof(conversationService));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    /// <inheritdoc />
    public async IAsyncEnumerable<string> GenerateWithRagAsync(
        Guid conversationId,
        string userMessage,
        RagChatOptions options,
        [EnumeratorCancellation] CancellationToken ct = default)
    {
        var conversation = await _conversationService.GetConversationAsync(conversationId, ct);
        if (conversation == null)
            throw new InvalidOperationException($"Conversation not found: {conversationId}");

        // Retrieve RAG context if enabled
        string? ragContext = null;
        if (options.EnableRag && !string.IsNullOrEmpty(options.WorkspacePath))
        {
            ragContext = await RetrieveContextAsync(userMessage, options, ct);
        }

        // Build messages with context
        var messages = BuildMessagesWithRag(conversation.Messages, userMessage, ragContext, options);

        _logger.LogDebug(
            "Generating RAG response: {MessageCount} messages, context: {HasContext}",
            messages.Count(), ragContext != null);

        // Stream response
        await foreach (var token in _llmService.GenerateStreamingAsync(
            messages, options.InferenceOptions, ct))
        {
            yield return token;
        }
    }

    /// <inheritdoc />
    public async Task<RagContextPreview> PreviewContextAsync(
        string userMessage,
        RagChatOptions options,
        CancellationToken ct = default)
    {
        if (!options.EnableRag)
        {
            return new RagContextPreview { IsEnabled = false, Reason = "RAG is disabled" };
        }

        if (string.IsNullOrEmpty(options.WorkspacePath))
        {
            return new RagContextPreview { IsEnabled = false, Reason = "No workspace path configured" };
        }

        var isIndexed = await _knowledgeService.IsIndexedAsync(options.WorkspacePath, ct);
        if (!isIndexed)
        {
            return new RagContextPreview { IsEnabled = false, Reason = "Workspace is not indexed" };
        }

        var queryResult = await _knowledgeService.QueryAsync(userMessage, new KnowledgeQueryOptions
        {
            WorkspacePath = options.WorkspacePath,
            MaxResults = options.MaxRagChunks,
            MinRelevance = options.MinRelevance,
            ExpandContext = true
        }, ct);

        var context = await _knowledgeService.BuildContextFromChunksAsync(
            queryResult.Chunks,
            new ContextBuildOptions
            {
                WorkspacePath = options.WorkspacePath,
                MaxTokens = options.MaxRagTokens,
                Format = ContextFormat.Markdown
            }, ct);

        return new RagContextPreview
        {
            IsEnabled = true,
            Context = context,
            ChunksFound = queryResult.Chunks.Count,
            FilesFound = queryResult.RelevantFiles.Count,
            QueryTime = queryResult.QueryTime,
            RelevantFiles = queryResult.RelevantFiles.ToList()
        };
    }

    #region Private Helpers

    private async Task<string?> RetrieveContextAsync(
        string userMessage, RagChatOptions options, CancellationToken ct)
    {
        try
        {
            var isIndexed = await _knowledgeService.IsIndexedAsync(options.WorkspacePath!, ct);
            if (!isIndexed)
            {
                _logger.LogDebug("Workspace not indexed, skipping RAG");
                return null;
            }

            var context = await _knowledgeService.BuildContextAsync(
                userMessage,
                new ContextBuildOptions
                {
                    WorkspacePath = options.WorkspacePath!,
                    MaxTokens = options.MaxRagTokens,
                    MaxChunks = options.MaxRagChunks,
                    MinRelevance = options.MinRelevance,
                    Format = ContextFormat.Markdown,
                    IncludeFileHeaders = true,
                    IncludeLineNumbers = true
                }, ct);

            if (string.IsNullOrWhiteSpace(context))
            {
                _logger.LogDebug("No relevant context found for query");
                return null;
            }

            _logger.LogDebug("Retrieved RAG context: {Length} chars", context.Length);
            return context;
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Failed to retrieve RAG context, continuing without");
            return null;
        }
    }

    private IEnumerable<ChatMessage> BuildMessagesWithRag(
        IEnumerable<ChatMessage> history,
        string userMessage,
        string? ragContext,
        RagChatOptions options)
    {
        // Build system prompt with RAG context
        var systemPrompt = options.SystemPrompt ?? DefaultSystemPrompt;
        if (!string.IsNullOrEmpty(ragContext))
        {
            systemPrompt = $"{systemPrompt}\n\n{RagInstructions}\n\n## Relevant Code Context\n\n{ragContext}";
        }

        yield return new ChatMessage { Role = MessageRole.System, Content = systemPrompt };

        // Include limited conversation history
        foreach (var msg in history.TakeLast(options.MaxHistoryMessages))
        {
            yield return msg;
        }

        // Current user message
        yield return new ChatMessage { Role = MessageRole.User, Content = userMessage };
    }

    #endregion
}
```

---

### 3. RagChatModels.cs

**Location**: `src/SeniorIntern.Core/Models/RagChatModels.cs`

```csharp
using System;
using System.Collections.Generic;

namespace SeniorIntern.Core.Models;

/// <summary>
/// Options for RAG-enhanced chat.
/// </summary>
public sealed class RagChatOptions
{
    /// <summary>
    /// Whether to enable RAG context injection.
    /// Default: true
    /// </summary>
    public bool EnableRag { get; init; } = true;

    /// <summary>
    /// Workspace path to retrieve context from.
    /// </summary>
    public string? WorkspacePath { get; init; }

    /// <summary>
    /// Maximum tokens to use for RAG context.
    /// Default: 4000
    /// </summary>
    public int MaxRagTokens { get; init; } = 4000;

    /// <summary>
    /// Maximum chunks to retrieve for context.
    /// Default: 10
    /// </summary>
    public int MaxRagChunks { get; init; } = 10;

    /// <summary>
    /// Minimum relevance score for included context.
    /// Default: 0.5
    /// </summary>
    public float MinRelevance { get; init; } = 0.5f;

    /// <summary>
    /// Maximum conversation history messages to include.
    /// Default: 20
    /// </summary>
    public int MaxHistoryMessages { get; init; } = 20;

    /// <summary>
    /// Custom system prompt (replaces default).
    /// </summary>
    public string? SystemPrompt { get; init; }

    /// <summary>
    /// Inference options for the LLM.
    /// </summary>
    public InferenceOptions InferenceOptions { get; init; } = new();

    /// <summary>
    /// Whether to include RAG metadata in response (for debugging).
    /// Default: false
    /// </summary>
    public bool IncludeMetadata { get; init; } = false;
}

/// <summary>
/// Preview of RAG context for a query.
/// </summary>
public sealed class RagContextPreview
{
    /// <summary>
    /// Whether RAG is enabled and available.
    /// </summary>
    public bool IsEnabled { get; init; }

    /// <summary>
    /// Reason if RAG is not enabled.
    /// </summary>
    public string? Reason { get; init; }

    /// <summary>
    /// The context that would be injected.
    /// </summary>
    public string? Context { get; init; }

    /// <summary>
    /// Number of chunks found.
    /// </summary>
    public int ChunksFound { get; init; }

    /// <summary>
    /// Number of files containing matches.
    /// </summary>
    public int FilesFound { get; init; }

    /// <summary>
    /// Time to retrieve context.
    /// </summary>
    public TimeSpan QueryTime { get; init; }

    /// <summary>
    /// List of relevant file paths.
    /// </summary>
    public IReadOnlyList<string> RelevantFiles { get; init; } = Array.Empty<string>();

    /// <summary>
    /// Estimated token count of context.
    /// </summary>
    public int EstimatedTokens { get; init; }

    /// <summary>
    /// Whether context was found.
    /// </summary>
    public bool HasContext => !string.IsNullOrEmpty(Context);
}
```

---

## Unit Testing Requirements

| Component | Test Count | Focus Areas |
|-----------|------------|-------------|
| `RagChatService.GenerateWithRagAsync` | 10-12 | Streaming, context injection, error handling |
| `RagChatService.PreviewContextAsync` | 8-10 | All disabled reasons, successful preview |
| `RagChatService.BuildMessagesWithRag` | 5-6 | Prompt structure, history limiting |
| `RagChatOptions` | 4-5 | Default values, init-only properties |
| `RagContextPreview` | 3-4 | HasContext computed property |

**Total: ~30-37 tests**

### Test Scenarios

```
GenerateWithRagAsync Tests:
├── Generate_ConversationNotFound_ThrowsInvalidOperation
├── Generate_RagDisabled_GeneratesWithoutContext
├── Generate_WorkspaceNotIndexed_GeneratesWithoutContext
├── Generate_WithContext_InjectsIntoSystemPrompt
├── Generate_RetrievalFails_ContinuesWithoutContext
├── Generate_StreamsTokensCorrectly
└── Generate_IncludesConversationHistory

PreviewContextAsync Tests:
├── Preview_RagDisabled_ReturnsDisabledReason
├── Preview_NoWorkspacePath_ReturnsDisabledReason
├── Preview_NotIndexed_ReturnsDisabledReason
├── Preview_Success_ReturnsContextAndMetadata
├── Preview_NoResults_ReturnsEmptyContext
└── Preview_TracksQueryTime

BuildMessagesWithRag Tests:
├── Build_WithContext_AppendsToSystemPrompt
├── Build_WithoutContext_UsesBasePrompt
├── Build_CustomSystemPrompt_ReplacesDefault
├── Build_LimitsHistoryToMaxMessages
└── Build_IncludesUserMessage
```

---

## Acceptance Criteria

### Functional Requirements
- [ ] `GenerateWithRagAsync` streams tokens from LLM
- [ ] RAG context is injected into system prompt when available
- [ ] Graceful degradation when RAG unavailable or fails
- [ ] `PreviewContextAsync` returns appropriate reason when disabled
- [ ] Conversation history is limited by `MaxHistoryMessages`
- [ ] Custom system prompts replace default
- [ ] All options have sensible defaults

### Quality Requirements
- [ ] All public methods have XML documentation
- [ ] Logging at appropriate levels
- [ ] Null checks on constructor parameters
- [ ] Thread-safe streaming implementation

---

## Future Considerations

Items deferred to later versions:
- **Future**: RAG metadata in response (file references, relevance scores)
- **Future**: Multi-turn RAG with context refinement
- **Future**: User feedback on RAG quality
