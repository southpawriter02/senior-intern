# Design Specification: AIntern v0.7.3d "File Processing Pipeline"

## Overview

**Version**: v0.7.3d
**Parent**: v0.7.3 Indexing Pipeline
**Focus**: Individual file processing through the complete read → chunk → embed → store pipeline

### Purpose

This sub-version implements the detailed file processing components:
1. `FileProcessor` - Process individual files through the complete pipeline
2. `FileContentReader` - Read file contents with encoding detection
3. `FileHasher` - Compute file hashes for change detection
4. `EmbeddingBatcher` - Batch embedding requests for efficiency
5. Supporting models for processing context and results

### Dependencies

**From v0.7.1 (Embedding Foundation)**:
- `IEmbeddingService` for generating embeddings (v0.7.1a)
- `IChunkingService` for text chunking (v0.7.1e)
- `TextChunk` model (v0.7.1d)
- `ChunkingOptions` model (v0.7.1d)

**From v0.7.2 (Vector Storage)**:
- `IVectorStore` for storing embeddings (v0.7.2a)
- `ChunkWithEmbedding` model (v0.7.2c)
- `IndexedFile` model (v0.7.2h)

**From v0.7.3b (Indexing Models & Options)**:
- `IndexingOptions` configuration
- `IndexingError` for error capture

**From v0.7.3c (Indexing Service Implementation)**:
- `IndexingService` consumes `FileProcessor`

---

## Architecture

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                     v0.7.3d File Processing Pipeline                          │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  src/SeniorIntern.Services/Indexing/                                         │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │                                                                          ││
│  │  FileProcessor                                                           ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Dependencies                                                      │  ││
│  │  │  ├── IChunkingService _chunkingService                             │  ││
│  │  │  ├── IEmbeddingService _embeddingService                           │  ││
│  │  │  ├── IVectorStore _vectorStore                                     │  ││
│  │  │  └── ILogger<FileProcessor> _logger                                │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Methods                                                           │  ││
│  │  │  ├── ProcessFileAsync(context) → FileProcessingResult             │  ││
│  │  │  └── ProcessFilesAsync(contexts, parallelism, progress)           │  ││
│  │  │      → BatchProcessingResult                                       │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │                                                                          ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  FileContentReader (Static Utility)                                      ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Methods                                                           │  ││
│  │  │  ├── ReadAsync(filePath) → FileContent                             │  ││
│  │  │  ├── ReadLinesAsync(filePath, startLine, endLine) → string[]      │  ││
│  │  │  └── DetectEncoding(stream) → Encoding                             │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Encoding Detection                                                │  ││
│  │  │  ├── BOM detection (UTF-8, UTF-16 LE/BE, UTF-32)                   │  ││
│  │  │  ├── Heuristic detection for BOM-less files                       │  ││
│  │  │  └── Fallback to UTF-8 with error handling                        │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  FileHasher (Static Utility)                                             ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Methods                                                           │  ││
│  │  │  ├── ComputeHash(content) → string (SHA256 hex)                   │  ││
│  │  │  ├── ComputeHashAsync(stream) → string                            │  ││
│  │  │  └── ComputeHashFromFile(filePath) → string                       │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  EmbeddingBatcher                                                        ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Constructor                                                       │  ││
│  │  │  └── EmbeddingBatcher(embeddingService, batchSize = 32)           │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Methods                                                           │  ││
│  │  │  ├── EmbedChunksAsync(chunks, progress) → ChunkWithEmbedding[]    │  ││
│  │  │  └── EmbedTextsAsync(texts, progress) → float[][]                 │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  Supporting Models                                                           │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  FileProcessingContext      → Input context for processing a file       ││
│  │  FileProcessingResult       → Result of processing a single file        ││
│  │  FileProcessingStatus       → Success, Failed, Skipped                   ││
│  │  FileContent                → Read file contents with metadata           ││
│  │  BatchProcessingResult      → Aggregated batch results                   ││
│  │  BatchProgress              → Progress for batch operations              ││
│  │  EmbeddingBatchProgress     → Progress for embedding batches             ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## File Processing Pipeline Flow

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                   Single File Processing Pipeline                             │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  FileProcessor.ProcessFileAsync(context)                                     │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Step 1: READ FILE                                                      │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  FileContentReader.ReadAsync(absolutePath)                        │  │ │
│  │  │  ├── Open file stream                                             │  │ │
│  │  │  ├── Detect encoding (BOM or heuristic)                          │  │ │
│  │  │  ├── Read entire content as string                                │  │ │
│  │  │  ├── Count lines                                                  │  │ │
│  │  │  └── Return FileContent { Content, Encoding, LineCount }         │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │                                                                          │ │
│  │  Output: FileContent                                                     │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Step 2: COMPUTE HASH                                                   │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  FileHasher.ComputeHash(content)                                  │  │ │
│  │  │  ├── Convert string to UTF-8 bytes                                │  │ │
│  │  │  ├── Compute SHA256 hash                                          │  │ │
│  │  │  └── Return lowercase hex string                                  │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │                                                                          │ │
│  │  Output: string (e.g., "a1b2c3d4...")                                   │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Step 3: CHUNK CONTENT                                                  │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  IChunkingService.ChunkDocument(content, relativePath, options)  │  │ │
│  │  │  ├── Detect language from file extension                          │  │ │
│  │  │  ├── Apply semantic chunking (code-aware or text-based)          │  │ │
│  │  │  ├── Create TextChunk instances with metadata                     │  │ │
│  │  │  └── Return IReadOnlyList<TextChunk>                             │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │                                                                          │ │
│  │  Output: IReadOnlyList<TextChunk>                                       │ │
│  │  Note: If chunks.Count == 0, skip to IndexedFile creation              │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Step 4: GENERATE EMBEDDINGS                                            │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  IEmbeddingService.EmbedBatchAsync(chunkContents, null, ct)      │  │ │
│  │  │  ├── Extract Content from each TextChunk                          │  │ │
│  │  │  ├── Send batch to embedding model                                │  │ │
│  │  │  └── Return IReadOnlyList<float[]>                                │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │                                                                          │ │
│  │  Output: IReadOnlyList<float[]> (one embedding per chunk)               │ │
│  │  Timing: Track EmbeddingDurationMs                                      │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Step 5: CREATE INDEXED FILE RECORD                                     │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  new IndexedFile                                                  │  │ │
│  │  │  {                                                                 │  │ │
│  │  │    IndexId, FilePath, FileHash, FileSize, LastModified,           │  │ │
│  │  │    ChunkCount, Language, Encoding, LineCount,                     │  │ │
│  │  │    Status = FileIndexStatus.Indexed,                              │  │ │
│  │  │    IndexingDurationMs                                             │  │ │
│  │  │  }                                                                 │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │  Step 6: STORE IN DATABASE                                              │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  IVectorStore.UpsertIndexedFileAsync(indexId, indexedFile)       │  │ │
│  │  │  ├── Insert or update file metadata                               │  │ │
│  │  │  └── Get generated file ID                                        │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Create ChunkWithEmbedding list                                   │  │ │
│  │  │  ├── Zip chunks with embeddings                                   │  │ │
│  │  │  └── Include FileId reference                                     │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  │  ┌───────────────────────────────────────────────────────────────────┐  │ │
│  │  │  IVectorStore.AddChunksAsync(indexId, chunksWithEmbeddings)      │  │ │
│  │  │  └── Bulk insert chunks with embeddings                          │  │ │
│  │  └───────────────────────────────────────────────────────────────────┘  │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│  │                                                                           │
│  ▼                                                                           │
│  Return FileProcessingResult                                                 │
│  {                                                                           │
│    FilePath, Status = Success, ChunkCount, FileSize, LineCount,             │
│    Language, Encoding, DurationMs, EmbeddingDurationMs                      │
│  }                                                                           │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Files to Create

| File | Purpose |
|------|---------|
| `src/SeniorIntern.Services/Indexing/FileProcessor.cs` | Main file processing class |
| `src/SeniorIntern.Services/Indexing/FileContentReader.cs` | File reading with encoding detection |
| `src/SeniorIntern.Services/Indexing/FileHasher.cs` | File hash computation |
| `src/SeniorIntern.Services/Indexing/EmbeddingBatcher.cs` | Batch embedding requests |
| `src/SeniorIntern.Services/Indexing/FileProcessingModels.cs` | Context and result models |

---

## Detailed Specifications

### 1. FileProcessor.cs

**Location**: `src/SeniorIntern.Services/Indexing/FileProcessor.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;
using SeniorIntern.Services.VectorStore;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Processes individual files through the indexing pipeline.
/// </summary>
/// <remarks>
/// <para>
/// FileProcessor handles the complete pipeline for a single file:
/// <list type="number">
///   <item>Read file content with encoding detection</item>
///   <item>Compute file hash for change detection</item>
///   <item>Chunk content using code-aware chunking</item>
///   <item>Generate embeddings for all chunks</item>
///   <item>Store file metadata and chunks in vector database</item>
/// </list>
/// </para>
/// <para>
/// The processor is designed to be called in parallel from
/// <see cref="IndexingService"/> for efficient batch processing.
/// </para>
/// </remarks>
public sealed class FileProcessor
{
    private readonly IChunkingService _chunkingService;
    private readonly IEmbeddingService _embeddingService;
    private readonly IVectorStore _vectorStore;
    private readonly ILogger<FileProcessor> _logger;

    /// <summary>
    /// Initializes a new instance of the <see cref="FileProcessor"/> class.
    /// </summary>
    public FileProcessor(
        IChunkingService chunkingService,
        IEmbeddingService embeddingService,
        IVectorStore vectorStore,
        ILogger<FileProcessor> logger)
    {
        _chunkingService = chunkingService ?? throw new ArgumentNullException(nameof(chunkingService));
        _embeddingService = embeddingService ?? throw new ArgumentNullException(nameof(embeddingService));
        _vectorStore = vectorStore ?? throw new ArgumentNullException(nameof(vectorStore));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    /// <summary>
    /// Process a single file through the complete pipeline.
    /// </summary>
    /// <param name="context">Processing context with file paths and options.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Result containing processing statistics and any errors.</returns>
    public async Task<FileProcessingResult> ProcessFileAsync(
        FileProcessingContext context,
        CancellationToken ct = default)
    {
        ArgumentNullException.ThrowIfNull(context);

        var stopwatch = Stopwatch.StartNew();
        var result = new FileProcessingResult
        {
            FilePath = context.RelativePath,
            StartedAt = DateTime.UtcNow
        };

        try
        {
            // Step 1: Read file
            _logger.LogDebug("Reading file: {Path}", context.RelativePath);
            var fileContent = await FileContentReader.ReadAsync(context.AbsolutePath, ct);

            result.FileSize = new FileInfo(context.AbsolutePath).Length;
            result.LineCount = fileContent.LineCount;
            result.Encoding = fileContent.Encoding;

            // Step 2: Compute hash for change detection
            var fileHash = FileHasher.ComputeHash(fileContent.Content);

            // Step 3: Chunk the content
            _logger.LogDebug("Chunking file: {Path}", context.RelativePath);
            var chunks = _chunkingService.ChunkDocument(
                fileContent.Content,
                context.RelativePath,
                context.Options.ChunkingOptions);

            result.ChunkCount = chunks.Count;
            result.Language = chunks.FirstOrDefault()?.Language
                ?? _chunkingService.DetectLanguage(context.RelativePath);

            if (chunks.Count == 0)
            {
                _logger.LogDebug("No chunks created for: {Path}", context.RelativePath);

                // Still track the file even with no chunks
                await StoreEmptyFileRecord(context, fileContent, fileHash, result, ct);

                result.Status = FileProcessingStatus.Skipped;
                result.SkipReason = "No content to chunk";
                stopwatch.Stop();
                result.DurationMs = (int)stopwatch.ElapsedMilliseconds;
                return result;
            }

            // Step 4: Generate embeddings
            _logger.LogDebug("Generating embeddings for {Count} chunks", chunks.Count);
            var embeddingStopwatch = Stopwatch.StartNew();

            var embeddings = await _embeddingService.EmbedBatchAsync(
                chunks.Select(c => c.Content),
                null,
                ct);

            embeddingStopwatch.Stop();
            result.EmbeddingDurationMs = (int)embeddingStopwatch.ElapsedMilliseconds;

            // Step 5: Create indexed file record
            var indexedFile = new IndexedFile
            {
                IndexId = context.IndexId,
                FilePath = context.RelativePath,
                FileHash = fileHash,
                FileSize = result.FileSize,
                LastModified = new FileInfo(context.AbsolutePath).LastWriteTimeUtc,
                ChunkCount = chunks.Count,
                Language = result.Language,
                Encoding = result.Encoding,
                LineCount = result.LineCount,
                Status = FileIndexStatus.Indexed,
                IndexingDurationMs = (int)stopwatch.ElapsedMilliseconds
            };

            // Step 6: Store in database
            _logger.LogDebug("Storing {Count} chunks", chunks.Count);
            await _vectorStore.UpsertIndexedFileAsync(context.IndexId, indexedFile, ct);

            var chunksWithEmbeddings = chunks.Zip(embeddings, (chunk, embedding) =>
                new ChunkWithEmbedding
                {
                    Chunk = chunk,
                    Embedding = embedding,
                    FileId = indexedFile.Id
                }).ToList();

            await _vectorStore.AddChunksAsync(context.IndexId, chunksWithEmbeddings, ct);

            stopwatch.Stop();
            result.DurationMs = (int)stopwatch.ElapsedMilliseconds;
            result.Status = FileProcessingStatus.Success;

            _logger.LogDebug(
                "Processed {Path}: {Chunks} chunks in {Duration}ms",
                context.RelativePath, chunks.Count, result.DurationMs);

            return result;
        }
        catch (Exception ex)
        {
            stopwatch.Stop();
            result.DurationMs = (int)stopwatch.ElapsedMilliseconds;
            result.Status = FileProcessingStatus.Failed;
            result.Error = IndexingError.FromException(context.RelativePath, ex);

            _logger.LogWarning(ex, "Failed to process file: {Path}", context.RelativePath);
            return result;
        }
    }

    /// <summary>
    /// Process multiple files in parallel.
    /// </summary>
    /// <param name="contexts">File processing contexts.</param>
    /// <param name="parallelism">Maximum parallel file processing.</param>
    /// <param name="progress">Optional progress reporter.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Aggregated batch processing result.</returns>
    public async Task<BatchProcessingResult> ProcessFilesAsync(
        IEnumerable<FileProcessingContext> contexts,
        int parallelism,
        IProgress<BatchProgress>? progress = null,
        CancellationToken ct = default)
    {
        ArgumentNullException.ThrowIfNull(contexts);
        if (parallelism < 1)
            throw new ArgumentOutOfRangeException(nameof(parallelism), "Must be at least 1");

        var contextList = contexts.ToList();
        var results = new List<FileProcessingResult>();
        var processed = 0;
        var total = contextList.Count;

        using var semaphore = new SemaphoreSlim(parallelism);
        var tasks = new List<Task<FileProcessingResult>>();

        foreach (var context in contextList)
        {
            ct.ThrowIfCancellationRequested();

            await semaphore.WaitAsync(ct);

            var task = Task.Run(async () =>
            {
                try
                {
                    var result = await ProcessFileAsync(context, ct);
                    var current = Interlocked.Increment(ref processed);

                    progress?.Report(new BatchProgress
                    {
                        Processed = current,
                        Total = total,
                        CurrentFile = context.RelativePath,
                        PercentComplete = (double)current / total * 100
                    });

                    return result;
                }
                finally
                {
                    semaphore.Release();
                }
            }, ct);

            tasks.Add(task);
        }

        var taskResults = await Task.WhenAll(tasks);
        results.AddRange(taskResults);

        var succeeded = results.Count(r => r.Status == FileProcessingStatus.Success);
        var failed = results.Count(r => r.Status == FileProcessingStatus.Failed);
        var skipped = results.Count(r => r.Status == FileProcessingStatus.Skipped);

        return new BatchProcessingResult
        {
            Results = results,
            TotalFiles = total,
            SuccessCount = succeeded,
            FailedCount = failed,
            SkippedCount = skipped,
            TotalChunks = results.Sum(r => r.ChunkCount),
            TotalBytes = results.Sum(r => r.FileSize),
            TotalDurationMs = results.Sum(r => r.DurationMs)
        };
    }

    private async Task StoreEmptyFileRecord(
        FileProcessingContext context,
        FileContent fileContent,
        string fileHash,
        FileProcessingResult result,
        CancellationToken ct)
    {
        var indexedFile = new IndexedFile
        {
            IndexId = context.IndexId,
            FilePath = context.RelativePath,
            FileHash = fileHash,
            FileSize = result.FileSize,
            LastModified = new FileInfo(context.AbsolutePath).LastWriteTimeUtc,
            ChunkCount = 0,
            Language = _chunkingService.DetectLanguage(context.RelativePath),
            Encoding = fileContent.Encoding,
            LineCount = fileContent.LineCount,
            Status = FileIndexStatus.Indexed
        };

        await _vectorStore.UpsertIndexedFileAsync(context.IndexId, indexedFile, ct);
    }
}
```

### 2. FileContentReader.cs

**Location**: `src/SeniorIntern.Services/Indexing/FileContentReader.cs`

```csharp
using System;
using System.IO;
using System.Text;
using System.Threading;
using System.Threading.Tasks;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Reads file contents with automatic encoding detection.
/// </summary>
/// <remarks>
/// <para>
/// Supports encoding detection via:
/// <list type="bullet">
///   <item>Byte Order Mark (BOM) detection for UTF-8, UTF-16, UTF-32</item>
///   <item>Heuristic detection for BOM-less files</item>
///   <item>Fallback to UTF-8 with replacement characters</item>
/// </list>
/// </para>
/// </remarks>
public static class FileContentReader
{
    /// <summary>
    /// Read entire file content with encoding detection.
    /// </summary>
    /// <param name="filePath">Absolute path to the file.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>File content with detected encoding and line count.</returns>
    /// <exception cref="FileNotFoundException">If file does not exist.</exception>
    /// <exception cref="IOException">If file cannot be read.</exception>
    public static async Task<FileContent> ReadAsync(string filePath, CancellationToken ct = default)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(filePath);

        if (!File.Exists(filePath))
            throw new FileNotFoundException("File not found", filePath);

        // Read the raw bytes first
        var bytes = await File.ReadAllBytesAsync(filePath, ct);

        // Detect encoding
        var encoding = DetectEncoding(bytes);
        var encodingName = GetEncodingName(encoding);

        // Decode content
        string content;
        try
        {
            content = encoding.GetString(bytes);

            // Remove BOM if present
            if (content.Length > 0 && content[0] == '\uFEFF')
            {
                content = content[1..];
            }
        }
        catch (DecoderFallbackException)
        {
            // Fallback to UTF-8 with replacement
            content = Encoding.UTF8.GetString(bytes);
            encodingName = "UTF-8 (fallback)";
        }

        // Count lines
        var lineCount = CountLines(content);

        return new FileContent
        {
            Content = content,
            Encoding = encodingName,
            LineCount = lineCount
        };
    }

    /// <summary>
    /// Read specific lines from a file.
    /// </summary>
    /// <param name="filePath">Absolute path to the file.</param>
    /// <param name="startLine">Starting line number (1-based, inclusive).</param>
    /// <param name="endLine">Ending line number (1-based, inclusive).</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Array of lines in the specified range.</returns>
    public static async Task<string[]> ReadLinesAsync(
        string filePath,
        int startLine,
        int endLine,
        CancellationToken ct = default)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(filePath);
        if (startLine < 1) throw new ArgumentOutOfRangeException(nameof(startLine));
        if (endLine < startLine) throw new ArgumentOutOfRangeException(nameof(endLine));

        var content = await ReadAsync(filePath, ct);
        var allLines = content.Content.Split('\n');

        var actualStart = Math.Max(0, startLine - 1);
        var actualEnd = Math.Min(allLines.Length, endLine);
        var count = actualEnd - actualStart;

        if (count <= 0)
            return Array.Empty<string>();

        var result = new string[count];
        Array.Copy(allLines, actualStart, result, 0, count);
        return result;
    }

    /// <summary>
    /// Detect encoding from byte content.
    /// </summary>
    private static Encoding DetectEncoding(byte[] bytes)
    {
        if (bytes.Length == 0)
            return Encoding.UTF8;

        // Check for BOM
        if (bytes.Length >= 3 && bytes[0] == 0xEF && bytes[1] == 0xBB && bytes[2] == 0xBF)
            return Encoding.UTF8;

        if (bytes.Length >= 2)
        {
            // UTF-16 LE
            if (bytes[0] == 0xFF && bytes[1] == 0xFE)
            {
                // Could be UTF-32 LE if we have 4 bytes and the next 2 are 0x00
                if (bytes.Length >= 4 && bytes[2] == 0x00 && bytes[3] == 0x00)
                    return Encoding.UTF32;
                return Encoding.Unicode;
            }

            // UTF-16 BE
            if (bytes[0] == 0xFE && bytes[1] == 0xFF)
                return Encoding.BigEndianUnicode;
        }

        // UTF-32 BE
        if (bytes.Length >= 4 && bytes[0] == 0x00 && bytes[1] == 0x00 &&
            bytes[2] == 0xFE && bytes[3] == 0xFF)
            return new UTF32Encoding(true, true);

        // Heuristic detection for non-BOM files
        return DetectEncodingHeuristic(bytes);
    }

    /// <summary>
    /// Heuristic encoding detection for files without BOM.
    /// </summary>
    private static Encoding DetectEncodingHeuristic(byte[] bytes)
    {
        // Check for null bytes (likely binary or UTF-16)
        var nullCount = 0;
        var highByteCount = 0;

        var checkLength = Math.Min(bytes.Length, 1024);
        for (int i = 0; i < checkLength; i++)
        {
            if (bytes[i] == 0x00) nullCount++;
            if (bytes[i] > 0x7F) highByteCount++;
        }

        // Many nulls suggest binary or UTF-16
        if (nullCount > checkLength / 10)
        {
            // Check for UTF-16 pattern (alternating nulls)
            var evenNulls = 0;
            var oddNulls = 0;
            for (int i = 0; i < checkLength; i++)
            {
                if (bytes[i] == 0x00)
                {
                    if (i % 2 == 0) evenNulls++;
                    else oddNulls++;
                }
            }

            if (evenNulls > checkLength / 4) return Encoding.Unicode;
            if (oddNulls > checkLength / 4) return Encoding.BigEndianUnicode;
        }

        // Try UTF-8 validation
        if (IsValidUtf8(bytes))
            return Encoding.UTF8;

        // Fallback to Windows-1252 for legacy ASCII-extended files
        try
        {
            return Encoding.GetEncoding(1252);
        }
        catch
        {
            return Encoding.UTF8;
        }
    }

    /// <summary>
    /// Check if bytes form valid UTF-8.
    /// </summary>
    private static bool IsValidUtf8(byte[] bytes)
    {
        int i = 0;
        while (i < bytes.Length)
        {
            var b = bytes[i];

            int expectedContinuationBytes;
            if ((b & 0x80) == 0x00) // ASCII
            {
                i++;
                continue;
            }
            else if ((b & 0xE0) == 0xC0) // 2-byte sequence
            {
                expectedContinuationBytes = 1;
            }
            else if ((b & 0xF0) == 0xE0) // 3-byte sequence
            {
                expectedContinuationBytes = 2;
            }
            else if ((b & 0xF8) == 0xF0) // 4-byte sequence
            {
                expectedContinuationBytes = 3;
            }
            else
            {
                return false; // Invalid UTF-8 start byte
            }

            // Check continuation bytes
            for (int j = 0; j < expectedContinuationBytes; j++)
            {
                i++;
                if (i >= bytes.Length || (bytes[i] & 0xC0) != 0x80)
                    return false;
            }
            i++;
        }
        return true;
    }

    /// <summary>
    /// Get human-readable encoding name.
    /// </summary>
    private static string GetEncodingName(Encoding encoding)
    {
        return encoding.WebName.ToUpperInvariant() switch
        {
            "UTF-8" => "UTF-8",
            "UTF-16" => "UTF-16 LE",
            "UTF-16BE" => "UTF-16 BE",
            "UTF-32" => "UTF-32",
            "WINDOWS-1252" => "Windows-1252",
            _ => encoding.WebName
        };
    }

    /// <summary>
    /// Count lines in content.
    /// </summary>
    private static int CountLines(string content)
    {
        if (string.IsNullOrEmpty(content))
            return 0;

        var count = 1;
        for (int i = 0; i < content.Length; i++)
        {
            if (content[i] == '\n')
                count++;
        }
        return count;
    }
}

/// <summary>
/// Result of reading a file.
/// </summary>
public sealed class FileContent
{
    /// <summary>
    /// File content as a string.
    /// </summary>
    public required string Content { get; init; }

    /// <summary>
    /// Detected encoding name.
    /// </summary>
    public required string Encoding { get; init; }

    /// <summary>
    /// Number of lines in the file.
    /// </summary>
    public int LineCount { get; init; }
}
```

### 3. FileHasher.cs

**Location**: `src/SeniorIntern.Services/Indexing/FileHasher.cs`

```csharp
using System;
using System.IO;
using System.Security.Cryptography;
using System.Text;
using System.Threading;
using System.Threading.Tasks;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Computes file content hashes for change detection.
/// </summary>
/// <remarks>
/// Uses SHA256 for reliable content-based change detection.
/// Hashes are returned as lowercase hexadecimal strings.
/// </remarks>
public static class FileHasher
{
    /// <summary>
    /// Compute SHA256 hash of string content.
    /// </summary>
    /// <param name="content">String content to hash.</param>
    /// <returns>Lowercase hex string of SHA256 hash.</returns>
    public static string ComputeHash(string content)
    {
        if (string.IsNullOrEmpty(content))
            return ComputeEmptyHash();

        var bytes = Encoding.UTF8.GetBytes(content);
        var hashBytes = SHA256.HashData(bytes);
        return Convert.ToHexString(hashBytes).ToLowerInvariant();
    }

    /// <summary>
    /// Compute SHA256 hash of a stream asynchronously.
    /// </summary>
    /// <param name="stream">Stream to hash.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Lowercase hex string of SHA256 hash.</returns>
    public static async Task<string> ComputeHashAsync(Stream stream, CancellationToken ct = default)
    {
        ArgumentNullException.ThrowIfNull(stream);

        var hashBytes = await SHA256.HashDataAsync(stream, ct);
        return Convert.ToHexString(hashBytes).ToLowerInvariant();
    }

    /// <summary>
    /// Compute SHA256 hash of a file.
    /// </summary>
    /// <param name="filePath">Path to the file.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>Lowercase hex string of SHA256 hash.</returns>
    /// <exception cref="FileNotFoundException">If file does not exist.</exception>
    public static async Task<string> ComputeHashFromFileAsync(
        string filePath,
        CancellationToken ct = default)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(filePath);

        if (!File.Exists(filePath))
            throw new FileNotFoundException("File not found", filePath);

        await using var stream = File.OpenRead(filePath);
        return await ComputeHashAsync(stream, ct);
    }

    /// <summary>
    /// Compute hash of empty content (cached).
    /// </summary>
    private static string ComputeEmptyHash()
    {
        // SHA256 of empty string - cached for efficiency
        return "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855";
    }
}
```

### 4. EmbeddingBatcher.cs

**Location**: `src/SeniorIntern.Services/Indexing/EmbeddingBatcher.cs`

```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Batches embedding requests for efficient processing.
/// </summary>
/// <remarks>
/// <para>
/// Embedding models are most efficient when processing multiple texts at once.
/// EmbeddingBatcher groups chunks into optimal batch sizes to maximize throughput
/// while staying within memory limits.
/// </para>
/// <para>
/// Typical batch sizes:
/// <list type="bullet">
///   <item>GPU with 8GB VRAM: 32-64 chunks</item>
///   <item>GPU with 16GB VRAM: 64-128 chunks</item>
///   <item>CPU-only: 8-16 chunks</item>
/// </list>
/// </para>
/// </remarks>
public sealed class EmbeddingBatcher
{
    private readonly IEmbeddingService _embeddingService;
    private readonly int _batchSize;

    /// <summary>
    /// Initializes a new instance of the <see cref="EmbeddingBatcher"/> class.
    /// </summary>
    /// <param name="embeddingService">Embedding service to use.</param>
    /// <param name="batchSize">Maximum chunks per batch.</param>
    public EmbeddingBatcher(IEmbeddingService embeddingService, int batchSize = 32)
    {
        _embeddingService = embeddingService ?? throw new ArgumentNullException(nameof(embeddingService));
        if (batchSize < 1) throw new ArgumentOutOfRangeException(nameof(batchSize), "Must be at least 1");
        _batchSize = batchSize;
    }

    /// <summary>
    /// Embed chunks in optimized batches.
    /// </summary>
    /// <param name="chunks">Chunks with their file IDs.</param>
    /// <param name="progress">Optional progress reporter.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of chunks paired with their embeddings.</returns>
    public async Task<IReadOnlyList<ChunkWithEmbedding>> EmbedChunksAsync(
        IEnumerable<(TextChunk Chunk, string FileId)> chunks,
        IProgress<EmbeddingBatchProgress>? progress = null,
        CancellationToken ct = default)
    {
        ArgumentNullException.ThrowIfNull(chunks);

        var chunkList = chunks.ToList();
        var results = new List<ChunkWithEmbedding>(chunkList.Count);
        var processedCount = 0;

        // Process in batches using LINQ Chunk
        foreach (var batch in chunkList.Chunk(_batchSize))
        {
            ct.ThrowIfCancellationRequested();

            var batchChunks = batch.ToList();
            var texts = batchChunks.Select(c => c.Chunk.Content).ToList();

            // Get embeddings for batch
            var embeddings = await _embeddingService.EmbedBatchAsync(texts, null, ct);

            // Pair chunks with embeddings
            for (int i = 0; i < batchChunks.Count; i++)
            {
                results.Add(new ChunkWithEmbedding
                {
                    Chunk = batchChunks[i].Chunk,
                    Embedding = embeddings[i],
                    FileId = batchChunks[i].FileId
                });
            }

            processedCount += batchChunks.Count;

            progress?.Report(new EmbeddingBatchProgress
            {
                ProcessedChunks = processedCount,
                TotalChunks = chunkList.Count,
                PercentComplete = (double)processedCount / chunkList.Count * 100
            });
        }

        return results;
    }

    /// <summary>
    /// Embed text content in optimized batches.
    /// </summary>
    /// <param name="texts">Text strings to embed.</param>
    /// <param name="progress">Optional progress reporter.</param>
    /// <param name="ct">Cancellation token.</param>
    /// <returns>List of embedding vectors.</returns>
    public async Task<IReadOnlyList<float[]>> EmbedTextsAsync(
        IEnumerable<string> texts,
        IProgress<EmbeddingBatchProgress>? progress = null,
        CancellationToken ct = default)
    {
        ArgumentNullException.ThrowIfNull(texts);

        var textList = texts.ToList();
        var results = new List<float[]>(textList.Count);
        var processedCount = 0;

        foreach (var batch in textList.Chunk(_batchSize))
        {
            ct.ThrowIfCancellationRequested();

            var batchTexts = batch.ToList();
            var embeddings = await _embeddingService.EmbedBatchAsync(batchTexts, null, ct);

            results.AddRange(embeddings);
            processedCount += batchTexts.Count;

            progress?.Report(new EmbeddingBatchProgress
            {
                ProcessedChunks = processedCount,
                TotalChunks = textList.Count,
                PercentComplete = (double)processedCount / textList.Count * 100
            });
        }

        return results;
    }
}

/// <summary>
/// Progress for embedding batch operations.
/// </summary>
public sealed class EmbeddingBatchProgress
{
    /// <summary>Number of chunks processed so far.</summary>
    public int ProcessedChunks { get; init; }

    /// <summary>Total chunks to process.</summary>
    public int TotalChunks { get; init; }

    /// <summary>Completion percentage (0-100).</summary>
    public double PercentComplete { get; init; }
}
```

### 5. FileProcessingModels.cs

**Location**: `src/SeniorIntern.Services/Indexing/FileProcessingModels.cs`

```csharp
using System;
using System.Collections.Generic;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Context for processing a single file.
/// </summary>
/// <remarks>
/// Contains all information needed to process a file through the pipeline.
/// Created by <see cref="IndexingService"/> and passed to <see cref="FileProcessor"/>.
/// </remarks>
public sealed class FileProcessingContext
{
    /// <summary>
    /// ID of the target index.
    /// </summary>
    public required string IndexId { get; init; }

    /// <summary>
    /// Absolute path to the file on disk.
    /// </summary>
    public required string AbsolutePath { get; init; }

    /// <summary>
    /// Path relative to the workspace root.
    /// </summary>
    /// <remarks>
    /// This is the path stored in the database and used for retrieval.
    /// </remarks>
    public required string RelativePath { get; init; }

    /// <summary>
    /// Indexing options for this file.
    /// </summary>
    public required IndexingOptions Options { get; init; }
}

/// <summary>
/// Result of processing a single file.
/// </summary>
public sealed class FileProcessingResult
{
    /// <summary>
    /// Relative path of the processed file.
    /// </summary>
    public required string FilePath { get; init; }

    /// <summary>
    /// Processing status.
    /// </summary>
    public FileProcessingStatus Status { get; set; }

    /// <summary>
    /// Number of chunks created from this file.
    /// </summary>
    public int ChunkCount { get; set; }

    /// <summary>
    /// File size in bytes.
    /// </summary>
    public long FileSize { get; set; }

    /// <summary>
    /// Number of lines in the file.
    /// </summary>
    public int LineCount { get; set; }

    /// <summary>
    /// Detected programming language.
    /// </summary>
    public string? Language { get; set; }

    /// <summary>
    /// Detected file encoding.
    /// </summary>
    public string? Encoding { get; set; }

    /// <summary>
    /// Total processing duration in milliseconds.
    /// </summary>
    public int DurationMs { get; set; }

    /// <summary>
    /// Embedding generation duration in milliseconds.
    /// </summary>
    public int EmbeddingDurationMs { get; set; }

    /// <summary>
    /// When processing started.
    /// </summary>
    public DateTime StartedAt { get; init; }

    /// <summary>
    /// Error details if processing failed.
    /// </summary>
    public IndexingError? Error { get; set; }

    /// <summary>
    /// Reason for skipping (if status is Skipped).
    /// </summary>
    public string? SkipReason { get; set; }

    /// <summary>
    /// Whether processing was successful.
    /// </summary>
    public bool IsSuccess => Status == FileProcessingStatus.Success;
}

/// <summary>
/// Status of file processing.
/// </summary>
public enum FileProcessingStatus
{
    /// <summary>File processed successfully.</summary>
    Success,

    /// <summary>File processing failed.</summary>
    Failed,

    /// <summary>File was skipped (empty, no chunks, etc.).</summary>
    Skipped
}

/// <summary>
/// Result of batch file processing.
/// </summary>
public sealed class BatchProcessingResult
{
    /// <summary>
    /// Individual file processing results.
    /// </summary>
    public IReadOnlyList<FileProcessingResult> Results { get; init; } = [];

    /// <summary>
    /// Total files in the batch.
    /// </summary>
    public int TotalFiles { get; init; }

    /// <summary>
    /// Count of successfully processed files.
    /// </summary>
    public int SuccessCount { get; init; }

    /// <summary>
    /// Count of failed files.
    /// </summary>
    public int FailedCount { get; init; }

    /// <summary>
    /// Count of skipped files.
    /// </summary>
    public int SkippedCount { get; init; }

    /// <summary>
    /// Total chunks created across all files.
    /// </summary>
    public int TotalChunks { get; init; }

    /// <summary>
    /// Total bytes processed.
    /// </summary>
    public long TotalBytes { get; init; }

    /// <summary>
    /// Total processing time in milliseconds.
    /// </summary>
    public int TotalDurationMs { get; init; }

    /// <summary>
    /// Average duration per file in milliseconds.
    /// </summary>
    public double AverageDurationMs => TotalFiles > 0
        ? (double)TotalDurationMs / TotalFiles
        : 0;

    /// <summary>
    /// Files processed per second.
    /// </summary>
    public double FilesPerSecond => TotalDurationMs > 0
        ? (double)TotalFiles / TotalDurationMs * 1000
        : 0;
}

/// <summary>
/// Progress for batch processing operations.
/// </summary>
public sealed class BatchProgress
{
    /// <summary>Number of files processed so far.</summary>
    public int Processed { get; init; }

    /// <summary>Total files to process.</summary>
    public int Total { get; init; }

    /// <summary>Current file being processed.</summary>
    public string? CurrentFile { get; init; }

    /// <summary>Completion percentage (0-100).</summary>
    public double PercentComplete { get; init; }
}
```

---

## Unit Testing Requirements

| Class | Test Count | Focus Areas |
|-------|------------|-------------|
| `FileProcessor` | 20-25 | Pipeline steps, error handling, batch processing |
| `FileContentReader` | 15-20 | Encoding detection, BOM handling, line counting |
| `FileHasher` | 8-10 | Hash consistency, empty content, file hashing |
| `EmbeddingBatcher` | 10-12 | Batch splitting, progress reporting |
| Processing Models | 8-10 | Properties, computed values |

**Total: ~61-77 tests**

---

## Acceptance Criteria

### Functional Requirements
- [ ] `FileProcessor` processes files through all 6 pipeline steps
- [ ] `FileContentReader` correctly detects UTF-8, UTF-16, UTF-32 encodings
- [ ] `FileContentReader` handles BOM and BOM-less files
- [ ] `FileHasher` produces consistent SHA256 hashes
- [ ] `EmbeddingBatcher` correctly batches requests
- [ ] Parallel processing respects parallelism limits
- [ ] Progress is reported during batch operations
- [ ] Empty files are tracked without creating chunks

### Quality Requirements
- [ ] All classes handle null arguments appropriately
- [ ] Cancellation tokens are propagated throughout
- [ ] Resources are properly disposed
- [ ] All public members have XML documentation

---

## Future Considerations

Items explicitly deferred to later sub-versions:
- **v0.7.3e**: GitignoreParser implementation
- **v0.7.3f**: FileScanner for advanced file enumeration
- **v0.7.3g**: IndexingJobQueue implementation
- **v0.7.3h**: FileWatcherService implementation
