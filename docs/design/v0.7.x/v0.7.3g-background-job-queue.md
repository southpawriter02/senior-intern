# Design Specification: AIntern v0.7.3g "Background Job Queue"

## Overview

**Version**: v0.7.3g
**Parent**: v0.7.3 Indexing Pipeline
**Focus**: Background job queue for asynchronous indexing operations with priority management

### Purpose

This sub-version implements the background job queue system:
1. `IndexingJobQueue` - Priority queue for indexing jobs using System.Threading.Channels
2. `IndexingJobProcessor` - Background service that processes jobs from the queue
3. Job lifecycle management (enqueue, dequeue, complete, fail, retry)
4. Event notifications for queue state changes

### Dependencies

**From v0.7.3a (Indexing Service Interface)**:
- `IIndexingJobQueue` interface
- `IndexingJob` model
- `IndexingJobStatus` enum
- `IndexingJobType` enum

**From v0.7.3b (Indexing Models & Options)**:
- `IndexingProgress` model
- `IndexingResult` model

**From v0.7.3c (Indexing Service Implementation)**:
- `IIndexingService` for executing jobs
- Event args classes

---

## Architecture

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                     v0.7.3g Background Job Queue                              │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  src/SeniorIntern.Services/Indexing/                                         │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │                                                                          ││
│  │  IndexingJobQueue : IIndexingJobQueue                                    ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  State                                                             │  ││
│  │  │  ├── _channel: Channel<IndexingJob>                                │  ││
│  │  │  ├── _jobs: ConcurrentDictionary<string, IndexingJob>             │  ││
│  │  │  ├── IsProcessing: bool                                            │  ││
│  │  │  └── QueueLength: int                                              │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  IIndexingJobQueue Implementation                                  │  ││
│  │  │  ├── Enqueue(job)                 [Add job to queue]              │  ││
│  │  │  ├── TryDequeue(out job) → bool   [Non-blocking dequeue]          │  ││
│  │  │  ├── DequeueAsync(ct) → Job       [Blocking async dequeue]        │  ││
│  │  │  ├── GetQueuedJobs() → List       [Get sorted queue]              │  ││
│  │  │  ├── Remove(jobId) → bool         [Cancel queued job]             │  ││
│  │  │  ├── Clear()                      [Cancel all jobs]               │  ││
│  │  │  └── Prioritize(jobId) → bool     [Boost job priority]            │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Additional Methods                                                │  ││
│  │  │  ├── MarkComplete(jobId)          [Mark job as completed]         │  ││
│  │  │  └── MarkFailed(jobId, error)     [Mark job as failed]            │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Events                                                            │  ││
│  │  │  ├── JobEnqueued: EventHandler<IndexingJobEventArgs>              │  ││
│  │  │  └── JobDequeued: EventHandler<IndexingJobEventArgs>              │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │                                                                          ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  IndexingJobProcessor : BackgroundService                                ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Dependencies                                                      │  ││
│  │  │  ├── IIndexingService _indexingService                            │  ││
│  │  │  ├── IndexingJobQueue _jobQueue                                    │  ││
│  │  │  └── ILogger<IndexingJobProcessor> _logger                        │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  BackgroundService Implementation                                  │  ││
│  │  │  └── ExecuteAsync(stoppingToken)  [Main processing loop]          │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  │  ┌────────────────────────────────────────────────────────────────────┐  ││
│  │  │  Job Processing                                                    │  ││
│  │  │  ├── ProcessJobAsync(job, ct)     [Execute single job]            │  ││
│  │  │  ├── Handle FullIndex             [Call IndexWorkspaceAsync]      │  ││
│  │  │  ├── Handle IncrementalUpdate     [Call UpdateIndexAsync]         │  ││
│  │  │  ├── Handle Sync                  [Call SyncIndexAsync]           │  ││
│  │  │  └── Handle retry on failure                                       │  ││
│  │  └────────────────────────────────────────────────────────────────────┘  ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
│  Supporting Event Args                                                       │
│  ┌──────────────────────────────────────────────────────────────────────────┐│
│  │  IndexingJobEventArgs           → Job reference                         ││
│  │  IndexingJobCompletedEventArgs  → Job + Result                          ││
│  │  IndexingStateChangedEventArgs  → OldStatus + NewStatus                 ││
│  │  FileIndexedEventArgs           → FilePath + ChunkCount + Success       ││
│  │  FileIndexingErrorEventArgs     → FilePath + Error                      ││
│  │  IndexingProgressEventArgs      → Progress                              ││
│  └──────────────────────────────────────────────────────────────────────────┘│
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Job Lifecycle Flow

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                         Job Lifecycle State Machine                           │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│                         ┌───────────────────────┐                            │
│                         │       Created         │                            │
│                         │ (IndexingJob ctor)    │                            │
│                         └───────────┬───────────┘                            │
│                                     │                                        │
│                                     │ Enqueue()                              │
│                                     ▼                                        │
│                         ┌───────────────────────┐                            │
│                         │       Queued          │ ◄──────┐                   │
│                         │ (Status = Queued)     │        │ Retry             │
│                         └───────────┬───────────┘        │ (job.CanRetry)    │
│                                     │                    │                   │
│                                     │ DequeueAsync()     │                   │
│                                     ▼                    │                   │
│                         ┌───────────────────────┐        │                   │
│                         │       Running         │        │                   │
│                         │ (Status = Running)    │────────┘                   │
│                         └───────────┬───────────┘                            │
│                                     │                                        │
│                    ┌────────────────┼────────────────┐                       │
│                    │                │                │                       │
│                    ▼                ▼                ▼                       │
│         ┌──────────────────┐ ┌────────────┐ ┌───────────────┐               │
│         │    Completed     │ │  Failed    │ │  Cancelled    │               │
│         │ (MarkComplete)   │ │(MarkFailed)│ │ (Remove())    │               │
│         └──────────────────┘ └────────────┘ └───────────────┘               │
│                                                                              │
│  Notes:                                                                      │
│  • Queued jobs sorted by Priority (desc), then CreatedAt (asc)              │
│  • Prioritize() boosts a job to max priority                                 │
│  • Failed jobs may retry if job.CanRetry is true                            │
│  • Remove() cancels a queued job (cannot cancel running)                    │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Job Processing Flow

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                    IndexingJobProcessor.ExecuteAsync()                        │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  while (!stoppingToken.IsCancellationRequested)                              │
│  {                                                                           │
│      ┌─────────────────────────────────────────────────────────────────────┐ │
│      │  1. DEQUEUE JOB (Blocking)                                          │ │
│      │  ┌───────────────────────────────────────────────────────────────┐  │ │
│      │  │  var job = await _jobQueue.DequeueAsync(stoppingToken);      │  │ │
│      │  │  • Blocks until job available or cancellation                │  │ │
│      │  │  • Sets job.Status = Running                                  │  │ │
│      │  │  • Sets job.StartedAt = DateTime.UtcNow                      │  │ │
│      │  │  • Sets IsProcessing = true                                   │  │ │
│      │  │  • Raises JobDequeued event                                   │  │ │
│      │  └───────────────────────────────────────────────────────────────┘  │ │
│      └─────────────────────────────────────────────────────────────────────┘ │
│                                      │                                       │
│                                      ▼                                       │
│      ┌─────────────────────────────────────────────────────────────────────┐ │
│      │  2. PROCESS JOB                                                     │ │
│      │  ┌───────────────────────────────────────────────────────────────┐  │ │
│      │  │  switch (job.Type)                                            │  │ │
│      │  │  {                                                             │  │ │
│      │  │    case FullIndex:                                             │  │ │
│      │  │      result = await _indexingService.IndexWorkspaceAsync(...);│  │ │
│      │  │                                                                │  │ │
│      │  │    case IncrementalUpdate:                                     │  │ │
│      │  │      result = await _indexingService.UpdateIndexAsync(...);   │  │ │
│      │  │                                                                │  │ │
│      │  │    case Sync:                                                  │  │ │
│      │  │      syncResult = await _indexingService.SyncIndexAsync(...); │  │ │
│      │  │      result = Convert(syncResult);                             │  │ │
│      │  │  }                                                             │  │ │
│      │  │                                                                │  │ │
│      │  │  job.Result = result;                                         │  │ │
│      │  └───────────────────────────────────────────────────────────────┘  │ │
│      └─────────────────────────────────────────────────────────────────────┘ │
│                                      │                                       │
│                      ┌───────────────┴───────────────┐                       │
│                      ▼                               ▼                       │
│      ┌────────────────────────────┐  ┌────────────────────────────────────┐ │
│      │  3a. SUCCESS               │  │  3b. FAILURE                       │ │
│      │  ┌──────────────────────┐  │  │  ┌──────────────────────────────┐  │ │
│      │  │  if (result.Success) │  │  │  │  else                        │  │ │
│      │  │  {                   │  │  │  │  {                           │  │ │
│      │  │    MarkComplete()    │  │  │  │    MarkFailed(error)         │  │ │
│      │  │    Log success       │  │  │  │    if (job.CanRetry)         │  │ │
│      │  │  }                   │  │  │  │    {                         │  │ │
│      │  └──────────────────────┘  │  │  │      job.RetryCount++        │  │ │
│      └────────────────────────────┘  │  │      Enqueue(job) // retry   │  │ │
│                                      │  │    }                         │  │ │
│                                      │  │  }                           │  │ │
│                                      │  └──────────────────────────────┘  │ │
│                                      └────────────────────────────────────┘ │
│  }                                                                           │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

---

## Files to Create

| File | Purpose |
|------|---------|
| `src/SeniorIntern.Services/Indexing/IndexingJobQueue.cs` | Priority queue implementation |
| `src/SeniorIntern.Services/Indexing/IndexingJobProcessor.cs` | Background processing service |
| `src/SeniorIntern.Services/Indexing/IndexingEventArgs.cs` | Event argument classes |

---

## Detailed Specifications

### 1. IndexingJobQueue.cs

**Location**: `src/SeniorIntern.Services/Indexing/IndexingJobQueue.cs`

```csharp
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Channels;
using System.Threading.Tasks;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Priority queue for indexing jobs.
/// </summary>
/// <remarks>
/// <para>
/// Uses <see cref="System.Threading.Channels.Channel{T}"/> for efficient
/// producer-consumer pattern with async support. Jobs are tracked in a
/// <see cref="ConcurrentDictionary{TKey,TValue}"/> for status lookup.
/// </para>
/// <para>
/// Priority ordering:
/// <list type="number">
///   <item>Higher priority jobs are processed first</item>
///   <item>Within same priority, older jobs processed first (FIFO)</item>
/// </list>
/// </para>
/// <para>
/// Thread-safe for concurrent enqueue operations.
/// </para>
/// </remarks>
public sealed class IndexingJobQueue : IIndexingJobQueue
{
    private readonly Channel<IndexingJob> _channel;
    private readonly ConcurrentDictionary<string, IndexingJob> _jobs = new();
    private readonly object _lock = new();

    /// <inheritdoc />
    public int QueueLength => _jobs.Count(j => j.Value.Status == IndexingJobStatus.Queued);

    /// <inheritdoc />
    public bool IsProcessing { get; private set; }

    /// <inheritdoc />
    public event EventHandler<IndexingJobEventArgs>? JobEnqueued;

    /// <inheritdoc />
    public event EventHandler<IndexingJobEventArgs>? JobDequeued;

    /// <summary>
    /// Raised when a job completes successfully.
    /// </summary>
    public event EventHandler<IndexingJobCompletedEventArgs>? JobCompleted;

    /// <summary>
    /// Raised when a job fails.
    /// </summary>
    public event EventHandler<IndexingJobEventArgs>? JobFailed;

    /// <summary>
    /// Initializes a new instance of the <see cref="IndexingJobQueue"/> class.
    /// </summary>
    public IndexingJobQueue()
    {
        _channel = Channel.CreateUnbounded<IndexingJob>(new UnboundedChannelOptions
        {
            SingleReader = true,  // Only one processor
            SingleWriter = false  // Multiple enqueue sources
        });
    }

    /// <inheritdoc />
    public void Enqueue(IndexingJob job)
    {
        ArgumentNullException.ThrowIfNull(job);

        if (_jobs.TryAdd(job.Id, job))
        {
            job.Status = IndexingJobStatus.Queued;
            _channel.Writer.TryWrite(job);
            JobEnqueued?.Invoke(this, new IndexingJobEventArgs { Job = job });
        }
    }

    /// <inheritdoc />
    public bool TryDequeue(out IndexingJob? job)
    {
        if (_channel.Reader.TryRead(out job))
        {
            if (job != null)
            {
                job.Status = IndexingJobStatus.Running;
                job.StartedAt = DateTime.UtcNow;
                IsProcessing = true;
                JobDequeued?.Invoke(this, new IndexingJobEventArgs { Job = job });
            }
            return true;
        }
        return false;
    }

    /// <inheritdoc />
    public async Task<IndexingJob> DequeueAsync(CancellationToken ct = default)
    {
        var job = await _channel.Reader.ReadAsync(ct);
        job.Status = IndexingJobStatus.Running;
        job.StartedAt = DateTime.UtcNow;
        IsProcessing = true;
        JobDequeued?.Invoke(this, new IndexingJobEventArgs { Job = job });
        return job;
    }

    /// <inheritdoc />
    public IReadOnlyList<IndexingJob> GetQueuedJobs()
    {
        return _jobs.Values
            .Where(j => j.Status == IndexingJobStatus.Queued)
            .OrderByDescending(j => j.Priority)
            .ThenBy(j => j.CreatedAt)
            .ToList();
    }

    /// <inheritdoc />
    public bool Remove(string jobId)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(jobId);

        if (_jobs.TryRemove(jobId, out var job))
        {
            job.Status = IndexingJobStatus.Cancelled;
            job.CompletedAt = DateTime.UtcNow;
            return true;
        }
        return false;
    }

    /// <inheritdoc />
    public void Clear()
    {
        lock (_lock)
        {
            foreach (var job in _jobs.Values.Where(j => j.Status == IndexingJobStatus.Queued))
            {
                job.Status = IndexingJobStatus.Cancelled;
                job.CompletedAt = DateTime.UtcNow;
            }
            _jobs.Clear();

            // Drain the channel
            while (_channel.Reader.TryRead(out _)) { }
        }
    }

    /// <inheritdoc />
    public bool Prioritize(string jobId)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(jobId);

        if (_jobs.TryGetValue(jobId, out var job) && job.Status == IndexingJobStatus.Queued)
        {
            // Note: Cannot truly re-order in a channel, but we can update the priority
            // for sorting purposes when listing jobs. The job will process in original
            // order unless re-queued.
            // 
            // For true priority, we would need a priority queue implementation.
            // This is a reasonable compromise - the job gets max priority for display
            // and will be first in sorted listings.
            var updatedJob = job with { Priority = int.MaxValue };
            _jobs.TryUpdate(jobId, updatedJob, job);
            return true;
        }
        return false;
    }

    /// <summary>
    /// Mark a job as completed successfully.
    /// </summary>
    /// <param name="jobId">ID of the completed job.</param>
    public void MarkComplete(string jobId)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(jobId);

        if (_jobs.TryGetValue(jobId, out var job))
        {
            job.Status = IndexingJobStatus.Completed;
            job.CompletedAt = DateTime.UtcNow;

            JobCompleted?.Invoke(this, new IndexingJobCompletedEventArgs
            {
                Job = job,
                Result = job.Result ?? IndexingResult.Failed("No result available")
            });
        }
        IsProcessing = false;
    }

    /// <summary>
    /// Mark a job as failed.
    /// </summary>
    /// <param name="jobId">ID of the failed job.</param>
    /// <param name="error">Error message.</param>
    public void MarkFailed(string jobId, string error)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(jobId);

        if (_jobs.TryGetValue(jobId, out var job))
        {
            job.Status = IndexingJobStatus.Failed;
            job.CompletedAt = DateTime.UtcNow;
            job.ErrorMessage = error;

            JobFailed?.Invoke(this, new IndexingJobEventArgs { Job = job });
        }
        IsProcessing = false;
    }

    /// <summary>
    /// Get a job by ID.
    /// </summary>
    /// <param name="jobId">Job ID.</param>
    /// <returns>The job if found, null otherwise.</returns>
    public IndexingJob? GetJob(string jobId)
    {
        ArgumentException.ThrowIfNullOrWhiteSpace(jobId);
        return _jobs.TryGetValue(jobId, out var job) ? job : null;
    }

    /// <summary>
    /// Get all jobs (queued, running, completed, failed).
    /// </summary>
    /// <returns>All tracked jobs.</returns>
    public IReadOnlyList<IndexingJob> GetAllJobs()
    {
        return _jobs.Values.ToList();
    }

    /// <summary>
    /// Get jobs by status.
    /// </summary>
    /// <param name="status">Status to filter by.</param>
    /// <returns>Jobs with the specified status.</returns>
    public IReadOnlyList<IndexingJob> GetJobsByStatus(IndexingJobStatus status)
    {
        return _jobs.Values.Where(j => j.Status == status).ToList();
    }

    /// <summary>
    /// Remove completed/failed jobs older than the specified age.
    /// </summary>
    /// <param name="maxAge">Maximum age for completed jobs.</param>
    /// <returns>Number of jobs removed.</returns>
    public int CleanupOldJobs(TimeSpan maxAge)
    {
        var cutoff = DateTime.UtcNow - maxAge;
        var toRemove = _jobs.Values
            .Where(j => j.Status is IndexingJobStatus.Completed or IndexingJobStatus.Failed
                        or IndexingJobStatus.Cancelled)
            .Where(j => j.CompletedAt.HasValue && j.CompletedAt.Value < cutoff)
            .Select(j => j.Id)
            .ToList();

        foreach (var id in toRemove)
        {
            _jobs.TryRemove(id, out _);
        }

        return toRemove.Count;
    }
}
```

### 2. IndexingJobProcessor.cs

**Location**: `src/SeniorIntern.Services/Indexing/IndexingJobProcessor.cs`

```csharp
using System;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.Logging;
using SeniorIntern.Core.Interfaces;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Background service that processes indexing jobs from the queue.
/// </summary>
/// <remarks>
/// <para>
/// This service runs continuously, waiting for jobs from the queue and
/// processing them sequentially. Only one job is processed at a time
/// to avoid resource contention.
/// </para>
/// <para>
/// Job types supported:
/// <list type="bullet">
///   <item><see cref="IndexingJobType.FullIndex"/>: Full workspace indexing</item>
///   <item><see cref="IndexingJobType.IncrementalUpdate"/>: Incremental update</item>
///   <item><see cref="IndexingJobType.Sync"/>: Full sync with filesystem</item>
/// </list>
/// </para>
/// <para>
/// Failed jobs are automatically retried if <see cref="IndexingJob.CanRetry"/> is true.
/// </para>
/// </remarks>
public sealed class IndexingJobProcessor : BackgroundService
{
    private readonly IIndexingService _indexingService;
    private readonly IndexingJobQueue _jobQueue;
    private readonly ILogger<IndexingJobProcessor> _logger;

    /// <summary>
    /// Delay after an error before retrying queue read.
    /// </summary>
    private static readonly TimeSpan ErrorRetryDelay = TimeSpan.FromSeconds(1);

    /// <summary>
    /// Initializes a new instance of the <see cref="IndexingJobProcessor"/> class.
    /// </summary>
    public IndexingJobProcessor(
        IIndexingService indexingService,
        IIndexingJobQueue jobQueue,
        ILogger<IndexingJobProcessor> logger)
    {
        _indexingService = indexingService ?? throw new ArgumentNullException(nameof(indexingService));
        _jobQueue = (IndexingJobQueue)(jobQueue ?? throw new ArgumentNullException(nameof(jobQueue)));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    /// <inheritdoc />
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        _logger.LogInformation("Indexing job processor started");

        while (!stoppingToken.IsCancellationRequested)
        {
            try
            {
                // Wait for next job (blocks until job available)
                var job = await _jobQueue.DequeueAsync(stoppingToken);

                // Process the job
                await ProcessJobAsync(job, stoppingToken);
            }
            catch (OperationCanceledException) when (stoppingToken.IsCancellationRequested)
            {
                // Normal shutdown
                break;
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error processing job from queue");

                // Brief delay before retrying to avoid tight error loop
                await Task.Delay(ErrorRetryDelay, stoppingToken);
            }
        }

        _logger.LogInformation("Indexing job processor stopped");
    }

    /// <summary>
    /// Process a single indexing job.
    /// </summary>
    private async Task ProcessJobAsync(IndexingJob job, CancellationToken ct)
    {
        _logger.LogInformation(
            "Processing job {JobId}: {Type} for {Path}",
            job.Id, job.Type, job.WorkspacePath);

        try
        {
            IndexingResult result;

            // Create progress reporter that updates job progress
            var progress = new Progress<IndexingProgress>(p => job.Progress = p);

            switch (job.Type)
            {
                case IndexingJobType.FullIndex:
                    result = await _indexingService.IndexWorkspaceAsync(
                        job.WorkspacePath,
                        job.Options,
                        progress,
                        ct);
                    break;

                case IndexingJobType.IncrementalUpdate:
                    if (string.IsNullOrEmpty(job.IndexId))
                        throw new InvalidOperationException("IndexId required for incremental update");

                    result = await _indexingService.UpdateIndexAsync(
                        job.IndexId,
                        progress,
                        ct);
                    break;

                case IndexingJobType.Sync:
                    if (string.IsNullOrEmpty(job.IndexId))
                        throw new InvalidOperationException("IndexId required for sync");

                    var syncResult = await _indexingService.SyncIndexAsync(
                        job.IndexId,
                        progress,
                        ct);

                    // Convert sync result to indexing result
                    result = new IndexingResult
                    {
                        Success = syncResult.Success,
                        IndexId = job.IndexId,
                        FilesIndexed = syncResult.FilesAdded + syncResult.FilesUpdated,
                        FilesSkipped = syncResult.FilesUnchanged,
                        FilesErrored = syncResult.Errors.Count,
                        ChunksCreated = syncResult.ChunksDelta > 0 ? syncResult.ChunksDelta : 0,
                        ChunksRemoved = syncResult.ChunksDelta < 0 ? -syncResult.ChunksDelta : 0,
                        Duration = syncResult.Duration,
                        Errors = syncResult.Errors,
                        ErrorMessage = syncResult.Errors.FirstOrDefault()?.Message
                    };
                    break;

                default:
                    throw new NotSupportedException($"Job type not supported: {job.Type}");
            }

            // Store result on job
            job.Result = result;

            // Mark complete or failed based on result
            if (result.Success)
            {
                _jobQueue.MarkComplete(job.Id);
                _logger.LogInformation(
                    "Job {JobId} completed: {Files} files, {Chunks} chunks in {Duration}",
                    job.Id, result.FilesIndexed, result.ChunksCreated, result.Duration);
            }
            else
            {
                _jobQueue.MarkFailed(job.Id, result.ErrorMessage ?? "Unknown error");
                _logger.LogWarning("Job {JobId} failed: {Error}", job.Id, result.ErrorMessage);
            }
        }
        catch (OperationCanceledException)
        {
            _jobQueue.MarkFailed(job.Id, "Job was cancelled");
            throw; // Re-throw to stop processor if app is shutting down
        }
        catch (Exception ex)
        {
            _jobQueue.MarkFailed(job.Id, ex.Message);
            _logger.LogError(ex, "Job {JobId} threw exception", job.Id);

            // Check if job should be retried
            if (job.CanRetry)
            {
                job.RetryCount++;
                job.Status = IndexingJobStatus.Queued;
                _jobQueue.Enqueue(job);
                _logger.LogInformation(
                    "Re-queued job {JobId} (attempt {Attempt} of {Max})",
                    job.Id, job.RetryCount + 1, job.MaxRetries);
            }
        }
    }
}
```

### 3. IndexingEventArgs.cs

**Location**: `src/SeniorIntern.Services/Indexing/IndexingEventArgs.cs`

```csharp
using System;
using SeniorIntern.Core.Models;

namespace SeniorIntern.Services.Indexing;

/// <summary>
/// Event args for indexing job events.
/// </summary>
public sealed class IndexingJobEventArgs : EventArgs
{
    /// <summary>
    /// The job that triggered the event.
    /// </summary>
    public required IndexingJob Job { get; init; }
}

/// <summary>
/// Event args for job completion.
/// </summary>
public sealed class IndexingJobCompletedEventArgs : EventArgs
{
    /// <summary>
    /// The completed job.
    /// </summary>
    public required IndexingJob Job { get; init; }

    /// <summary>
    /// Result of the indexing operation.
    /// </summary>
    public required IndexingResult Result { get; init; }
}

/// <summary>
/// Event args for indexing service state changes.
/// </summary>
public sealed class IndexingStateChangedEventArgs : EventArgs
{
    /// <summary>
    /// Previous status.
    /// </summary>
    public IndexingStatus OldStatus { get; init; }

    /// <summary>
    /// New status.
    /// </summary>
    public IndexingStatus NewStatus { get; init; }
}

/// <summary>
/// Event args for file indexed events.
/// </summary>
public sealed class FileIndexedEventArgs : EventArgs
{
    /// <summary>
    /// Relative path of the indexed file.
    /// </summary>
    public required string FilePath { get; init; }

    /// <summary>
    /// Number of chunks created from this file.
    /// </summary>
    public int ChunkCount { get; init; }

    /// <summary>
    /// Whether indexing was successful.
    /// </summary>
    public bool Success { get; init; }

    /// <summary>
    /// Error message if indexing failed.
    /// </summary>
    public string? Error { get; init; }
}

/// <summary>
/// Event args for file indexing errors.
/// </summary>
public sealed class FileIndexingErrorEventArgs : EventArgs
{
    /// <summary>
    /// Relative path of the file that failed.
    /// </summary>
    public required string FilePath { get; init; }

    /// <summary>
    /// Error details.
    /// </summary>
    public required IndexingError Error { get; init; }
}

/// <summary>
/// Event args for progress updates.
/// </summary>
public sealed class IndexingProgressEventArgs : EventArgs
{
    /// <summary>
    /// Current progress information.
    /// </summary>
    public required IndexingProgress Progress { get; init; }
}

/// <summary>
/// Status of the indexing service.
/// </summary>
public enum IndexingStatus
{
    /// <summary>
    /// No indexing in progress.
    /// </summary>
    Idle,

    /// <summary>
    /// Scanning filesystem for files.
    /// </summary>
    Scanning,

    /// <summary>
    /// Processing files (chunking, embedding, storing).
    /// </summary>
    Indexing,

    /// <summary>
    /// Updating existing index incrementally.
    /// </summary>
    Updating,

    /// <summary>
    /// Indexing is paused.
    /// </summary>
    Paused,

    /// <summary>
    /// Cancellation in progress.
    /// </summary>
    Cancelling
}
```

---

## Dependency Injection Registration

```csharp
// In ServiceCollectionExtensions.cs or Program.cs

services.AddSingleton<IIndexingJobQueue, IndexingJobQueue>();
services.AddSingleton<IndexingJobQueue>(sp => 
    (IndexingJobQueue)sp.GetRequiredService<IIndexingJobQueue>());

services.AddHostedService<IndexingJobProcessor>();
```

---

## Unit Testing Requirements

| Class | Test Count | Focus Areas |
|-------|------------|-------------|
| `IndexingJobQueue` | 25-30 | Enqueue/dequeue, priority, concurrency, cleanup |
| `IndexingJobProcessor` | 15-20 | Job type handling, retry logic, error handling |
| Event Args | 5-8 | Properties, required members |

**Total: ~45-58 tests**

### Test Scenarios

**IndexingJobQueue**:
- Enqueue adds job and raises event
- TryDequeue returns false when empty
- DequeueAsync blocks until job available
- GetQueuedJobs returns sorted by priority then CreatedAt
- Remove cancels queued job
- Clear cancels all queued jobs
- Prioritize boosts job to max priority
- MarkComplete sets status and raises event
- MarkFailed sets status and error message
- CleanupOldJobs removes old completed/failed jobs
- Concurrent enqueue is thread-safe
- Cannot enqueue duplicate job ID

**IndexingJobProcessor**:
- ExecuteAsync processes jobs continuously
- FullIndex calls IndexWorkspaceAsync
- IncrementalUpdate calls UpdateIndexAsync
- Sync calls SyncIndexAsync and converts result
- Progress updates job.Progress
- Success calls MarkComplete
- Failure calls MarkFailed
- Retry re-enqueues job when CanRetry is true
- Cancellation handled gracefully
- Error does not crash processor

---

## Acceptance Criteria

### Functional Requirements
- [ ] `IndexingJobQueue.Enqueue` successfully adds jobs
- [ ] `IndexingJobQueue.DequeueAsync` blocks until job available
- [ ] Jobs are tracked by ID in dictionary
- [ ] Priority ordering works correctly
- [ ] `IndexingJobProcessor` processes all job types
- [ ] Progress is reported through job.Progress
- [ ] Failed jobs are retried when CanRetry is true
- [ ] Events are raised for queue state changes
- [ ] Old completed jobs can be cleaned up

### Quality Requirements
- [ ] Thread-safe enqueue operations
- [ ] Proper cancellation token handling
- [ ] Graceful shutdown of background processor
- [ ] All public members have XML documentation

---

## Future Considerations

Items explicitly deferred to later sub-versions:
- **v0.7.3h**: FileWatcherService that enqueues incremental update jobs
- **v0.7.3i**: Progress tracking integration with UI
